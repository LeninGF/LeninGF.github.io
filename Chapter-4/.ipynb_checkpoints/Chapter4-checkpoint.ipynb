{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "<center>\n",
    "    \n",
    "<img src='images/neuron.png' width=60%\\>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una red neuronal es una estructura compuesta por **nodos** o **unidades** que se encuentran interconectados. La potencia de la interconexión entre los nodos se evalúa por medio un valor de **peso**. Si la suma ponderada de todas las conexiones al **nodo** o **neurona** es mayor que un **valor umbral**, decimos que la neurona se **activa**. La función matemática aplicada a la suma ponderada se denomina **función de activación**. \n",
    "\n",
    "Se denomina **Modelo de Perceptrón** a una red neuronal con una sola salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"174pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 174.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 170,-257 170,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"106,-89 106,-164 158,-164 158,-89 106,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"132\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.041,-184.3947C64.2693,-170.9815 91.1723,-148.7454 110.144,-133.0647\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"112.5069,-135.6525 117.985,-126.5838 108.0473,-130.2569 112.5069,-135.6525\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[0]</text>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5204,-137.1729C66.2924,-133.1031 87.6838,-127.2096 104.6999,-122.5214\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.9201,-125.8158 114.6312,-119.7853 104.0608,-119.0672 105.9201,-125.8158\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[1]</text>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5204,-92.8271C66.2924,-96.8969 87.6838,-102.7904 104.6999,-107.4786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.0608,-110.9328 114.6312,-110.2147 105.9201,-104.1842 104.0608,-110.9328\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-107.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[2]</text>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.041,-45.6053C64.2693,-59.0185 91.1723,-81.2546 110.144,-96.9353\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0473,-99.7431 117.985,-103.4162 112.5069,-94.3475 108.0473,-99.7431\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-82.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[3]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa72821b668>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_logistic_regression_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sea $\\mathbf{X}$ el espacio de entrada que contiene $N$ muestras de datos. Cada muestra está descrita por $d$ características o **features**. Sea $\\mathcal{Y} = \\{-1, +1\\}$ el espacio de salida binario. El perceptrón queda definido por:\n",
    "\n",
    "\n",
    "    \n",
    "$h(\\mathbf{x}) = sign \\left( \\sum_{i=1}^{d} \\left( w_ix_i \\right) + b \\right)$\n",
    "\n",
    "Donde **sign** es la función signo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sea $\\mathbf{w} = \\{w_{0},w_{1}, w_{2}, \\dots, w_{d} \\}^T$ el vector de pesos; en donde $w_{0}=b$ y sea $\\mathbf{x} = \\{x_{0},x_{1}, x_{2}, \\dots, x_{d} \\}^T $ con $w_{0}=1$, entonces la expresión para el Perceptron se puede reescribir:\n",
    "\n",
    "$h(\\mathbf{x}) = sign \\left(  \\mathbf{w}^T \\mathbf{x} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo de aprendizaje del perceptrón\n",
    "Para realizar el entrenamiento es preciso que las muestras de datos y etiquetas (o valores) sean randomizados. Luega en cada iteración se corregirá los valores del vector $\\mathbf{w}$, mediante la siguiente expresión:\n",
    "\n",
    "$\\mathbf{w}(t+1)=\\mathbf{w}(t)+\\alpha y(t)\\mathbf{x}(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## El Perceptron  y la compuerta AND\n",
    "La compuerta **and** consta de 4 ejemplos. Cada uno con 2 características $d=2$. \n",
    "\n",
    "\n",
    "| muestra | x1 | x2 | y  |\n",
    "|---------|----|----|----|\n",
    "| 1       | -1 | -1 | -1 |\n",
    "| 2       | -1 |  1 | -1 |\n",
    "| 3       |  1 | -1 | -1 |\n",
    "| 4       |  1 | 1  |  1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "Y = np.array([-1, -1, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 4, Avg. loss: 0.750000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 8, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 12, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 16, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 20, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Rendimiento del entrenamiento: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "percept_and = Perceptron(verbose=1, shuffle=True)\n",
    "percept_and.fit(X, Y)\n",
    "print('Rendimiento del entrenamiento: {}'.format(percept_and.score(X,Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = percept_and.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "1. Verifique que la Compuerta **XOR** No tiene solución con un Perceptron\n",
    "2. Verifique que la Computerta **OR** Tiene solución con un Perceptrón\n",
    "3. Escriba un programa en Python que ejecute el algoritmo de aprendizaje del Perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales Multicapa con Alimentación hacia adelante (Feed Forward)\n",
    "Al añadir capas ocultas a una estructra de redes neuronales se amplía el espacio de hipótesis. Una red sencilla con una capa oculta con 3 perceptrones es la indicada en la siguiente figura. Observe la estructura de izquiera a derecha formada por:\n",
    "\n",
    "* Capa de entrada\n",
    "* Capa oculta\n",
    "* Capa de Salida\n",
    "\n",
    "Note que la capa de salida puede tener más nodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"252pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 252.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 248,-257 248,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"80,-35 80,-218 164,-218 164,-35 80,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"184,-89 184,-164 236,-164 236,-89 184,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- h0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>h0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[0]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.9237,-180.7762C59.1082,-157.4817 88.244,-112.7848 106.311,-85.0684\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.4488,-86.6639 111.9776,-76.3753 103.5847,-82.8414 109.4488,-86.6639\"/>\n",
       "</g>\n",
       "<!-- h1 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>h1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[1]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-190.6657C63.8004,-186.8567 80.7424,-181.6586 94.9198,-177.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-180.6026 104.6501,-174.3232 94.0634,-173.9105 96.1167,-180.6026\"/>\n",
       "</g>\n",
       "<!-- h2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>h2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[2]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-183.6978C61.5794,-170.6144 84.2611,-149.7369 100.8935,-134.4276\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5216,-136.7655 108.5089,-127.4179 98.7809,-131.6152 103.5216,-136.7655\"/>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-129.6978C61.5794,-116.6144 84.2611,-95.7369 100.8935,-80.4276\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5216,-82.7655 108.5089,-73.4179 98.7809,-77.6152 103.5216,-82.7655\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-147.3343C63.8004,-151.1433 80.7424,-156.3414 94.9198,-160.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-164.0895 104.6501,-163.6768 96.1167,-157.3974 94.0634,-164.0895\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-136.6657C63.8004,-132.8567 80.7424,-127.6586 94.9198,-123.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-126.6026 104.6501,-120.3232 94.0634,-119.9105 96.1167,-126.6026\"/>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-82.6657C63.8004,-78.8567 80.7424,-73.6586 94.9198,-69.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-72.6026 104.6501,-66.3232 94.0634,-65.9105 96.1167,-72.6026\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-100.3022C61.5794,-113.3856 84.2611,-134.2631 100.8935,-149.5724\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.7809,-152.3848 108.5089,-156.5821 103.5216,-147.2345 98.7809,-152.3848\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h2 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-93.3343C63.8004,-97.1433 80.7424,-102.3414 94.9198,-106.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-110.0895 104.6501,-109.6768 96.1167,-103.3974 94.0634,-110.0895\"/>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-39.3343C63.8004,-43.1433 80.7424,-48.3414 94.9198,-52.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-56.0895 104.6501,-55.6768 96.1167,-49.3974 94.0634,-56.0895\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.9237,-49.2238C59.1082,-72.5183 88.244,-117.2152 106.311,-144.9316\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5847,-147.1586 111.9776,-153.6247 109.4488,-143.3361 103.5847,-147.1586\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h2 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-46.3022C61.5794,-59.3856 84.2611,-80.2631 100.8935,-95.5724\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.7809,-98.3848 108.5089,-102.5821 103.5216,-93.2345 98.7809,-98.3848\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"210\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- h0&#45;&gt;y -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>h0&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.7326,-70.6541C150.9973,-78.7938 170.2058,-90.5808 185.4857,-99.9571\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.0498,-103.1824 194.4036,-105.4295 187.7109,-97.2161 184.0498,-103.1824\"/>\n",
       "</g>\n",
       "<!-- h1&#45;&gt;y -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>h1&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.7326,-159.3459C150.9973,-151.2062 170.2058,-139.4192 185.4857,-130.0429\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7109,-132.7839 194.4036,-124.5705 184.0498,-126.8176 187.7109,-132.7839\"/>\n",
       "</g>\n",
       "<!-- h2&#45;&gt;y -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>h2&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.2337,-115C152.1508,-115 167.9616,-115 181.5183,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.7897,-118.5001 191.7897,-115 181.7897,-111.5001 181.7897,-118.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa6d16a9b70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_single_hidden_layer_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La complejidad del problema puede requerir incrementar el número de capas ocultas. Para entrenar este tipo de redes se necesita el algoritmo de **back propagation** o retropropagación del error, ya que al tener varias neuronas en una capa oculta se dispone de un vector de hipótesis cuyos valores correctos no se conocen previamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"378pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 378.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 374,-257 374,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"80,-35 80,-218 175,-218 175,-35 80,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer 1</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"195,-35 195,-218 290,-218 290,-35 195,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer 2</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"310,-89 310,-164 362,-164 362,-89 310,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- h1[0] -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>h1[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[0]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.308,-181.0368C60.4387,-157.6212 91.7762,-112.1314 110.9005,-84.3702\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.8551,-86.2509 116.6459,-76.0302 108.0905,-82.2797 113.8551,-86.2509\"/>\n",
       "</g>\n",
       "<!-- h1[1] -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>h1[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[1]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-190.9215C65.1319,-186.9617 84.3149,-181.3924 99.9321,-176.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-180.2051 109.5858,-174.0557 99.0065,-173.4827 100.9582,-180.2051\"/>\n",
       "</g>\n",
       "<!-- h1[2] -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>h1[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[2]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-184.0482C62.9704,-170.7677 87.7855,-149.1546 105.5924,-133.6453\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.9791,-136.208 113.2212,-127.0009 103.3816,-130.9294 107.9791,-136.208\"/>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-130.0482C62.9704,-116.7677 87.7855,-95.1546 105.5924,-79.6453\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.9791,-82.208 113.2212,-73.0009 103.3816,-76.9294 107.9791,-82.208\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-147.0785C65.1319,-151.0383 84.3149,-156.6076 99.9321,-161.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-164.5173 109.5858,-163.9443 100.9582,-157.7949 99.0065,-164.5173\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-136.9215C65.1319,-132.9617 84.3149,-127.3924 99.9321,-122.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-126.2051 109.5858,-120.0557 99.0065,-119.4827 100.9582,-126.2051\"/>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-82.9215C65.1319,-78.9617 84.3149,-73.3924 99.9321,-68.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-72.2051 109.5858,-66.0557 99.0065,-65.4827 100.9582,-72.2051\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-99.9518C62.9704,-113.2323 87.7855,-134.8454 105.5924,-150.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3816,-153.0706 113.2212,-156.9991 107.9791,-147.792 103.3816,-153.0706\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-93.0785C65.1319,-97.0383 84.3149,-102.6076 99.9321,-107.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-110.5173 109.5858,-109.9443 100.9582,-103.7949 99.0065,-110.5173\"/>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-39.0785C65.1319,-43.0383 84.3149,-48.6076 99.9321,-53.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-56.5173 109.5858,-55.9443 100.9582,-49.7949 99.0065,-56.5173\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.308,-48.9632C60.4387,-72.3788 91.7762,-117.8686 110.9005,-145.6298\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0905,-147.7203 116.6459,-153.9698 113.8551,-143.7491 108.0905,-147.7203\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-45.9518C62.9704,-59.2323 87.7855,-80.8454 105.5924,-96.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3816,-99.0706 113.2212,-102.9991 107.9791,-93.792 103.3816,-99.0706\"/>\n",
       "</g>\n",
       "<!-- h2[0] -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>h2[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[0]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-61C163.6433,-61 192.3671,-61 213.7431,-61\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-64.5001 223.8632,-61 213.8631,-57.5001 213.8632,-64.5001\"/>\n",
       "</g>\n",
       "<!-- h2[1] -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>h2[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[1]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.192,-73.389C160.0161,-92.0064 197.669,-127.3674 221.211,-149.4764\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.9222,-152.1284 228.6077,-156.4228 223.7142,-147.0258 218.9222,-152.1284\"/>\n",
       "</g>\n",
       "<!-- h2[2] -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>h2[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[2]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-68.7369C162.5201,-77.679 194.0899,-92.5031 216.3526,-102.9569\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0145,-106.1951 225.5539,-107.2775 217.9898,-99.8589 215.0145,-106.1951\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.192,-156.611C160.0161,-137.9936 197.669,-102.6326 221.211,-80.5236\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"223.7142,-82.9742 228.6077,-73.5772 218.9222,-77.8716 223.7142,-82.9742\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-169C163.6433,-169 192.3671,-169 213.7431,-169\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-172.5001 223.8632,-169 213.8631,-165.5001 213.8632,-172.5001\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-161.2631C162.5201,-152.321 194.0899,-137.4969 216.3526,-127.0431\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.9898,-130.1411 225.5539,-122.7225 215.0145,-123.8049 217.9898,-130.1411\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-107.2631C162.5201,-98.321 194.0899,-83.4969 216.3526,-73.0431\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.9898,-76.1411 225.5539,-68.7225 215.0145,-69.8049 217.9898,-76.1411\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-122.7369C162.5201,-131.679 194.0899,-146.5031 216.3526,-156.9569\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0145,-160.1951 225.5539,-161.2775 217.9898,-153.8589 215.0145,-160.1951\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-115C163.6433,-115 192.3671,-115 213.7431,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-118.5001 223.8632,-115 213.8631,-111.5001 213.8632,-118.5001\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"336\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- h2[0]&#45;&gt;y -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>h2[0]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M257.9458,-70.1604C272.6188,-78.5895 294.6007,-91.2174 311.5017,-100.9265\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"309.8752,-104.0285 320.2897,-105.9749 313.3621,-97.9588 309.8752,-104.0285\"/>\n",
       "</g>\n",
       "<!-- h2[1]&#45;&gt;y -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>h2[1]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M257.9458,-159.8396C272.6188,-151.4105 294.6007,-138.7826 311.5017,-129.0735\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.3621,-132.0412 320.2897,-124.0251 309.8752,-125.9715 313.3621,-132.0412\"/>\n",
       "</g>\n",
       "<!-- h2[2]&#45;&gt;y -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>h2[2]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M260.1241,-115C273.6484,-115 292.3808,-115 307.8486,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.9315,-118.5001 317.9315,-115 307.9315,-111.5001 307.9315,-118.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa6d165f128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_two_hidden_layer_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "Utilice una red neuronal multicapa para clasificar los datos del dataset moons, con:\n",
    "* Algoritmo de descenso de gradiente estocástico,\n",
    "* 50 neuronas en la capa oculta,\n",
    "* Función de activación relu, luego con sigmoid\n",
    "* Pruebe con algoritmo lbfgs y sgd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Realicemos un plot de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], c=y, cmap=cm_bright)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42) #, stratify=y\n",
    "red = MLPClassifier(hidden_layer_sizes=(50,), \n",
    "                    solver='lbfgs', \n",
    "#                     learning_rate_init=0.0001, \n",
    "#                     activation='relu', \n",
    "                    random_state=0, \n",
    "                    verbose=True, \n",
    "                    max_iter=1000)\n",
    "history = red.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31702684, -0.2525239 ],\n",
       "       [ 1.15536561, -0.50593577],\n",
       "       [ 1.31311917, -0.69665985],\n",
       "       [ 0.8729088 ,  0.08643291],\n",
       "       [ 1.72532644,  0.53367598],\n",
       "       [-0.4993884 ,  0.13192906],\n",
       "       [ 0.35940317,  0.84867003],\n",
       "       [-0.16955317,  0.60660877],\n",
       "       [ 1.50917461, -0.06701048],\n",
       "       [ 0.36877983, -0.34894509],\n",
       "       [-0.7280717 ,  0.3259131 ],\n",
       "       [ 0.77145295, -0.69709227],\n",
       "       [ 1.00549331,  0.38686701],\n",
       "       [-0.74872343, -0.06972957],\n",
       "       [ 1.89948318,  0.79928869],\n",
       "       [-0.87006365,  0.70686285],\n",
       "       [ 1.12856036,  0.33191968],\n",
       "       [ 0.97370054, -0.08631168],\n",
       "       [ 0.89715307,  0.94175457],\n",
       "       [-0.51699811,  0.74457804],\n",
       "       [-0.59385445,  0.46769065],\n",
       "       [-0.46333991,  0.86330772],\n",
       "       [ 0.55039452,  1.16554689],\n",
       "       [-0.60690411,  0.50000529],\n",
       "       [ 0.42598043, -0.3006242 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La precisión sobre el dataset de entrenamiento es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = red.score(X_train, y_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La precisión sobre el dataset de prueba es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = red.score(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD5CAYAAAAHtt/AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt0VNXZP/DvztVcgMSiECzqr6kVlYCK0BZaUDRoRQWKfcUCQfFntfTHQo0SXCpvqa+1YENRRNG+tWBBU2/ghWqSJgKFomCsEBCqZRVEe7wFQhIIIZf9+2NyksnkzMyZmXM/389aWcbJmZkDZJ7znGfv/WwhpQQREblHkt0nQEREsWHgJiJyGQZuIiKXYeAmInIZBm4iIpdh4CYichkGbiIil2HgJiJyGQZuIiKXSTHjRfv2PVUOGDDYjJcmInK9lONNyMpK7vV4zccffy2lPC3q8804qQEDBmPp0jfNeGkiItcbULsFo0ad2utxUVh4UM/zWSohIrJQuKAdCwZuIiKLDKjdYsjrMHATEVko0WwbYOAmIrKEUdk2wMBNRGQZI7JtgIGbiMh0RgxIBmPgJiIykZElEhUDNxGRyYzMtgEGbiIi05iRbQMM3EREpjI62wYYuImITGH0gGQwBm4iIoOZVSJRMXATEZnArGwbYOAmIjKU2dk2wMBNRGQ4M7NtgIGbiMgwZg5IBmPgJiIygBUlEhUDNxGRQazItgEGbiKihFmZbQMM3EREhrAq2wYYuImIEmLVgGQwBm4iojhZXSJRpdjyruQbinIAr77+DDZuWofmpnpkZOfg0nFTMOna2cjLO9vmsyNKnNXZNsCMm0xUU1ONecUTsa2uETk3Lsbgu9ch58bF2FbXiHnFE1FTU233KRLFza5sG2DgJpMoygEsLp2LnMn3oe/YIqTm5kEkJSM1Nw99xxYhZ/J9WFw6F4pywNbzJEqEHdk2wMBNJnn19WeQUTAB6Wecp/nz9DPOQ0ZBIV57448WnxlR4uwYkAzGwE2m2LhpHTIKCiMek1EwARs3rbPojIiMYWeJRMXATaZobqpHSr/TIx6T0vc0HG+qt+iMiIxjZ7YNcFaJ6ymKM2dtZGTnoO3ol0jNzQt7TFvDV8jMzrHwrIgS44RsG2DgdrWammosLp2LjIIJyLlxMfr3Ox1tR7/EttpKVBdPREnxcowYMd7Uc1AU7QvHyEsux67aSqSOLQr73ObaClw6boqp50dkNLuzbYCB27UUpXvWRvAAYGpuHlLHFiE9fyQWl87Fo6UbTMu8I104ju+qQEd7G9LzR2oOULZ8thfNtZW4rnSDKedGZDS7BySDscbtUnbP2lCUyNP9cqfcD5GUhMOv/AoNm1ej9YgC2d6G1iMKGjavRv36h1BSvJyLcMgVnFIiUTHjdqmNmwKLWSLJKJiAjWULcNutiwx/fz0XjqzhV2F4ZhKyMvtgY9kCHG+qR2ZnKeU6E+8EiMzglGwbYOB2reamevS3cdaG3gvHjrIFeH7NLlMuHkRWcFq2DbBU4lrqrI1IzJy1wel+5CdOyrYBBm7XunTcFDTXVkY8xsxZG3ZfOIis4KQByWAM3C416drZaK6tQMtnezV/3jVr45qbTXl/uy8cRGZzYolExcDtUnl5Z6OkeDnq1z9ky6wNuy8cRFZwYrYNcHDS1UaMGI9HSzfgtTf+aPmsDfXCEZjHXYiMgglI6Xsa2hq+QnNtBZprKzndj1zLydk2AAgppeEves45w+XSpW8a/rrkPIpyIHDh2LSu54XjmpsZtMm17Kpti8LCGinlJVGPY+AmIupm54Ck3sDNGjcRUSenl0hUrHF7iKI4s1MgkZs4dUAyGDNuj+D+jkSJcUu2DTBwe4KicH9HIiO4IdsGGLg9we5OgURu59QVkuEwcHsA93ckip+bSiQqBm4PYMMnosS4KdsGGLg9gQ2fiOLjxmwbYOD2BDZ8Ioqf27JtgIHbE9jwiSh2bhuQDMbA7QF2dwokchu3lkhUXDnpEXZ2CiRyI7dm2wADt6fk5Z2N225dxP0diSJwe7YNsFRCRD7k5mwbYOAmIh/xQrYNsFRCDqQo7HJIxlODttuzbYAZNzkMuxySmbwQtAFm3OQgitLd5TC4YVZqbh5SxxYhPX8kFpfOxaMGzZJRFGb2fuGVEomKGTfpMqB2i+m//FZ2OWRm7z9eybYBBm5bKcoBrHx6IaZNL8CkSYMxbXoBVj690HF9s63KVqzqcqgo7F/uJ17LtgEGbtsYnfEpirkXgVGjTsWoUaea+iGwqssh+5f7h5cGJIMxcNtAUYzN+My67T98+Av86oGpqGvsDpRmBm+ruhyyf7m/eC1oAwzctjAy41MU827717+0DPv/uR2V/9zQ43Gt4K0oiWf8VnU5ZP9yf/BiiUTFwG0DIzM+s277Dx/+Am9Xv4CqogysrijH54cP9zpG/WAYlfFb1eWQ/cv9w4vZNsDAbQsjMz6zbvvXv7QMswqScFFeMoqGJWNJ2doeP1c/EK0bXzIs47eqyyH7l3ufl7NtgIHbFkZmfGbc9qvZ9oIxgV+P+d9P0sy6R406Fc+/U47MoYVxZ/yK0rPE8sjSefjuyEIMz0zC0bIFOLR0Ko6WLcDo/v3waOkGjBgxXvefIxz2L/c2rw5IBmPgtoGRGZ8Zt/3rX1qGWcOTkdcn8OuR1ydJM+sGgMrdf8cpwyZEPscwGX+4EsuuEwLvvFuOu+9chlfXf4Ln1+zCbbcuMmxRDPuXe5+XgzbAlZO2mHTtbFQXT0R6/kjNTLUr4yvdoPHsni4dNwXbaiuROrYo7DHhLgKK0nvl4Pe+eyXe2/oK9v08tcex87+fhKFPlWP+tOkYeGr3h6KhsQH94sj4FcXaVZKh2L/cm7xeIlEx47aBkRlfvLf94bLdHR9ux/QLZFe23XXOYbLuvn36xpXxO2Eutdq//Pk1u0zJ7MkeXs+2AQZu26gZ3+j+/RKq5cZzEVAU7SmEIjUd7YcP4YGxaZrvpVXrnj7+MrTsroh4jloZv1fnUiuKO1bDepFfsm2ApRJbGbVjTay3/eGy3RPvluGm4Sm9su2u8w3KupfOmQsAuGvKZDz7i7lI/daomMo+zU316O+xudQ1NdVYXDoXGQUTkHPjYvTvdzrajn6JbbWVqC6eiJLi5YYMrlJvfhiQDMbA7RGxXAQ2bgqURUJ1fL4PT3x6HE+8G/n5Y4bs6fo+f9AgvHBvCf7r4QfRWjAB6QVXIqXvaWhr+ArNtRVorq3ULPuog6qpuXlh38fKudSKklinQEWxt2ZP/gnaAAO3L4XLdvtOfwx9O7+X7W34dOmP0V5eHvX1fjRqFD5YsRy/W/8q1pTNR2PTUWRm9MVVw8egMEygSmRQ1WhGZMqx1Oy5J6ix/FQiUbHG7UN6pxD2ye6n+zXzBw3C43N+jvqXX0B7eTka17+IeyYW4cKvP9U8XmtQtfWIgsNVv8eh5TNwcMm1qN/xGpqONZhaH1YUY1oGeLVm7xZ+yrYBBm5f0jOPvKW2HDMuvyyh91E/TFoZUeigauPOCnz+p2KIlFQMnPEIzrx7PfJmP45dzTC1P7ZRs1vY/8Qefsy2AQZuX9IzhbCltgJ3Tp6U8HtFCt7qoOrwDIEjVU/h9KkPIHfcTZb2xzYqUzZqIZSicFaKXn4bkAzGwO1D0aYQHn3lQbxwbwnyBw0y5P2iZd6ZmX2Qc8kkW+Z0H288gsaa1zrLM9fh0PIZOFz1e7QeUbqO0ZMpG7EalrvyxM6PQRtg4PatSPPI19z+IH40apSh7xcpeNtVH66pqYZITYNITe8sz6zDwBmPQKSk4fM/FaN5/3sA9GXK8S6EUpRAhn3DT4di0aIinGxvR1trCwBwV54I/FoiUQkppeEves45w+XSpW8a/rpepSiBqWhvb3wFzcfqIZLTIGUHTjklE+Mvu97SzWsH1G4xNYvZvj2weOeLgh90PTZp0mAMvnsdRFJy2OfJ9jYcWjoVr67/xJDzUJQDmFc8sdf0PVXLZ3vx5csPYuDMUjTXVmB0/35RZ4N0z04pREbBBM1pkcGzU4Jns2QUFCKlczZL064KNO0sR/+JdyEj/5Ku4xs2r9Z1Hn5g9u+pXURhYY2U8pJoxzHjtpl6e/z3rxuQ+9MlXYNyfUdOxsn2Dmz+10eeuk3Wyrzt6I+tZ1Aye/gE1P/tT7o7BcayGlZRws9myR03C6dPfQBfb1jao2TDWSkBfs+2AQZuWylK94e337hZvT+81y/E8YM7kX35bZ66TQ4N3nb0x9ZTnskediWaP343pk6Bevuf6L1wNL7/RtdjnJXSzYvZdiwYuE2gKPpmBuj98LZ8ts9zm9cGB287+mPrnb6HjlZTlqnrvXAc27up6/+5K493SySxYuA2WCwzA2L58Fpxm2z1Laj6Abzw608t74+tvzyTa9h7BtN74eg43tD9HJ/vysMSSbe4ArcQItvoE/ECRYltFV4sH16rbpOtzmbU97s6Lc2Qbol62b19md4LR1JmoAkBd+UJYLYdEG/G/aGhZ+ERsa7Ci+XD6+Xb5ODM26r+2HZvX6bnwtG0sxwZ3xrJXXnAbDtU2MAthLgrzFcxAGbcGmKdj6zrw7urHFnnjfP8bXKked5msHv7Mj0Xjsaa19Hx7x2m3XW4DbPtbpEy7l8DyAXQJ+QrO8rzfCvWfhV6PrxNOyuQfsYQX9wmWx28jdrMIh56LhwL7/tf/Pm5Pb7flYfZdm9hF+AIIf4OYK6UskbjZ4eklIPDvahfF+BMm16AnBsXR+wx3XpEwdGyBXh+zS4A3YswThl6BTKHdfeybtpZjqad5cg8ezjaPt1tehN+J43Way3S8SpFORDYAGPTup4bYFxzs6+DdTAn/W6aTe8CnEiB+1wAdVLKrzV+NkBK+UW4F/Vr4F759EJsq2tE3wg9prVWvylK4MNb/fbLaD52FCIlFbKjAxkZWRh/2fWWfIid9uHwU/Cm8Iz6vVTq6nDzkl9jVcl9PTa7dhq9gTvsRgpSyn9G+FnYoO1n8e7ebtQWZl4yatSp2L79MAbUbmHw9ikjSyRLytZi+97dPbbdczPWqg1k94CX11hd8ybnMSrbXl1RgaqZGb02u3YrXwRuRbGux7GdA17xcnJgZPD2p+Str+POVb80JMguKVuLWcOTcVFectdm127n+e6A4TqwNddWorm2gjtvw3n1bS1uq3krSmKbD/vd87+5GW/946+46aprEiptKHV1uGD2LOy5PRV5fZKgNHZg6FOt2PPMs46sdRvWHVAI8R0hRJUQYnfn/w8TQtxvxEmaTVGM2U+Q7OemzJsbIiQmeevr+Ms/NhpS2lCz7bw+gVCX1yfJE1m3nlLJ7wHcC6AVAKSUuwBMM/OkjGLUfoLkDG4I3orCZCFRa/72Cm6+MCXh0oZa257//Z5hbv73k1xf69YTuDOllNtDHmsz42SMxp23vcfpwVtPspB23mW4bc447iepQc221WCbSJANzbZVXsi69QTur4UQ+QAkAAghrgegRH6KM7ht521FsX6jWDfUt0M5OXjr6vh40dVISs9m+USDmm0nWtoIl22r3J516wncvwDwFIAhQojPANwB4HZTz8ogVu+soijxB14v1kWVujpcVVJsyofDqcFbd8fH5gaWT0KEZtuqeIJsuGxb5fasO2LgFkIkAbhESnkFgNMADJFS/kBKedCSs0uQla07Ewm8iuLNumjwogczODF4x9quFeBYiyo021bFE2R37PsQy7Ydh1jUEPZr2bbj2L53j9F/DEtEDNxSyg4A8zu/PyalbLTkrAxiVetORUks8HpxENWqRQ9OC96xdHwM5vexlnDZtirWrHvL8pWQlZVRv7YsXxn2Ncy8Y0yUnlLJX4UQdwshBgshTlW/TD+zKBQlelnCqpWMiQZeuwZRzQx2Vi56cFLw1tvxsc/F1/R43EljLXYIl22r7ChtmH3HmAg9gfsGBOrcmwHUdH69Z+ZJRRNLWcKKlYyJBl47B1HNGJgMHRiyYiDIKcE7UrJwZNMqfPnyg+g/8a5eHSS9vFFGNANqt+CTw/sdVdpw+jL5sE2mVFLK/2PFieilKN1lieAMNzU3D6lji5CePxKLS+fi0dINXZm02U2cmpvq0T+BwKvWRSO1g3XTBzvSogczG/w4pTGVmiy89sYfsbFsAY41HkFSWgayCq7AwJmlmv/OXt8oIxz1QhupZGGHnneM0nHNqfSsnCzS+rLi5LQ4sR6c6OwVu/c/NJLdix6clHmr27A9tfJvSEtNRdaQH2gGbb/vJ+m06ah23DHGSk+pZGTQ1w8B/BLAdSaeU0RG1YMVxbg504kGXrv3PzSS0Yse4hkgckrwVrFrpDan/PuEcsMy+aiBW0o5N+jrVgAXw8Y9J42oBxs9ZzrRwOuVD7YZix7iHSByWhbnxq6RVnDav5Pdd4x6xdwdUAiRCmC3lPLccMeY2R0wnu3BginKAcwrntirRq5q+Wwv6tc/1KNGrkd3F8JCZBRM6NqCrLm2As21lbq6ECqKddtYmbFi8s4VjwFfVOF3E8IPndxZ0QYx8Apd9UK1s1vVjBRcsbYt5o5usXQUVBR287OSmm07LXBH+h2O5Xc3XglvXdZ1gBCvo3O5OwIZ+vkAXpRSloR7jpmBO97twYx6fiSK4tz9AxWlZ2DKyuyDosLxuGvKZOQPGmTIe/xg7u3Yum9/1OPGDMnXNRgV/CGK90OjJ3iz9a+1nBq0Q1vA9vq5BS1hjQzcwSsF2gAclFJ+Guk5ZgZuRUksY040Y7eKohiXAYYLTC27K9Cyqxwv3FuCH40aZcYfI25G9FFW9xmcN+EXaBt9jfYxijl3YKTNqUEbMP6OMR4J7zkZ5OrQ7FoIsThSxm0mtR4crSwR7kOW6NQ9KwQH2pwbF6N/Z6DdVluJ6uKJMWWAihJh+uQPZyH1W6PwXw8/iA9WLDcs8zaCEVMK1fr4mlNexrw+OZpZdyyzlLgnaGSKEjnZcHLQBgLL5LfuO45l2yIfN2aI/cvk9WTc70spLw55bJeUcli451ixA46ixFeWcHrGrSjGZoB6SkNNm1dh2sAOPD7n5/GfuIHC3bLGknWH1sfXzH0M39AI3k7/fXALrbu6FuUjHPvLErSeaMFvrp+D0ede5Nig7RQJ74AjhPi5EKIWwLlCiF1BX/8GYPtvcPA82VfXf4Ln1+zCbbcuihrMnD5n2uh56nqmT6YXXIk1VW/HfK5mMWJKYeiS+8p/btA8zm2tf51IUbR79bTtexvJx+uQcdZQ3Pvi47jnuYWOmZXhdpGmAz4H4FoAr3X+V/0aIaWcYcG5mcLpc6aN7luiNzA1Nh3VfY5mMmJKYbgFFGd+u/fcYT2Lp058ugcpaRmW9kl3E61ko63pMJp3/xVvF2Xg5IEapPb7Bnbt/8hRc6HdLGzgllIelVIekFLe2NnGtRmB2SXZQogzLTtDgzl9zrTRGaDeVZ19svvpPkczGdFHOdoCiuDgHe0OrHn/e/hq3UPIHH6lZ/qkG00r2TjxbhluGh7YfuwnQ5LQdvgQqosyHTUX2s2iDk4KIa4FsBTAIABfAjgLwF4AF5h7auYJ7SXRo0Zu8+wBo/uWXDpuCrbVViI1Qo27pbYcMy6/LOZzNUOiA0Rqtr3n9tQej8//fhKGPlWO+dOm45N/dT8+6drZqC6eiPT8kb3KU61HFHz9xm8x4CeLdPfF8aPQAX81275/ThoAIE204aZhzu374UZ6Bid3AhgP4K9SyouEEJcBmCGlvCXcc6wYnPQqo+eZK0r0wc6m9c6bVRIvvQsotm8/3DVQGW7xVN0bv0XaN8/HqZeF/VWPe86/l4QO8DZVPYEbkjdixVUpUBo7cMETTdgzJzvuaZ1+kvDgZJBWKWUdgCQhRJKU8m0AUV+Y4mN0DT5Saahp8yo0rX8QL9xb4omgHWt9XC2ZhFuO3nH4U/S58OqI7+n3DRCAwF3diV0VAIKy7TGBf4MlW09i1vA0R/f9cCM9gbteCJEN4G8A1gohHgVwzNzT8i8zavC9AlPpj3GsbD6mDezAByuWO27xTbxiqY+HNqLSmqXU1tLMGScRDKjdggG1W3DLd4bh5O5ytHy2t6u2rWbXq3eexPwxaT2e57S+H26kp1SShcDAZBKA6QD6AVjbmYVrYqkkcYpi3vJ5N+7srkc8S+4jLYnnHG9twYO76u/Rm9u34/qHHoZsa8b+/5eBvD5JuPOtEwCA3111Sq/XsKLvhxsZtuQdAIQQZwE4R0r5VyFEJoDkSPtPMnA7l9NXr9khXPA2s6+NG2kF7GCzlzyMzKNb8fiP0nvVtkOx1q3NsBq3EOJWAC8BeKrzoTMArE/s9MhODNo9hevf7fQ5/1ZRSyJA4O8q3O/PR4cOYsX2FohFDfj2Y02YNlS7WRPAWnei9PQq+QWAUQDeBQAp5cdCiMiFPwspCttxkja1ydSqkvuiZnVa254l2hfH7WK9O1PLT3eueAzPvPk6nnyvFU++1xrxOU7o++FGegJ3i5TypBACACCESEF3m1dbGdmMibwneBMGPbVUreDt5Dn/ZohWDolGndmzcVZWXD3USR89g5NLANQDKAIwF8AcAB9KKe8L9xyrmkyxHWfsvDowGSqRTRiC53j7RaIBW2VED3U/M3Ie9wIAXwGoBXAbgL8AuD+x00ucEzcNJucIbTIVay3VqfshGk1v/VoPN2yy6xWRugOeCQBSyg4p5e+llD+RUl7f+b3tpRKjmzH5gV+CUaIBxA93JEYGbJUbNtn1ikgZd9fMESHEyxacS0zYjjM+fghKS8rW4vrzknDzq834vKmDAaSTGqzVcplRARtwzya7XhEpcIug779l9onESm/XO73NmMgb1AAC2Ybtn7VjydaTAOLLuhO9Q1GUA1j59ELL28EePvwFfvXAVBw5Evh8mJFdhzKihzrpFylwyzDfO4LTN0Qge6jZ9ksftqKqKAurd7baknXX1FRjXvFEbKtrtLwd7PqXlmH/R9tR/lSJ6QEbMKaHOsUmUuAeLoRoEEI0AhjW+X2DEKJRCNFg1QmGw8URFCo42541PK1zYDI17qwbiG9cQFG0d4QBgLbWFpxsb8eiRUW44adDDc/ADx/+Am9XlaFqZgb+8o+NOPPb5pfHjOihTrEJO49bSpls5YnEyu+LI6i3rmx7Twv2zMkGAMwfk4ahTx7D/DFpMW84rM7rjpXWjKfm/e/h6w1LkT38SgycuRQpBq85UC8wz2/4A26+MLCBwU0XWtP72k2b7HqFngU4juW3xRGJ8MOMkh37PsSOj5txy0WpPWY23HBBCs5a1oST7YHjzA4gGzcFyiKq1iMKvt6wFKdPfcDwDRmC/10H50u89cGmrk0kgjePiGcRjN6Vp+qKSbKOriZTsWKTKefxw8IbI3aHDxWpe2Cv91cC7RfefOtPkO1tSMroi6zzx6HjxDEkZ+cid9yssM+NtVmV1oIZrU0kElkEc+eKx7C6fANuuuoaLqKxiJELcIhsp9TV4aqS4oj1aTNmNui92AUPRubNXoEz716HgTMegUhJw/F9m5E9bELE5+tdcxBuhojR0/HU16uamcGBRQdi4CZXCO47osXOmQ2Koj0YmZqbh9xxsyDbWxNecxBtSp/RF61EV56SuRi4yfH0ZH96ZjbMLIg/6440RhCt/UJSRr+41hzoXTBj9EWLS9edj4GbHE9P9rdj34dYtu04xKKGsF+PvnMc2/caPzAZrf1C1vnj0LSrPOJrBK85CM2uB+fLiGUio6fjcem687l6Vgl5n5r9RZspEW5mQ2iXwJcW/Tqu8whMDdyiOUjZ3FSP/hFKIX0uvgaf/6kYmd/+bthOls21lZj9s0WaPbCjtac1cjpe6N+3KtEZKmQsBm4fcPOMkkjZn56ZDj2zdXPmNavtF8LtTZmam4eccTfhiz/fj5xLruu15uDEznI8fP0cfPMbA3v9OwWXia5Yqx04jZyOp6dWzhkm9mOphGKiZ3aHke+VyEwJM2q1WrVuPe0X5FEF4344CaP798PRsgU4VPpjNKy9B5eL46h9cjnumHm55sXVykFCLl13DwZuikm02R1Gv1ciMyWMrtUmujfl3AvHYOH3ClFd8gTe+Z/n0bj+Rby46A7kDxqk+TyrBwn11MpvPF/il6v+YMr7k34M3BSVmmXv3L/fsrm9iWZ/ZrUZ1cqK1fYL9esfQsPm1Wg9okC2t6H1iIKGTatw9JUH8fCPb+8qheht+GT1IKGeAd4VO06ifMe7prw/6cfATVGpWfatv/1N12371CFJ+OG8ObZmf5GCmJltRrWmB6rtFy4Xx9Gw9p6uUshP8zoilkLCsaO/9ZblKyErKzW//lNWhtzMdLz/syw0NJ9gucRmHJykiNQAUjY1HZPLDuDV6wLNmyDb8NWROvxy1R+w8q57DH/fRGZKhJsZoTJqhkRo8B4A4GeL7gBwR9yvqXLaIGHoIO/CVX/AJ198HrWPCZmDvUo8Tmt6WSzU/hfoaENbh8TyqzOgNHbggieaUFWUhXGrT+CjZ59z1IdXq2dHr2McvJFtuJ4rXT9PoPeKEeejNHZgyIpmJCdJ9jExmN5eJcy4fSDeoK1mrtUzkjH+2ZNdrVKXbD3Z1e96RkGSaVl3vNzeZjSWMpEVQVPrfDpkOzbOzAo7RZHMxcBNYakf2NU7AxsTqNnW6p3dQfyBsek4d0UVfnnTLY758G5ZvtLVne2cdOHRKjst2XoSt1yUiovykjGzwJqe39QTAzdpipZtB890MCPr1tsLOtK5R1q04mRO6m8dmm2HXrhLRnNFpR04q4Q0Rcq2549J63HsA2PT8Vx1laEzDRKZL87OdsbQmtmideGOtXmXlYu4vIqBm3oJ/sDu+E87lr17EmJRA85+tAnThvYeMMvrk4SZBgbIRHpBs7OdccJl26EX7pLR2n/H4QK0lYu4vIqBm3oJ/sBumZ0F+d998Z+7spGVGsiutdz/wzTDAmQiGTM72xkndEFOpAu31t+xVoDmBg3GYOD2sHibS2mtoAv3oVUZFSATyZj1Llrhrbo+wQty/lNWhqz09LAXbq2/Y60AzTKWMRi4qRetFXQjz8nHk++1RlwOvWxb4v2uE8mY9a6W5K167GK1v7n+AAAI8klEQVRdyaoVoFnGMg5nlZAuVsx0SKQXtN7VkrOuvNrVM07sEssUxXA91JuamxNq0UvdGLjJMRJZ5q03IwzutxLanzuRKYheF8uF+84Vj/UK0DMLkvHM29X45y8yehzLDRriw1IJOUKi3QD1dLZbtu049hw8GPZWnSWUxIX7dywZnQTIdgjR83gOHseHgZscIdFugJE626lfd0y+Fj+7JEPzVp2zHYwR6a5p9kWpWLL1ZK/nsNYdO5ZKPCrSruROZPYy72j1c7X+auYWZ14XbZyhZEw6hj55DPPHpGFgdndgj7XWzZIWA7enuWmfSbMHPyNlgqH1V9Zd46PnrumGC1Jw1rImnGzv/XO9F+Vomyf7AQM3eV7UTHB0Ep55v7v+ytkO8dF/15Qf94Xa7X1ojMLATZ6nJxNU669LrzwFALPueFgxZTR0Qwe/XlwZuMnzdGeCg5O7vmfW7Tzh5of78eLKwE2eFy4TjLbTjJ8DgxNFWlXrt4srpwOSbyU6BZGsY8fmyU7GjJt8y0k7zVBkTts82W4M3B7ktjncdnHSTjMUnt4+NH4qabFU4lF2zuFm21QyEktavTHjJsNxgUQAV/gZgyWt3hi4yVBcINHNyguYly8SLGn1xlIJGYo7nARY3bSKnQ39xTOBW1EOYOXTCzFtegEmTRqMadMLsPLphVCUA7ael59wh5NuVl7A2NnQfzwRuGtqqjGveCK21TUi58bFGHz3OuTcuBjb6hoxr3giamqq7T5FX/DjRr1aA7FWX8B4l+M/rg/cinIAi0vnImfyfeg7tgipuXkQSclIzc1D37FFyJl8HxaXzmXmbTI/LJDQCtJaJQorL2B6LxKc6eMtrg/cr77+DDIKJiD9jPM0f55+xnnIKCjEa2/80eIzs4ddc7j1btTrZqFBWqtEYfUFTO9FgjVwb3F94N64aR0yCgojHpNRMAEbN62z6IzsZ/Uc7kS3HXMDrSCtVaKw8gKm9yLBGrj3uD5wNzfVI6Xf6RGPSel7Go431Vt0Rv7jhwUSoUH6v1f9oVeJ4o9vvYXVFeWWXcD0XiRYA/ce18/jzsjOQdvRL5Gamxf2mLaGr5CZnWPhWfmL1xdIaLUTPXdFFaYNTetRovh2bge+9019F7BE53XrXQY+68qr2QrVg1wfuC8dNwXbaiuROrYo7DHNtRW4dNwUC8/KX7y+QEKrjjyjIAntHW0AugNnkujA49vb8Pj2loivZ8QFTO9dzq2//U3YGvg9N/zUs4t2vM71gXvStbNRXTwR6fkjNQcoWz7bi+baSlxXusGGsyO3C5fZPjA2sPHtoss6uja+fff/ZuPOijaIgVeYvlJS711O3/SDePW6rB6PqVn3sRMn2JrApVxf487LOxslxctRv/4hNGxejdYjCmR7G1qPKGjYvBr16x9CSfFy5OWdbfepkgtFriMHtjsLplXHNmMq3pblKyErKyN+3TH5Wsy+OEPz3KcOScJz1VUcsHQp1wduABgxYjweLd2A0f374WjZAhxaOhVHyxZgdP9+eLR0A0aMGG/3KZILRZ0tMyYNq3e24vOmjq7HtAZi7ZiKF+3cIdswsyCJA5Yu5fpSiSov72zcdusi3HbrIrtPhVwmXIMmPXXkGy5IwVnLmnCyvefP1Dq2XU23Ip270tiBlz5sxZ452QA4YOlGngncFFh8Y2cfbrcK18VP/2yZ/LADtHbtSh7p3NOSgVsuStUcsGSt2x2ElNLwFz3nnOFy6dI3DX9dioyBO3bqhsFVM1Jwxdo27HnmWcOyztDNiJXGDgx9qtXQ90j0nLoed8C5ESAKC2uklJdEO84TNW6ieJm5OMWJTbf80JrADxi4ybfM7OLnxKZbfmhN4BcM3ORbZmbETsxs/dCawC84OEm+FG5hjREzLJy6K7nXWxP4CQM3+ZKejDjeGRaxZLZWzuLwemsCP2HgJt8xOyNmZktmY+D2CLs2UHAjszNiZrZkNgZuD+Ecbn2YEZPbMXCT7zAjJrfjdEAiIpdh4CYichkGbiIil2HgJiJyGQZuIiKXYeAmInIZBm4PYB9uIn9h4CYichkGbiIil2HgJiJyGQZuIiKXYeAmInIZBm4iIpdh4CYichkGbpfjBgpE/sPA7QFcfEPkLwzcREQuw8BNROQyDNxERC7DwE1E5DIM3ERELsPATUTkMkJKafyLCvEVgIOGvzARkbedJaU8LdpBpgRuIiIyD0slREQuw8BNROQyDNzkSEKIdiHEB0FfZ8fxGjlCiDnGn13X6wshxGNCiH8JIXYJIS42672IgqXYfQJEYTRLKS9M8DVyAMwB8EQsTxJCJEsp23Uc+iMA53R+fRfAk53/JTIVM25yDSFEshDiESHEjs4M97bOx7OFEFVCiPeFELVCiEmdT/kNgPzOjP0RIcSlQog3gl7vcSHETZ3fHxBCLBZCvA/gJ0KIfCHEW0KIGiHE34QQQzROaRKAZ2XAOwByhBB5pv4lEIEZNzlXhhDig87v/y2lnALgFgBHpZQjhRDpALYKISoAHAIwRUrZIIToD+AdIcRrABYAGKpm7kKIS6O8Z52U8uLOY6sA3C6l/FgI8V0EsvbxIcef0fneqk87H1Pi/DMT6cLATU6lVSqZAGCYEOL6zv/vh0CZ4lMAvxZCjAXQgUDwHBDHe/4ZCGTwAEYDeFEIof4sPY7XIzIFAze5iQAwV0pZ3uPBQLnjNAAjpJStQogDAE7ReH4bepYHQ4851vnfJAD1OmrsnwEYHPT/3+x8jMhUrHGTm5QD+LkQIhUAhBDfEUJkIZB5f9kZtC8DcFbn8Y0A+gQ9/yCA84UQ6UKIHACXa72JlLIBwL+FED/pfB8hhBiucehrAIo6f/49BMo4LJOQ6Zhxk5v8L4CzAbwvAjWMrwBMBrAWwOtCiFoA7wHYBwBSyjohxFYhxG4Ab0op7xFCvABgN4B/A/hHhPeaDuBJIcT9AFIBlAHYGXLMXwBcDeBfAI4DuNmQPyVRFFzyTkTkMiyVEBG5DAM3EZHLMHATEbkMAzcRkcswcBMRuQwDNxGRyzBwExG5DAM3EZHL/H93fVZL08TjngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_2d_separator(red, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train) \n",
    "plt.xlabel(\"Feature 0\") \n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio\n",
    "Resuelva el problema del perceptron con 2 neuronas en la capa oculta. Considere utilizar una función de activación apropiada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "Y = np.array([[-1], [1], [1],[-1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "red_xor = MLPClassifier(hidden_layer_sizes=(2,2),\n",
    "                        activation='tanh',\n",
    "                        solver='sgd',\n",
    "                        max_iter=1500, verbose=1)\n",
    "#lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71897916\n",
      "Iteration 2, loss = 0.71889496\n",
      "Iteration 3, loss = 0.71877501\n",
      "Iteration 4, loss = 0.71862301\n",
      "Iteration 5, loss = 0.71844235\n",
      "Iteration 6, loss = 0.71823607\n",
      "Iteration 7, loss = 0.71800696\n",
      "Iteration 8, loss = 0.71775749\n",
      "Iteration 9, loss = 0.71748996\n",
      "Iteration 10, loss = 0.71720639\n",
      "Iteration 11, loss = 0.71690864\n",
      "Iteration 12, loss = 0.71659837\n",
      "Iteration 13, loss = 0.71627710\n",
      "Iteration 14, loss = 0.71594617\n",
      "Iteration 15, loss = 0.71560680\n",
      "Iteration 16, loss = 0.71526010\n",
      "Iteration 17, loss = 0.71490707\n",
      "Iteration 18, loss = 0.71454858\n",
      "Iteration 19, loss = 0.71418544\n",
      "Iteration 20, loss = 0.71381838\n",
      "Iteration 21, loss = 0.71344803\n",
      "Iteration 22, loss = 0.71307499\n",
      "Iteration 23, loss = 0.71269978\n",
      "Iteration 24, loss = 0.71232285\n",
      "Iteration 25, loss = 0.71194464\n",
      "Iteration 26, loss = 0.71156552\n",
      "Iteration 27, loss = 0.71118583\n",
      "Iteration 28, loss = 0.71080586\n",
      "Iteration 29, loss = 0.71042589\n",
      "Iteration 30, loss = 0.71004616\n",
      "Iteration 31, loss = 0.70966688\n",
      "Iteration 32, loss = 0.70928825\n",
      "Iteration 33, loss = 0.70891044\n",
      "Iteration 34, loss = 0.70853359\n",
      "Iteration 35, loss = 0.70815784\n",
      "Iteration 36, loss = 0.70778331\n",
      "Iteration 37, loss = 0.70741011\n",
      "Iteration 38, loss = 0.70703833\n",
      "Iteration 39, loss = 0.70666805\n",
      "Iteration 40, loss = 0.70629934\n",
      "Iteration 41, loss = 0.70593227\n",
      "Iteration 42, loss = 0.70556689\n",
      "Iteration 43, loss = 0.70520325\n",
      "Iteration 44, loss = 0.70484139\n",
      "Iteration 45, loss = 0.70448134\n",
      "Iteration 46, loss = 0.70412314\n",
      "Iteration 47, loss = 0.70376681\n",
      "Iteration 48, loss = 0.70341236\n",
      "Iteration 49, loss = 0.70305983\n",
      "Iteration 50, loss = 0.70270922\n",
      "Iteration 51, loss = 0.70236053\n",
      "Iteration 52, loss = 0.70201379\n",
      "Iteration 53, loss = 0.70166899\n",
      "Iteration 54, loss = 0.70132614\n",
      "Iteration 55, loss = 0.70098523\n",
      "Iteration 56, loss = 0.70064627\n",
      "Iteration 57, loss = 0.70030926\n",
      "Iteration 58, loss = 0.69997419\n",
      "Iteration 59, loss = 0.69964105\n",
      "Iteration 60, loss = 0.69930985\n",
      "Iteration 61, loss = 0.69898057\n",
      "Iteration 62, loss = 0.69865320\n",
      "Iteration 63, loss = 0.69832773\n",
      "Iteration 64, loss = 0.69800417\n",
      "Iteration 65, loss = 0.69768249\n",
      "Iteration 66, loss = 0.69736268\n",
      "Iteration 67, loss = 0.69704474\n",
      "Iteration 68, loss = 0.69672865\n",
      "Iteration 69, loss = 0.69641440\n",
      "Iteration 70, loss = 0.69610198\n",
      "Iteration 71, loss = 0.69579137\n",
      "Iteration 72, loss = 0.69548257\n",
      "Iteration 73, loss = 0.69517555\n",
      "Iteration 74, loss = 0.69487031\n",
      "Iteration 75, loss = 0.69456683\n",
      "Iteration 76, loss = 0.69426510\n",
      "Iteration 77, loss = 0.69396510\n",
      "Iteration 78, loss = 0.69366682\n",
      "Iteration 79, loss = 0.69337025\n",
      "Iteration 80, loss = 0.69307537\n",
      "Iteration 81, loss = 0.69278217\n",
      "Iteration 82, loss = 0.69249064\n",
      "Iteration 83, loss = 0.69220076\n",
      "Iteration 84, loss = 0.69191251\n",
      "Iteration 85, loss = 0.69162588\n",
      "Iteration 86, loss = 0.69134087\n",
      "Iteration 87, loss = 0.69105744\n",
      "Iteration 88, loss = 0.69077560\n",
      "Iteration 89, loss = 0.69049532\n",
      "Iteration 90, loss = 0.69021660\n",
      "Iteration 91, loss = 0.68993941\n",
      "Iteration 92, loss = 0.68966375\n",
      "Iteration 93, loss = 0.68938960\n",
      "Iteration 94, loss = 0.68911694\n",
      "Iteration 95, loss = 0.68884577\n",
      "Iteration 96, loss = 0.68857607\n",
      "Iteration 97, loss = 0.68830782\n",
      "Iteration 98, loss = 0.68804102\n",
      "Iteration 99, loss = 0.68777564\n",
      "Iteration 100, loss = 0.68751168\n",
      "Iteration 101, loss = 0.68724912\n",
      "Iteration 102, loss = 0.68698796\n",
      "Iteration 103, loss = 0.68672816\n",
      "Iteration 104, loss = 0.68646973\n",
      "Iteration 105, loss = 0.68621265\n",
      "Iteration 106, loss = 0.68595691\n",
      "Iteration 107, loss = 0.68570249\n",
      "Iteration 108, loss = 0.68544938\n",
      "Iteration 109, loss = 0.68519757\n",
      "Iteration 110, loss = 0.68494705\n",
      "Iteration 111, loss = 0.68469780\n",
      "Iteration 112, loss = 0.68444981\n",
      "Iteration 113, loss = 0.68420306\n",
      "Iteration 114, loss = 0.68395756\n",
      "Iteration 115, loss = 0.68371327\n",
      "Iteration 116, loss = 0.68347020\n",
      "Iteration 117, loss = 0.68322833\n",
      "Iteration 118, loss = 0.68298765\n",
      "Iteration 119, loss = 0.68274814\n",
      "Iteration 120, loss = 0.68250979\n",
      "Iteration 121, loss = 0.68227260\n",
      "Iteration 122, loss = 0.68203654\n",
      "Iteration 123, loss = 0.68180162\n",
      "Iteration 124, loss = 0.68156781\n",
      "Iteration 125, loss = 0.68133510\n",
      "Iteration 126, loss = 0.68110349\n",
      "Iteration 127, loss = 0.68087296\n",
      "Iteration 128, loss = 0.68064351\n",
      "Iteration 129, loss = 0.68041511\n",
      "Iteration 130, loss = 0.68018776\n",
      "Iteration 131, loss = 0.67996145\n",
      "Iteration 132, loss = 0.67973617\n",
      "Iteration 133, loss = 0.67951190\n",
      "Iteration 134, loss = 0.67928864\n",
      "Iteration 135, loss = 0.67906637\n",
      "Iteration 136, loss = 0.67884508\n",
      "Iteration 137, loss = 0.67862477\n",
      "Iteration 138, loss = 0.67840542\n",
      "Iteration 139, loss = 0.67818702\n",
      "Iteration 140, loss = 0.67796957\n",
      "Iteration 141, loss = 0.67775304\n",
      "Iteration 142, loss = 0.67753744\n",
      "Iteration 143, loss = 0.67732274\n",
      "Iteration 144, loss = 0.67710895\n",
      "Iteration 145, loss = 0.67689605\n",
      "Iteration 146, loss = 0.67668402\n",
      "Iteration 147, loss = 0.67647287\n",
      "Iteration 148, loss = 0.67626258\n",
      "Iteration 149, loss = 0.67605314\n",
      "Iteration 150, loss = 0.67584454\n",
      "Iteration 151, loss = 0.67563678\n",
      "Iteration 152, loss = 0.67542983\n",
      "Iteration 153, loss = 0.67522370\n",
      "Iteration 154, loss = 0.67501837\n",
      "Iteration 155, loss = 0.67481383\n",
      "Iteration 156, loss = 0.67461008\n",
      "Iteration 157, loss = 0.67440711\n",
      "Iteration 158, loss = 0.67420489\n",
      "Iteration 159, loss = 0.67400344\n",
      "Iteration 160, loss = 0.67380273\n",
      "Iteration 161, loss = 0.67360277\n",
      "Iteration 162, loss = 0.67340353\n",
      "Iteration 163, loss = 0.67320501\n",
      "Iteration 164, loss = 0.67300721\n",
      "Iteration 165, loss = 0.67281011\n",
      "Iteration 166, loss = 0.67261370\n",
      "Iteration 167, loss = 0.67241798\n",
      "Iteration 168, loss = 0.67222294\n",
      "Iteration 169, loss = 0.67202856\n",
      "Iteration 170, loss = 0.67183485\n",
      "Iteration 171, loss = 0.67164179\n",
      "Iteration 172, loss = 0.67144937\n",
      "Iteration 173, loss = 0.67125758\n",
      "Iteration 174, loss = 0.67106643\n",
      "Iteration 175, loss = 0.67087589\n",
      "Iteration 176, loss = 0.67068597\n",
      "Iteration 177, loss = 0.67049665\n",
      "Iteration 178, loss = 0.67030792\n",
      "Iteration 179, loss = 0.67011978\n",
      "Iteration 180, loss = 0.66993222\n",
      "Iteration 181, loss = 0.66974523\n",
      "Iteration 182, loss = 0.66955881\n",
      "Iteration 183, loss = 0.66937294\n",
      "Iteration 184, loss = 0.66918762\n",
      "Iteration 185, loss = 0.66900284\n",
      "Iteration 186, loss = 0.66881859\n",
      "Iteration 187, loss = 0.66863487\n",
      "Iteration 188, loss = 0.66845167\n",
      "Iteration 189, loss = 0.66826898\n",
      "Iteration 190, loss = 0.66808679\n",
      "Iteration 191, loss = 0.66790510\n",
      "Iteration 192, loss = 0.66772390\n",
      "Iteration 193, loss = 0.66754318\n",
      "Iteration 194, loss = 0.66736294\n",
      "Iteration 195, loss = 0.66718316\n",
      "Iteration 196, loss = 0.66700385\n",
      "Iteration 197, loss = 0.66682499\n",
      "Iteration 198, loss = 0.66664658\n",
      "Iteration 199, loss = 0.66646860\n",
      "Iteration 200, loss = 0.66629106\n",
      "Iteration 201, loss = 0.66611395\n",
      "Iteration 202, loss = 0.66593726\n",
      "Iteration 203, loss = 0.66576098\n",
      "Iteration 204, loss = 0.66558511\n",
      "Iteration 205, loss = 0.66540964\n",
      "Iteration 206, loss = 0.66523457\n",
      "Iteration 207, loss = 0.66505988\n",
      "Iteration 208, loss = 0.66488557\n",
      "Iteration 209, loss = 0.66471164\n",
      "Iteration 210, loss = 0.66453808\n",
      "Iteration 211, loss = 0.66436488\n",
      "Iteration 212, loss = 0.66419203\n",
      "Iteration 213, loss = 0.66401954\n",
      "Iteration 214, loss = 0.66384739\n",
      "Iteration 215, loss = 0.66367558\n",
      "Iteration 216, loss = 0.66350410\n",
      "Iteration 217, loss = 0.66333294\n",
      "Iteration 218, loss = 0.66316211\n",
      "Iteration 219, loss = 0.66299159\n",
      "Iteration 220, loss = 0.66282138\n",
      "Iteration 221, loss = 0.66265147\n",
      "Iteration 222, loss = 0.66248186\n",
      "Iteration 223, loss = 0.66231254\n",
      "Iteration 224, loss = 0.66214350\n",
      "Iteration 225, loss = 0.66197475\n",
      "Iteration 226, loss = 0.66180627\n",
      "Iteration 227, loss = 0.66163806\n",
      "Iteration 228, loss = 0.66147011\n",
      "Iteration 229, loss = 0.66130242\n",
      "Iteration 230, loss = 0.66113499\n",
      "Iteration 231, loss = 0.66096780\n",
      "Iteration 232, loss = 0.66080085\n",
      "Iteration 233, loss = 0.66063415\n",
      "Iteration 234, loss = 0.66046767\n",
      "Iteration 235, loss = 0.66030142\n",
      "Iteration 236, loss = 0.66013539\n",
      "Iteration 237, loss = 0.65996958\n",
      "Iteration 238, loss = 0.65980398\n",
      "Iteration 239, loss = 0.65963858\n",
      "Iteration 240, loss = 0.65947339\n",
      "Iteration 241, loss = 0.65930839\n",
      "Iteration 242, loss = 0.65914359\n",
      "Iteration 243, loss = 0.65897897\n",
      "Iteration 244, loss = 0.65881454\n",
      "Iteration 245, loss = 0.65865028\n",
      "Iteration 246, loss = 0.65848619\n",
      "Iteration 247, loss = 0.65832228\n",
      "Iteration 248, loss = 0.65815852\n",
      "Iteration 249, loss = 0.65799493\n",
      "Iteration 250, loss = 0.65783149\n",
      "Iteration 251, loss = 0.65766820\n",
      "Iteration 252, loss = 0.65750506\n",
      "Iteration 253, loss = 0.65734205\n",
      "Iteration 254, loss = 0.65717919\n",
      "Iteration 255, loss = 0.65701645\n",
      "Iteration 256, loss = 0.65685385\n",
      "Iteration 257, loss = 0.65669136\n",
      "Iteration 258, loss = 0.65652900\n",
      "Iteration 259, loss = 0.65636675\n",
      "Iteration 260, loss = 0.65620461\n",
      "Iteration 261, loss = 0.65604258\n",
      "Iteration 262, loss = 0.65588066\n",
      "Iteration 263, loss = 0.65571883\n",
      "Iteration 264, loss = 0.65555710\n",
      "Iteration 265, loss = 0.65539545\n",
      "Iteration 266, loss = 0.65523390\n",
      "Iteration 267, loss = 0.65507243\n",
      "Iteration 268, loss = 0.65491104\n",
      "Iteration 269, loss = 0.65474972\n",
      "Iteration 270, loss = 0.65458847\n",
      "Iteration 271, loss = 0.65442729\n",
      "Iteration 272, loss = 0.65426618\n",
      "Iteration 273, loss = 0.65410513\n",
      "Iteration 274, loss = 0.65394413\n",
      "Iteration 275, loss = 0.65378319\n",
      "Iteration 276, loss = 0.65362230\n",
      "Iteration 277, loss = 0.65346145\n",
      "Iteration 278, loss = 0.65330065\n",
      "Iteration 279, loss = 0.65313988\n",
      "Iteration 280, loss = 0.65297915\n",
      "Iteration 281, loss = 0.65281845\n",
      "Iteration 282, loss = 0.65265779\n",
      "Iteration 283, loss = 0.65249714\n",
      "Iteration 284, loss = 0.65233652\n",
      "Iteration 285, loss = 0.65217592\n",
      "Iteration 286, loss = 0.65201534\n",
      "Iteration 287, loss = 0.65185477\n",
      "Iteration 288, loss = 0.65169420\n",
      "Iteration 289, loss = 0.65153365\n",
      "Iteration 290, loss = 0.65137309\n",
      "Iteration 291, loss = 0.65121254\n",
      "Iteration 292, loss = 0.65105199\n",
      "Iteration 293, loss = 0.65089143\n",
      "Iteration 294, loss = 0.65073086\n",
      "Iteration 295, loss = 0.65057027\n",
      "Iteration 296, loss = 0.65040968\n",
      "Iteration 297, loss = 0.65024906\n",
      "Iteration 298, loss = 0.65008843\n",
      "Iteration 299, loss = 0.64992777\n",
      "Iteration 300, loss = 0.64976709\n",
      "Iteration 301, loss = 0.64960638\n",
      "Iteration 302, loss = 0.64944564\n",
      "Iteration 303, loss = 0.64928486\n",
      "Iteration 304, loss = 0.64912405\n",
      "Iteration 305, loss = 0.64896320\n",
      "Iteration 306, loss = 0.64880230\n",
      "Iteration 307, loss = 0.64864137\n",
      "Iteration 308, loss = 0.64848038\n",
      "Iteration 309, loss = 0.64831935\n",
      "Iteration 310, loss = 0.64815826\n",
      "Iteration 311, loss = 0.64799712\n",
      "Iteration 312, loss = 0.64783593\n",
      "Iteration 313, loss = 0.64767467\n",
      "Iteration 314, loss = 0.64751336\n",
      "Iteration 315, loss = 0.64735198\n",
      "Iteration 316, loss = 0.64719053\n",
      "Iteration 317, loss = 0.64702902\n",
      "Iteration 318, loss = 0.64686743\n",
      "Iteration 319, loss = 0.64670578\n",
      "Iteration 320, loss = 0.64654405\n",
      "Iteration 321, loss = 0.64638224\n",
      "Iteration 322, loss = 0.64622036\n",
      "Iteration 323, loss = 0.64605839\n",
      "Iteration 324, loss = 0.64589634\n",
      "Iteration 325, loss = 0.64573421\n",
      "Iteration 326, loss = 0.64557199\n",
      "Iteration 327, loss = 0.64540968\n",
      "Iteration 328, loss = 0.64524728\n",
      "Iteration 329, loss = 0.64508478\n",
      "Iteration 330, loss = 0.64492220\n",
      "Iteration 331, loss = 0.64475952\n",
      "Iteration 332, loss = 0.64459674\n",
      "Iteration 333, loss = 0.64443386\n",
      "Iteration 334, loss = 0.64427087\n",
      "Iteration 335, loss = 0.64410779\n",
      "Iteration 336, loss = 0.64394460\n",
      "Iteration 337, loss = 0.64378131\n",
      "Iteration 338, loss = 0.64361790\n",
      "Iteration 339, loss = 0.64345439\n",
      "Iteration 340, loss = 0.64329077\n",
      "Iteration 341, loss = 0.64312703\n",
      "Iteration 342, loss = 0.64296318\n",
      "Iteration 343, loss = 0.64279921\n",
      "Iteration 344, loss = 0.64263513\n",
      "Iteration 345, loss = 0.64247093\n",
      "Iteration 346, loss = 0.64230660\n",
      "Iteration 347, loss = 0.64214216\n",
      "Iteration 348, loss = 0.64197760\n",
      "Iteration 349, loss = 0.64181291\n",
      "Iteration 350, loss = 0.64164809\n",
      "Iteration 351, loss = 0.64148315\n",
      "Iteration 352, loss = 0.64131808\n",
      "Iteration 353, loss = 0.64115289\n",
      "Iteration 354, loss = 0.64098756\n",
      "Iteration 355, loss = 0.64082210\n",
      "Iteration 356, loss = 0.64065651\n",
      "Iteration 357, loss = 0.64049079\n",
      "Iteration 358, loss = 0.64032493\n",
      "Iteration 359, loss = 0.64015894\n",
      "Iteration 360, loss = 0.63999281\n",
      "Iteration 361, loss = 0.63982654\n",
      "Iteration 362, loss = 0.63966014\n",
      "Iteration 363, loss = 0.63949359\n",
      "Iteration 364, loss = 0.63932691\n",
      "Iteration 365, loss = 0.63916008\n",
      "Iteration 366, loss = 0.63899312\n",
      "Iteration 367, loss = 0.63882601\n",
      "Iteration 368, loss = 0.63865875\n",
      "Iteration 369, loss = 0.63849136\n",
      "Iteration 370, loss = 0.63832382\n",
      "Iteration 371, loss = 0.63815613\n",
      "Iteration 372, loss = 0.63798829\n",
      "Iteration 373, loss = 0.63782031\n",
      "Iteration 374, loss = 0.63765219\n",
      "Iteration 375, loss = 0.63748391\n",
      "Iteration 376, loss = 0.63731548\n",
      "Iteration 377, loss = 0.63714691\n",
      "Iteration 378, loss = 0.63697819\n",
      "Iteration 379, loss = 0.63680931\n",
      "Iteration 380, loss = 0.63664029\n",
      "Iteration 381, loss = 0.63647111\n",
      "Iteration 382, loss = 0.63630178\n",
      "Iteration 383, loss = 0.63613230\n",
      "Iteration 384, loss = 0.63596267\n",
      "Iteration 385, loss = 0.63579288\n",
      "Iteration 386, loss = 0.63562294\n",
      "Iteration 387, loss = 0.63545285\n",
      "Iteration 388, loss = 0.63528260\n",
      "Iteration 389, loss = 0.63511220\n",
      "Iteration 390, loss = 0.63494165\n",
      "Iteration 391, loss = 0.63477094\n",
      "Iteration 392, loss = 0.63460008\n",
      "Iteration 393, loss = 0.63442906\n",
      "Iteration 394, loss = 0.63425788\n",
      "Iteration 395, loss = 0.63408656\n",
      "Iteration 396, loss = 0.63391507\n",
      "Iteration 397, loss = 0.63374343\n",
      "Iteration 398, loss = 0.63357164\n",
      "Iteration 399, loss = 0.63339969\n",
      "Iteration 400, loss = 0.63322759\n",
      "Iteration 401, loss = 0.63305533\n",
      "Iteration 402, loss = 0.63288291\n",
      "Iteration 403, loss = 0.63271034\n",
      "Iteration 404, loss = 0.63253762\n",
      "Iteration 405, loss = 0.63236474\n",
      "Iteration 406, loss = 0.63219170\n",
      "Iteration 407, loss = 0.63201851\n",
      "Iteration 408, loss = 0.63184517\n",
      "Iteration 409, loss = 0.63167167\n",
      "Iteration 410, loss = 0.63149802\n",
      "Iteration 411, loss = 0.63132421\n",
      "Iteration 412, loss = 0.63115025\n",
      "Iteration 413, loss = 0.63097614\n",
      "Iteration 414, loss = 0.63080188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 415, loss = 0.63062746\n",
      "Iteration 416, loss = 0.63045289\n",
      "Iteration 417, loss = 0.63027817\n",
      "Iteration 418, loss = 0.63010329\n",
      "Iteration 419, loss = 0.62992827\n",
      "Iteration 420, loss = 0.62975310\n",
      "Iteration 421, loss = 0.62957777\n",
      "Iteration 422, loss = 0.62940230\n",
      "Iteration 423, loss = 0.62922668\n",
      "Iteration 424, loss = 0.62905091\n",
      "Iteration 425, loss = 0.62887499\n",
      "Iteration 426, loss = 0.62869892\n",
      "Iteration 427, loss = 0.62852271\n",
      "Iteration 428, loss = 0.62834635\n",
      "Iteration 429, loss = 0.62816984\n",
      "Iteration 430, loss = 0.62799319\n",
      "Iteration 431, loss = 0.62781640\n",
      "Iteration 432, loss = 0.62763946\n",
      "Iteration 433, loss = 0.62746238\n",
      "Iteration 434, loss = 0.62728516\n",
      "Iteration 435, loss = 0.62710779\n",
      "Iteration 436, loss = 0.62693029\n",
      "Iteration 437, loss = 0.62675265\n",
      "Iteration 438, loss = 0.62657486\n",
      "Iteration 439, loss = 0.62639694\n",
      "Iteration 440, loss = 0.62621888\n",
      "Iteration 441, loss = 0.62604069\n",
      "Iteration 442, loss = 0.62586236\n",
      "Iteration 443, loss = 0.62568389\n",
      "Iteration 444, loss = 0.62550529\n",
      "Iteration 445, loss = 0.62532656\n",
      "Iteration 446, loss = 0.62514769\n",
      "Iteration 447, loss = 0.62496870\n",
      "Iteration 448, loss = 0.62478957\n",
      "Iteration 449, loss = 0.62461032\n",
      "Iteration 450, loss = 0.62443093\n",
      "Iteration 451, loss = 0.62425142\n",
      "Iteration 452, loss = 0.62407179\n",
      "Iteration 453, loss = 0.62389203\n",
      "Iteration 454, loss = 0.62371214\n",
      "Iteration 455, loss = 0.62353213\n",
      "Iteration 456, loss = 0.62335201\n",
      "Iteration 457, loss = 0.62317176\n",
      "Iteration 458, loss = 0.62299139\n",
      "Iteration 459, loss = 0.62281090\n",
      "Iteration 460, loss = 0.62263029\n",
      "Iteration 461, loss = 0.62244957\n",
      "Iteration 462, loss = 0.62226874\n",
      "Iteration 463, loss = 0.62208779\n",
      "Iteration 464, loss = 0.62190673\n",
      "Iteration 465, loss = 0.62172556\n",
      "Iteration 466, loss = 0.62154427\n",
      "Iteration 467, loss = 0.62136288\n",
      "Iteration 468, loss = 0.62118138\n",
      "Iteration 469, loss = 0.62099978\n",
      "Iteration 470, loss = 0.62081807\n",
      "Iteration 471, loss = 0.62063626\n",
      "Iteration 472, loss = 0.62045434\n",
      "Iteration 473, loss = 0.62027233\n",
      "Iteration 474, loss = 0.62009021\n",
      "Iteration 475, loss = 0.61990800\n",
      "Iteration 476, loss = 0.61972569\n",
      "Iteration 477, loss = 0.61954329\n",
      "Iteration 478, loss = 0.61936079\n",
      "Iteration 479, loss = 0.61917820\n",
      "Iteration 480, loss = 0.61899551\n",
      "Iteration 481, loss = 0.61881274\n",
      "Iteration 482, loss = 0.61862988\n",
      "Iteration 483, loss = 0.61844694\n",
      "Iteration 484, loss = 0.61826390\n",
      "Iteration 485, loss = 0.61808079\n",
      "Iteration 486, loss = 0.61789759\n",
      "Iteration 487, loss = 0.61771431\n",
      "Iteration 488, loss = 0.61753095\n",
      "Iteration 489, loss = 0.61734752\n",
      "Iteration 490, loss = 0.61716400\n",
      "Iteration 491, loss = 0.61698042\n",
      "Iteration 492, loss = 0.61679676\n",
      "Iteration 493, loss = 0.61661302\n",
      "Iteration 494, loss = 0.61642922\n",
      "Iteration 495, loss = 0.61624535\n",
      "Iteration 496, loss = 0.61606141\n",
      "Iteration 497, loss = 0.61587741\n",
      "Iteration 498, loss = 0.61569334\n",
      "Iteration 499, loss = 0.61550921\n",
      "Iteration 500, loss = 0.61532502\n",
      "Iteration 501, loss = 0.61514078\n",
      "Iteration 502, loss = 0.61495647\n",
      "Iteration 503, loss = 0.61477211\n",
      "Iteration 504, loss = 0.61458769\n",
      "Iteration 505, loss = 0.61440322\n",
      "Iteration 506, loss = 0.61421870\n",
      "Iteration 507, loss = 0.61403413\n",
      "Iteration 508, loss = 0.61384952\n",
      "Iteration 509, loss = 0.61366486\n",
      "Iteration 510, loss = 0.61348015\n",
      "Iteration 511, loss = 0.61329540\n",
      "Iteration 512, loss = 0.61311061\n",
      "Iteration 513, loss = 0.61292578\n",
      "Iteration 514, loss = 0.61274091\n",
      "Iteration 515, loss = 0.61255601\n",
      "Iteration 516, loss = 0.61237107\n",
      "Iteration 517, loss = 0.61218610\n",
      "Iteration 518, loss = 0.61200110\n",
      "Iteration 519, loss = 0.61181608\n",
      "Iteration 520, loss = 0.61163102\n",
      "Iteration 521, loss = 0.61144594\n",
      "Iteration 522, loss = 0.61126083\n",
      "Iteration 523, loss = 0.61107570\n",
      "Iteration 524, loss = 0.61089055\n",
      "Iteration 525, loss = 0.61070539\n",
      "Iteration 526, loss = 0.61052020\n",
      "Iteration 527, loss = 0.61033500\n",
      "Iteration 528, loss = 0.61014979\n",
      "Iteration 529, loss = 0.60996456\n",
      "Iteration 530, loss = 0.60977933\n",
      "Iteration 531, loss = 0.60959408\n",
      "Iteration 532, loss = 0.60940883\n",
      "Iteration 533, loss = 0.60922358\n",
      "Iteration 534, loss = 0.60903832\n",
      "Iteration 535, loss = 0.60885306\n",
      "Iteration 536, loss = 0.60866780\n",
      "Iteration 537, loss = 0.60848254\n",
      "Iteration 538, loss = 0.60829728\n",
      "Iteration 539, loss = 0.60811204\n",
      "Iteration 540, loss = 0.60792679\n",
      "Iteration 541, loss = 0.60774156\n",
      "Iteration 542, loss = 0.60755634\n",
      "Iteration 543, loss = 0.60737113\n",
      "Iteration 544, loss = 0.60718593\n",
      "Iteration 545, loss = 0.60700075\n",
      "Iteration 546, loss = 0.60681559\n",
      "Iteration 547, loss = 0.60663045\n",
      "Iteration 548, loss = 0.60644533\n",
      "Iteration 549, loss = 0.60626023\n",
      "Iteration 550, loss = 0.60607515\n",
      "Iteration 551, loss = 0.60589010\n",
      "Iteration 552, loss = 0.60570508\n",
      "Iteration 553, loss = 0.60552009\n",
      "Iteration 554, loss = 0.60533513\n",
      "Iteration 555, loss = 0.60515020\n",
      "Iteration 556, loss = 0.60496531\n",
      "Iteration 557, loss = 0.60478046\n",
      "Iteration 558, loss = 0.60459564\n",
      "Iteration 559, loss = 0.60441086\n",
      "Iteration 560, loss = 0.60422613\n",
      "Iteration 561, loss = 0.60404143\n",
      "Iteration 562, loss = 0.60385679\n",
      "Iteration 563, loss = 0.60367218\n",
      "Iteration 564, loss = 0.60348763\n",
      "Iteration 565, loss = 0.60330313\n",
      "Iteration 566, loss = 0.60311868\n",
      "Iteration 567, loss = 0.60293428\n",
      "Iteration 568, loss = 0.60274994\n",
      "Iteration 569, loss = 0.60256565\n",
      "Iteration 570, loss = 0.60238142\n",
      "Iteration 571, loss = 0.60219725\n",
      "Iteration 572, loss = 0.60201314\n",
      "Iteration 573, loss = 0.60182910\n",
      "Iteration 574, loss = 0.60164512\n",
      "Iteration 575, loss = 0.60146121\n",
      "Iteration 576, loss = 0.60127736\n",
      "Iteration 577, loss = 0.60109359\n",
      "Iteration 578, loss = 0.60090988\n",
      "Iteration 579, loss = 0.60072625\n",
      "Iteration 580, loss = 0.60054270\n",
      "Iteration 581, loss = 0.60035922\n",
      "Iteration 582, loss = 0.60017581\n",
      "Iteration 583, loss = 0.59999249\n",
      "Iteration 584, loss = 0.59980925\n",
      "Iteration 585, loss = 0.59962608\n",
      "Iteration 586, loss = 0.59944301\n",
      "Iteration 587, loss = 0.59926002\n",
      "Iteration 588, loss = 0.59907711\n",
      "Iteration 589, loss = 0.59889429\n",
      "Iteration 590, loss = 0.59871157\n",
      "Iteration 591, loss = 0.59852893\n",
      "Iteration 592, loss = 0.59834639\n",
      "Iteration 593, loss = 0.59816394\n",
      "Iteration 594, loss = 0.59798159\n",
      "Iteration 595, loss = 0.59779934\n",
      "Iteration 596, loss = 0.59761718\n",
      "Iteration 597, loss = 0.59743512\n",
      "Iteration 598, loss = 0.59725317\n",
      "Iteration 599, loss = 0.59707132\n",
      "Iteration 600, loss = 0.59688958\n",
      "Iteration 601, loss = 0.59670794\n",
      "Iteration 602, loss = 0.59652640\n",
      "Iteration 603, loss = 0.59634498\n",
      "Iteration 604, loss = 0.59616367\n",
      "Iteration 605, loss = 0.59598247\n",
      "Iteration 606, loss = 0.59580138\n",
      "Iteration 607, loss = 0.59562041\n",
      "Iteration 608, loss = 0.59543955\n",
      "Iteration 609, loss = 0.59525881\n",
      "Iteration 610, loss = 0.59507819\n",
      "Iteration 611, loss = 0.59489769\n",
      "Iteration 612, loss = 0.59471731\n",
      "Iteration 613, loss = 0.59453705\n",
      "Iteration 614, loss = 0.59435692\n",
      "Iteration 615, loss = 0.59417691\n",
      "Iteration 616, loss = 0.59399703\n",
      "Iteration 617, loss = 0.59381728\n",
      "Iteration 618, loss = 0.59363765\n",
      "Iteration 619, loss = 0.59345816\n",
      "Iteration 620, loss = 0.59327880\n",
      "Iteration 621, loss = 0.59309957\n",
      "Iteration 622, loss = 0.59292047\n",
      "Iteration 623, loss = 0.59274151\n",
      "Iteration 624, loss = 0.59256269\n",
      "Iteration 625, loss = 0.59238400\n",
      "Iteration 626, loss = 0.59220546\n",
      "Iteration 627, loss = 0.59202705\n",
      "Iteration 628, loss = 0.59184879\n",
      "Iteration 629, loss = 0.59167066\n",
      "Iteration 630, loss = 0.59149269\n",
      "Iteration 631, loss = 0.59131485\n",
      "Iteration 632, loss = 0.59113716\n",
      "Iteration 633, loss = 0.59095962\n",
      "Iteration 634, loss = 0.59078223\n",
      "Iteration 635, loss = 0.59060499\n",
      "Iteration 636, loss = 0.59042789\n",
      "Iteration 637, loss = 0.59025095\n",
      "Iteration 638, loss = 0.59007416\n",
      "Iteration 639, loss = 0.58989753\n",
      "Iteration 640, loss = 0.58972105\n",
      "Iteration 641, loss = 0.58954472\n",
      "Iteration 642, loss = 0.58936855\n",
      "Iteration 643, loss = 0.58919254\n",
      "Iteration 644, loss = 0.58901669\n",
      "Iteration 645, loss = 0.58884100\n",
      "Iteration 646, loss = 0.58866547\n",
      "Iteration 647, loss = 0.58849010\n",
      "Iteration 648, loss = 0.58831489\n",
      "Iteration 649, loss = 0.58813985\n",
      "Iteration 650, loss = 0.58796497\n",
      "Iteration 651, loss = 0.58779026\n",
      "Iteration 652, loss = 0.58761571\n",
      "Iteration 653, loss = 0.58744133\n",
      "Iteration 654, loss = 0.58726712\n",
      "Iteration 655, loss = 0.58709308\n",
      "Iteration 656, loss = 0.58691921\n",
      "Iteration 657, loss = 0.58674551\n",
      "Iteration 658, loss = 0.58657198\n",
      "Iteration 659, loss = 0.58639863\n",
      "Iteration 660, loss = 0.58622544\n",
      "Iteration 661, loss = 0.58605244\n",
      "Iteration 662, loss = 0.58587960\n",
      "Iteration 663, loss = 0.58570695\n",
      "Iteration 664, loss = 0.58553447\n",
      "Iteration 665, loss = 0.58536217\n",
      "Iteration 666, loss = 0.58519004\n",
      "Iteration 667, loss = 0.58501810\n",
      "Iteration 668, loss = 0.58484633\n",
      "Iteration 669, loss = 0.58467475\n",
      "Iteration 670, loss = 0.58450335\n",
      "Iteration 671, loss = 0.58433213\n",
      "Iteration 672, loss = 0.58416109\n",
      "Iteration 673, loss = 0.58399023\n",
      "Iteration 674, loss = 0.58381956\n",
      "Iteration 675, loss = 0.58364908\n",
      "Iteration 676, loss = 0.58347878\n",
      "Iteration 677, loss = 0.58330867\n",
      "Iteration 678, loss = 0.58313874\n",
      "Iteration 679, loss = 0.58296900\n",
      "Iteration 680, loss = 0.58279945\n",
      "Iteration 681, loss = 0.58263009\n",
      "Iteration 682, loss = 0.58246092\n",
      "Iteration 683, loss = 0.58229194\n",
      "Iteration 684, loss = 0.58212314\n",
      "Iteration 685, loss = 0.58195454\n",
      "Iteration 686, loss = 0.58178614\n",
      "Iteration 687, loss = 0.58161792\n",
      "Iteration 688, loss = 0.58144990\n",
      "Iteration 689, loss = 0.58128207\n",
      "Iteration 690, loss = 0.58111443\n",
      "Iteration 691, loss = 0.58094699\n",
      "Iteration 692, loss = 0.58077974\n",
      "Iteration 693, loss = 0.58061269\n",
      "Iteration 694, loss = 0.58044584\n",
      "Iteration 695, loss = 0.58027918\n",
      "Iteration 696, loss = 0.58011272\n",
      "Iteration 697, loss = 0.57994646\n",
      "Iteration 698, loss = 0.57978039\n",
      "Iteration 699, loss = 0.57961452\n",
      "Iteration 700, loss = 0.57944886\n",
      "Iteration 701, loss = 0.57928339\n",
      "Iteration 702, loss = 0.57911812\n",
      "Iteration 703, loss = 0.57895305\n",
      "Iteration 704, loss = 0.57878818\n",
      "Iteration 705, loss = 0.57862351\n",
      "Iteration 706, loss = 0.57845904\n",
      "Iteration 707, loss = 0.57829478\n",
      "Iteration 708, loss = 0.57813072\n",
      "Iteration 709, loss = 0.57796685\n",
      "Iteration 710, loss = 0.57780320\n",
      "Iteration 711, loss = 0.57763974\n",
      "Iteration 712, loss = 0.57747649\n",
      "Iteration 713, loss = 0.57731344\n",
      "Iteration 714, loss = 0.57715060\n",
      "Iteration 715, loss = 0.57698796\n",
      "Iteration 716, loss = 0.57682552\n",
      "Iteration 717, loss = 0.57666329\n",
      "Iteration 718, loss = 0.57650127\n",
      "Iteration 719, loss = 0.57633945\n",
      "Iteration 720, loss = 0.57617783\n",
      "Iteration 721, loss = 0.57601642\n",
      "Iteration 722, loss = 0.57585522\n",
      "Iteration 723, loss = 0.57569423\n",
      "Iteration 724, loss = 0.57553344\n",
      "Iteration 725, loss = 0.57537286\n",
      "Iteration 726, loss = 0.57521248\n",
      "Iteration 727, loss = 0.57505231\n",
      "Iteration 728, loss = 0.57489235\n",
      "Iteration 729, loss = 0.57473260\n",
      "Iteration 730, loss = 0.57457305\n",
      "Iteration 731, loss = 0.57441372\n",
      "Iteration 732, loss = 0.57425459\n",
      "Iteration 733, loss = 0.57409567\n",
      "Iteration 734, loss = 0.57393696\n",
      "Iteration 735, loss = 0.57377845\n",
      "Iteration 736, loss = 0.57362016\n",
      "Iteration 737, loss = 0.57346207\n",
      "Iteration 738, loss = 0.57330419\n",
      "Iteration 739, loss = 0.57314653\n",
      "Iteration 740, loss = 0.57298907\n",
      "Iteration 741, loss = 0.57283182\n",
      "Iteration 742, loss = 0.57267478\n",
      "Iteration 743, loss = 0.57251795\n",
      "Iteration 744, loss = 0.57236133\n",
      "Iteration 745, loss = 0.57220491\n",
      "Iteration 746, loss = 0.57204871\n",
      "Iteration 747, loss = 0.57189272\n",
      "Iteration 748, loss = 0.57173694\n",
      "Iteration 749, loss = 0.57158136\n",
      "Iteration 750, loss = 0.57142600\n",
      "Iteration 751, loss = 0.57127085\n",
      "Iteration 752, loss = 0.57111590\n",
      "Iteration 753, loss = 0.57096117\n",
      "Iteration 754, loss = 0.57080664\n",
      "Iteration 755, loss = 0.57065233\n",
      "Iteration 756, loss = 0.57049823\n",
      "Iteration 757, loss = 0.57034433\n",
      "Iteration 758, loss = 0.57019065\n",
      "Iteration 759, loss = 0.57003717\n",
      "Iteration 760, loss = 0.56988391\n",
      "Iteration 761, loss = 0.56973085\n",
      "Iteration 762, loss = 0.56957800\n",
      "Iteration 763, loss = 0.56942537\n",
      "Iteration 764, loss = 0.56927294\n",
      "Iteration 765, loss = 0.56912072\n",
      "Iteration 766, loss = 0.56896871\n",
      "Iteration 767, loss = 0.56881692\n",
      "Iteration 768, loss = 0.56866533\n",
      "Iteration 769, loss = 0.56851395\n",
      "Iteration 770, loss = 0.56836277\n",
      "Iteration 771, loss = 0.56821181\n",
      "Iteration 772, loss = 0.56806106\n",
      "Iteration 773, loss = 0.56791051\n",
      "Iteration 774, loss = 0.56776018\n",
      "Iteration 775, loss = 0.56761005\n",
      "Iteration 776, loss = 0.56746013\n",
      "Iteration 777, loss = 0.56731042\n",
      "Iteration 778, loss = 0.56716091\n",
      "Iteration 779, loss = 0.56701162\n",
      "Iteration 780, loss = 0.56686253\n",
      "Iteration 781, loss = 0.56671365\n",
      "Iteration 782, loss = 0.56656498\n",
      "Iteration 783, loss = 0.56641651\n",
      "Iteration 784, loss = 0.56626825\n",
      "Iteration 785, loss = 0.56612020\n",
      "Iteration 786, loss = 0.56597236\n",
      "Iteration 787, loss = 0.56582472\n",
      "Iteration 788, loss = 0.56567729\n",
      "Iteration 789, loss = 0.56553006\n",
      "Iteration 790, loss = 0.56538304\n",
      "Iteration 791, loss = 0.56523623\n",
      "Iteration 792, loss = 0.56508962\n",
      "Iteration 793, loss = 0.56494322\n",
      "Iteration 794, loss = 0.56479702\n",
      "Iteration 795, loss = 0.56465103\n",
      "Iteration 796, loss = 0.56450524\n",
      "Iteration 797, loss = 0.56435966\n",
      "Iteration 798, loss = 0.56421428\n",
      "Iteration 799, loss = 0.56406911\n",
      "Iteration 800, loss = 0.56392414\n",
      "Iteration 801, loss = 0.56377937\n",
      "Iteration 802, loss = 0.56363481\n",
      "Iteration 803, loss = 0.56349045\n",
      "Iteration 804, loss = 0.56334629\n",
      "Iteration 805, loss = 0.56320233\n",
      "Iteration 806, loss = 0.56305858\n",
      "Iteration 807, loss = 0.56291503\n",
      "Iteration 808, loss = 0.56277168\n",
      "Iteration 809, loss = 0.56262853\n",
      "Iteration 810, loss = 0.56248558\n",
      "Iteration 811, loss = 0.56234284\n",
      "Iteration 812, loss = 0.56220029\n",
      "Iteration 813, loss = 0.56205795\n",
      "Iteration 814, loss = 0.56191580\n",
      "Iteration 815, loss = 0.56177386\n",
      "Iteration 816, loss = 0.56163211\n",
      "Iteration 817, loss = 0.56149057\n",
      "Iteration 818, loss = 0.56134922\n",
      "Iteration 819, loss = 0.56120807\n",
      "Iteration 820, loss = 0.56106712\n",
      "Iteration 821, loss = 0.56092637\n",
      "Iteration 822, loss = 0.56078581\n",
      "Iteration 823, loss = 0.56064545\n",
      "Iteration 824, loss = 0.56050529\n",
      "Iteration 825, loss = 0.56036533\n",
      "Iteration 826, loss = 0.56022556\n",
      "Iteration 827, loss = 0.56008599\n",
      "Iteration 828, loss = 0.55994661\n",
      "Iteration 829, loss = 0.55980743\n",
      "Iteration 830, loss = 0.55966844\n",
      "Iteration 831, loss = 0.55952965\n",
      "Iteration 832, loss = 0.55939105\n",
      "Iteration 833, loss = 0.55925265\n",
      "Iteration 834, loss = 0.55911444\n",
      "Iteration 835, loss = 0.55897642\n",
      "Iteration 836, loss = 0.55883860\n",
      "Iteration 837, loss = 0.55870097\n",
      "Iteration 838, loss = 0.55856353\n",
      "Iteration 839, loss = 0.55842628\n",
      "Iteration 840, loss = 0.55828923\n",
      "Iteration 841, loss = 0.55815236\n",
      "Iteration 842, loss = 0.55801569\n",
      "Iteration 843, loss = 0.55787920\n",
      "Iteration 844, loss = 0.55774291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 845, loss = 0.55760680\n",
      "Iteration 846, loss = 0.55747089\n",
      "Iteration 847, loss = 0.55733516\n",
      "Iteration 848, loss = 0.55719962\n",
      "Iteration 849, loss = 0.55706427\n",
      "Iteration 850, loss = 0.55692911\n",
      "Iteration 851, loss = 0.55679413\n",
      "Iteration 852, loss = 0.55665934\n",
      "Iteration 853, loss = 0.55652474\n",
      "Iteration 854, loss = 0.55639032\n",
      "Iteration 855, loss = 0.55625609\n",
      "Iteration 856, loss = 0.55612204\n",
      "Iteration 857, loss = 0.55598818\n",
      "Iteration 858, loss = 0.55585451\n",
      "Iteration 859, loss = 0.55572101\n",
      "Iteration 860, loss = 0.55558771\n",
      "Iteration 861, loss = 0.55545458\n",
      "Iteration 862, loss = 0.55532164\n",
      "Iteration 863, loss = 0.55518888\n",
      "Iteration 864, loss = 0.55505630\n",
      "Iteration 865, loss = 0.55492390\n",
      "Iteration 866, loss = 0.55479169\n",
      "Iteration 867, loss = 0.55465965\n",
      "Iteration 868, loss = 0.55452780\n",
      "Iteration 869, loss = 0.55439612\n",
      "Iteration 870, loss = 0.55426463\n",
      "Iteration 871, loss = 0.55413331\n",
      "Iteration 872, loss = 0.55400217\n",
      "Iteration 873, loss = 0.55387121\n",
      "Iteration 874, loss = 0.55374043\n",
      "Iteration 875, loss = 0.55360983\n",
      "Iteration 876, loss = 0.55347940\n",
      "Iteration 877, loss = 0.55334915\n",
      "Iteration 878, loss = 0.55321907\n",
      "Iteration 879, loss = 0.55308918\n",
      "Iteration 880, loss = 0.55295945\n",
      "Iteration 881, loss = 0.55282990\n",
      "Iteration 882, loss = 0.55270053\n",
      "Iteration 883, loss = 0.55257133\n",
      "Iteration 884, loss = 0.55244230\n",
      "Iteration 885, loss = 0.55231345\n",
      "Iteration 886, loss = 0.55218477\n",
      "Iteration 887, loss = 0.55205626\n",
      "Iteration 888, loss = 0.55192792\n",
      "Iteration 889, loss = 0.55179975\n",
      "Iteration 890, loss = 0.55167176\n",
      "Iteration 891, loss = 0.55154393\n",
      "Iteration 892, loss = 0.55141628\n",
      "Iteration 893, loss = 0.55128879\n",
      "Iteration 894, loss = 0.55116148\n",
      "Iteration 895, loss = 0.55103433\n",
      "Iteration 896, loss = 0.55090735\n",
      "Iteration 897, loss = 0.55078054\n",
      "Iteration 898, loss = 0.55065389\n",
      "Iteration 899, loss = 0.55052742\n",
      "Iteration 900, loss = 0.55040111\n",
      "Iteration 901, loss = 0.55027496\n",
      "Iteration 902, loss = 0.55014898\n",
      "Iteration 903, loss = 0.55002317\n",
      "Iteration 904, loss = 0.54989752\n",
      "Iteration 905, loss = 0.54977203\n",
      "Iteration 906, loss = 0.54964671\n",
      "Iteration 907, loss = 0.54952155\n",
      "Iteration 908, loss = 0.54939656\n",
      "Iteration 909, loss = 0.54927173\n",
      "Iteration 910, loss = 0.54914706\n",
      "Iteration 911, loss = 0.54902255\n",
      "Iteration 912, loss = 0.54889820\n",
      "Iteration 913, loss = 0.54877401\n",
      "Iteration 914, loss = 0.54864998\n",
      "Iteration 915, loss = 0.54852611\n",
      "Iteration 916, loss = 0.54840241\n",
      "Iteration 917, loss = 0.54827886\n",
      "Iteration 918, loss = 0.54815547\n",
      "Iteration 919, loss = 0.54803223\n",
      "Iteration 920, loss = 0.54790916\n",
      "Iteration 921, loss = 0.54778624\n",
      "Iteration 922, loss = 0.54766348\n",
      "Iteration 923, loss = 0.54754087\n",
      "Iteration 924, loss = 0.54741842\n",
      "Iteration 925, loss = 0.54729612\n",
      "Iteration 926, loss = 0.54717398\n",
      "Iteration 927, loss = 0.54705200\n",
      "Iteration 928, loss = 0.54693016\n",
      "Iteration 929, loss = 0.54680849\n",
      "Iteration 930, loss = 0.54668696\n",
      "Iteration 931, loss = 0.54656559\n",
      "Iteration 932, loss = 0.54644436\n",
      "Iteration 933, loss = 0.54632329\n",
      "Iteration 934, loss = 0.54620238\n",
      "Iteration 935, loss = 0.54608161\n",
      "Iteration 936, loss = 0.54596099\n",
      "Iteration 937, loss = 0.54584052\n",
      "Iteration 938, loss = 0.54572020\n",
      "Iteration 939, loss = 0.54560004\n",
      "Iteration 940, loss = 0.54548001\n",
      "Iteration 941, loss = 0.54536014\n",
      "Iteration 942, loss = 0.54524042\n",
      "Iteration 943, loss = 0.54512084\n",
      "Iteration 944, loss = 0.54500141\n",
      "Iteration 945, loss = 0.54488212\n",
      "Iteration 946, loss = 0.54476298\n",
      "Iteration 947, loss = 0.54464399\n",
      "Iteration 948, loss = 0.54452514\n",
      "Iteration 949, loss = 0.54440643\n",
      "Iteration 950, loss = 0.54428787\n",
      "Iteration 951, loss = 0.54416945\n",
      "Iteration 952, loss = 0.54405118\n",
      "Iteration 953, loss = 0.54393305\n",
      "Iteration 954, loss = 0.54381506\n",
      "Iteration 955, loss = 0.54369721\n",
      "Iteration 956, loss = 0.54357950\n",
      "Iteration 957, loss = 0.54346194\n",
      "Iteration 958, loss = 0.54334451\n",
      "Iteration 959, loss = 0.54322723\n",
      "Iteration 960, loss = 0.54311008\n",
      "Iteration 961, loss = 0.54299308\n",
      "Iteration 962, loss = 0.54287621\n",
      "Iteration 963, loss = 0.54275948\n",
      "Iteration 964, loss = 0.54264289\n",
      "Iteration 965, loss = 0.54252643\n",
      "Iteration 966, loss = 0.54241012\n",
      "Iteration 967, loss = 0.54229394\n",
      "Iteration 968, loss = 0.54217789\n",
      "Iteration 969, loss = 0.54206198\n",
      "Iteration 970, loss = 0.54194621\n",
      "Iteration 971, loss = 0.54183057\n",
      "Iteration 972, loss = 0.54171506\n",
      "Iteration 973, loss = 0.54159969\n",
      "Iteration 974, loss = 0.54148446\n",
      "Iteration 975, loss = 0.54136935\n",
      "Iteration 976, loss = 0.54125438\n",
      "Iteration 977, loss = 0.54113954\n",
      "Iteration 978, loss = 0.54102483\n",
      "Iteration 979, loss = 0.54091025\n",
      "Iteration 980, loss = 0.54079581\n",
      "Iteration 981, loss = 0.54068149\n",
      "Iteration 982, loss = 0.54056731\n",
      "Iteration 983, loss = 0.54045325\n",
      "Iteration 984, loss = 0.54033932\n",
      "Iteration 985, loss = 0.54022553\n",
      "Iteration 986, loss = 0.54011186\n",
      "Iteration 987, loss = 0.53999831\n",
      "Iteration 988, loss = 0.53988490\n",
      "Iteration 989, loss = 0.53977161\n",
      "Iteration 990, loss = 0.53965845\n",
      "Iteration 991, loss = 0.53954542\n",
      "Iteration 992, loss = 0.53943251\n",
      "Iteration 993, loss = 0.53931973\n",
      "Iteration 994, loss = 0.53920707\n",
      "Iteration 995, loss = 0.53909453\n",
      "Iteration 996, loss = 0.53898212\n",
      "Iteration 997, loss = 0.53886984\n",
      "Iteration 998, loss = 0.53875767\n",
      "Iteration 999, loss = 0.53864563\n",
      "Iteration 1000, loss = 0.53853372\n",
      "Iteration 1001, loss = 0.53842192\n",
      "Iteration 1002, loss = 0.53831025\n",
      "Iteration 1003, loss = 0.53819869\n",
      "Iteration 1004, loss = 0.53808726\n",
      "Iteration 1005, loss = 0.53797595\n",
      "Iteration 1006, loss = 0.53786476\n",
      "Iteration 1007, loss = 0.53775368\n",
      "Iteration 1008, loss = 0.53764273\n",
      "Iteration 1009, loss = 0.53753190\n",
      "Iteration 1010, loss = 0.53742118\n",
      "Iteration 1011, loss = 0.53731058\n",
      "Iteration 1012, loss = 0.53720010\n",
      "Iteration 1013, loss = 0.53708974\n",
      "Iteration 1014, loss = 0.53697949\n",
      "Iteration 1015, loss = 0.53686936\n",
      "Iteration 1016, loss = 0.53675935\n",
      "Iteration 1017, loss = 0.53664945\n",
      "Iteration 1018, loss = 0.53653967\n",
      "Iteration 1019, loss = 0.53643000\n",
      "Iteration 1020, loss = 0.53632044\n",
      "Iteration 1021, loss = 0.53621100\n",
      "Iteration 1022, loss = 0.53610168\n",
      "Iteration 1023, loss = 0.53599246\n",
      "Iteration 1024, loss = 0.53588336\n",
      "Iteration 1025, loss = 0.53577437\n",
      "Iteration 1026, loss = 0.53566550\n",
      "Iteration 1027, loss = 0.53555673\n",
      "Iteration 1028, loss = 0.53544808\n",
      "Iteration 1029, loss = 0.53533953\n",
      "Iteration 1030, loss = 0.53523110\n",
      "Iteration 1031, loss = 0.53512278\n",
      "Iteration 1032, loss = 0.53501457\n",
      "Iteration 1033, loss = 0.53490646\n",
      "Iteration 1034, loss = 0.53479847\n",
      "Iteration 1035, loss = 0.53469058\n",
      "Iteration 1036, loss = 0.53458281\n",
      "Iteration 1037, loss = 0.53447514\n",
      "Iteration 1038, loss = 0.53436757\n",
      "Iteration 1039, loss = 0.53426012\n",
      "Iteration 1040, loss = 0.53415277\n",
      "Iteration 1041, loss = 0.53404553\n",
      "Iteration 1042, loss = 0.53393839\n",
      "Iteration 1043, loss = 0.53383136\n",
      "Iteration 1044, loss = 0.53372443\n",
      "Iteration 1045, loss = 0.53361761\n",
      "Iteration 1046, loss = 0.53351089\n",
      "Iteration 1047, loss = 0.53340428\n",
      "Iteration 1048, loss = 0.53329777\n",
      "Iteration 1049, loss = 0.53319137\n",
      "Iteration 1050, loss = 0.53308506\n",
      "Iteration 1051, loss = 0.53297886\n",
      "Iteration 1052, loss = 0.53287276\n",
      "Iteration 1053, loss = 0.53276677\n",
      "Iteration 1054, loss = 0.53266087\n",
      "Iteration 1055, loss = 0.53255508\n",
      "Iteration 1056, loss = 0.53244939\n",
      "Iteration 1057, loss = 0.53234379\n",
      "Iteration 1058, loss = 0.53223830\n",
      "Iteration 1059, loss = 0.53213291\n",
      "Iteration 1060, loss = 0.53202762\n",
      "Iteration 1061, loss = 0.53192242\n",
      "Iteration 1062, loss = 0.53181733\n",
      "Iteration 1063, loss = 0.53171233\n",
      "Iteration 1064, loss = 0.53160743\n",
      "Iteration 1065, loss = 0.53150263\n",
      "Iteration 1066, loss = 0.53139792\n",
      "Iteration 1067, loss = 0.53129332\n",
      "Iteration 1068, loss = 0.53118881\n",
      "Iteration 1069, loss = 0.53108439\n",
      "Iteration 1070, loss = 0.53098007\n",
      "Iteration 1071, loss = 0.53087585\n",
      "Iteration 1072, loss = 0.53077172\n",
      "Iteration 1073, loss = 0.53066769\n",
      "Iteration 1074, loss = 0.53056375\n",
      "Iteration 1075, loss = 0.53045990\n",
      "Iteration 1076, loss = 0.53035615\n",
      "Iteration 1077, loss = 0.53025249\n",
      "Iteration 1078, loss = 0.53014893\n",
      "Iteration 1079, loss = 0.53004546\n",
      "Iteration 1080, loss = 0.52994208\n",
      "Iteration 1081, loss = 0.52983879\n",
      "Iteration 1082, loss = 0.52973560\n",
      "Iteration 1083, loss = 0.52963250\n",
      "Iteration 1084, loss = 0.52952948\n",
      "Iteration 1085, loss = 0.52942656\n",
      "Iteration 1086, loss = 0.52932373\n",
      "Iteration 1087, loss = 0.52922099\n",
      "Iteration 1088, loss = 0.52911834\n",
      "Iteration 1089, loss = 0.52901578\n",
      "Iteration 1090, loss = 0.52891331\n",
      "Iteration 1091, loss = 0.52881092\n",
      "Iteration 1092, loss = 0.52870863\n",
      "Iteration 1093, loss = 0.52860642\n",
      "Iteration 1094, loss = 0.52850430\n",
      "Iteration 1095, loss = 0.52840227\n",
      "Iteration 1096, loss = 0.52830033\n",
      "Iteration 1097, loss = 0.52819847\n",
      "Iteration 1098, loss = 0.52809670\n",
      "Iteration 1099, loss = 0.52799502\n",
      "Iteration 1100, loss = 0.52789342\n",
      "Iteration 1101, loss = 0.52779191\n",
      "Iteration 1102, loss = 0.52769048\n",
      "Iteration 1103, loss = 0.52758914\n",
      "Iteration 1104, loss = 0.52748788\n",
      "Iteration 1105, loss = 0.52738671\n",
      "Iteration 1106, loss = 0.52728562\n",
      "Iteration 1107, loss = 0.52718462\n",
      "Iteration 1108, loss = 0.52708370\n",
      "Iteration 1109, loss = 0.52698286\n",
      "Iteration 1110, loss = 0.52688211\n",
      "Iteration 1111, loss = 0.52678144\n",
      "Iteration 1112, loss = 0.52668085\n",
      "Iteration 1113, loss = 0.52658034\n",
      "Iteration 1114, loss = 0.52647992\n",
      "Iteration 1115, loss = 0.52637957\n",
      "Iteration 1116, loss = 0.52627931\n",
      "Iteration 1117, loss = 0.52617913\n",
      "Iteration 1118, loss = 0.52607903\n",
      "Iteration 1119, loss = 0.52597901\n",
      "Iteration 1120, loss = 0.52587907\n",
      "Iteration 1121, loss = 0.52577921\n",
      "Iteration 1122, loss = 0.52567943\n",
      "Iteration 1123, loss = 0.52557973\n",
      "Iteration 1124, loss = 0.52548010\n",
      "Iteration 1125, loss = 0.52538056\n",
      "Iteration 1126, loss = 0.52528109\n",
      "Iteration 1127, loss = 0.52518171\n",
      "Iteration 1128, loss = 0.52508239\n",
      "Iteration 1129, loss = 0.52498316\n",
      "Iteration 1130, loss = 0.52488401\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(2, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_xor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_xor.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = red_xor.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_grafico = [-1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], c=y_grafico, cmap=cm_bright)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_2d_separator(red_xor, X, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y_grafico) \n",
    "plt.xlabel(\"Feature 0\") \n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicios adicionales\n",
    "Resuelva con una arquitectura de red neuronal feed forward multicapa el dataset iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Red Neuronal como Regresión\n",
    "Considere una función $y = x^2-2x+3$. Para el intervalo de $[-5, 5]$ Obtenga 1000 puntos. Puede hacer que la red neuronal reproduzca esta función en el Intervalo propuesto?\n",
    "\n",
    "Que pasa si incrementa el dataset a 2000 muestras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5, num=2000)\n",
    "# x = np.arange(10)\n",
    "y = x*x-2*x+3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.        , -4.98998999, -4.97997998, -4.96996997, -4.95995996,\n",
       "       -4.94994995, -4.93993994, -4.92992993, -4.91991992, -4.90990991,\n",
       "       -4.8998999 , -4.88988989, -4.87987988, -4.86986987, -4.85985986,\n",
       "       -4.84984985, -4.83983984, -4.82982983, -4.81981982, -4.80980981,\n",
       "       -4.7997998 , -4.78978979, -4.77977978, -4.76976977, -4.75975976,\n",
       "       -4.74974975, -4.73973974, -4.72972973, -4.71971972, -4.70970971,\n",
       "       -4.6996997 , -4.68968969, -4.67967968, -4.66966967, -4.65965966,\n",
       "       -4.64964965, -4.63963964, -4.62962963, -4.61961962, -4.60960961,\n",
       "       -4.5995996 , -4.58958959, -4.57957958, -4.56956957, -4.55955956,\n",
       "       -4.54954955, -4.53953954, -4.52952953, -4.51951952, -4.50950951,\n",
       "       -4.4994995 , -4.48948949, -4.47947948, -4.46946947, -4.45945946,\n",
       "       -4.44944945, -4.43943944, -4.42942943, -4.41941942, -4.40940941,\n",
       "       -4.3993994 , -4.38938939, -4.37937938, -4.36936937, -4.35935936,\n",
       "       -4.34934935, -4.33933934, -4.32932933, -4.31931932, -4.30930931,\n",
       "       -4.2992993 , -4.28928929, -4.27927928, -4.26926927, -4.25925926,\n",
       "       -4.24924925, -4.23923924, -4.22922923, -4.21921922, -4.20920921,\n",
       "       -4.1991992 , -4.18918919, -4.17917918, -4.16916917, -4.15915916,\n",
       "       -4.14914915, -4.13913914, -4.12912913, -4.11911912, -4.10910911,\n",
       "       -4.0990991 , -4.08908909, -4.07907908, -4.06906907, -4.05905906,\n",
       "       -4.04904905, -4.03903904, -4.02902903, -4.01901902, -4.00900901,\n",
       "       -3.998999  , -3.98898899, -3.97897898, -3.96896897, -3.95895896,\n",
       "       -3.94894895, -3.93893894, -3.92892893, -3.91891892, -3.90890891,\n",
       "       -3.8988989 , -3.88888889, -3.87887888, -3.86886887, -3.85885886,\n",
       "       -3.84884885, -3.83883884, -3.82882883, -3.81881882, -3.80880881,\n",
       "       -3.7987988 , -3.78878879, -3.77877878, -3.76876877, -3.75875876,\n",
       "       -3.74874875, -3.73873874, -3.72872873, -3.71871872, -3.70870871,\n",
       "       -3.6986987 , -3.68868869, -3.67867868, -3.66866867, -3.65865866,\n",
       "       -3.64864865, -3.63863864, -3.62862863, -3.61861862, -3.60860861,\n",
       "       -3.5985986 , -3.58858859, -3.57857858, -3.56856857, -3.55855856,\n",
       "       -3.54854855, -3.53853854, -3.52852853, -3.51851852, -3.50850851,\n",
       "       -3.4984985 , -3.48848849, -3.47847848, -3.46846847, -3.45845846,\n",
       "       -3.44844845, -3.43843844, -3.42842843, -3.41841842, -3.40840841,\n",
       "       -3.3983984 , -3.38838839, -3.37837838, -3.36836837, -3.35835836,\n",
       "       -3.34834835, -3.33833834, -3.32832833, -3.31831832, -3.30830831,\n",
       "       -3.2982983 , -3.28828829, -3.27827828, -3.26826827, -3.25825826,\n",
       "       -3.24824825, -3.23823824, -3.22822823, -3.21821822, -3.20820821,\n",
       "       -3.1981982 , -3.18818819, -3.17817818, -3.16816817, -3.15815816,\n",
       "       -3.14814815, -3.13813814, -3.12812813, -3.11811812, -3.10810811,\n",
       "       -3.0980981 , -3.08808809, -3.07807808, -3.06806807, -3.05805806,\n",
       "       -3.04804805, -3.03803804, -3.02802803, -3.01801802, -3.00800801,\n",
       "       -2.997998  , -2.98798799, -2.97797798, -2.96796797, -2.95795796,\n",
       "       -2.94794795, -2.93793794, -2.92792793, -2.91791792, -2.90790791,\n",
       "       -2.8978979 , -2.88788789, -2.87787788, -2.86786787, -2.85785786,\n",
       "       -2.84784785, -2.83783784, -2.82782783, -2.81781782, -2.80780781,\n",
       "       -2.7977978 , -2.78778779, -2.77777778, -2.76776777, -2.75775776,\n",
       "       -2.74774775, -2.73773774, -2.72772773, -2.71771772, -2.70770771,\n",
       "       -2.6976977 , -2.68768769, -2.67767768, -2.66766767, -2.65765766,\n",
       "       -2.64764765, -2.63763764, -2.62762763, -2.61761762, -2.60760761,\n",
       "       -2.5975976 , -2.58758759, -2.57757758, -2.56756757, -2.55755756,\n",
       "       -2.54754755, -2.53753754, -2.52752753, -2.51751752, -2.50750751,\n",
       "       -2.4974975 , -2.48748749, -2.47747748, -2.46746747, -2.45745746,\n",
       "       -2.44744745, -2.43743744, -2.42742743, -2.41741742, -2.40740741,\n",
       "       -2.3973974 , -2.38738739, -2.37737738, -2.36736737, -2.35735736,\n",
       "       -2.34734735, -2.33733734, -2.32732733, -2.31731732, -2.30730731,\n",
       "       -2.2972973 , -2.28728729, -2.27727728, -2.26726727, -2.25725726,\n",
       "       -2.24724725, -2.23723724, -2.22722723, -2.21721722, -2.20720721,\n",
       "       -2.1971972 , -2.18718719, -2.17717718, -2.16716717, -2.15715716,\n",
       "       -2.14714715, -2.13713714, -2.12712713, -2.11711712, -2.10710711,\n",
       "       -2.0970971 , -2.08708709, -2.07707708, -2.06706707, -2.05705706,\n",
       "       -2.04704705, -2.03703704, -2.02702703, -2.01701702, -2.00700701,\n",
       "       -1.996997  , -1.98698699, -1.97697698, -1.96696697, -1.95695696,\n",
       "       -1.94694695, -1.93693694, -1.92692693, -1.91691692, -1.90690691,\n",
       "       -1.8968969 , -1.88688689, -1.87687688, -1.86686687, -1.85685686,\n",
       "       -1.84684685, -1.83683684, -1.82682683, -1.81681682, -1.80680681,\n",
       "       -1.7967968 , -1.78678679, -1.77677678, -1.76676677, -1.75675676,\n",
       "       -1.74674675, -1.73673674, -1.72672673, -1.71671672, -1.70670671,\n",
       "       -1.6966967 , -1.68668669, -1.67667668, -1.66666667, -1.65665666,\n",
       "       -1.64664665, -1.63663664, -1.62662663, -1.61661662, -1.60660661,\n",
       "       -1.5965966 , -1.58658659, -1.57657658, -1.56656657, -1.55655656,\n",
       "       -1.54654655, -1.53653654, -1.52652653, -1.51651652, -1.50650651,\n",
       "       -1.4964965 , -1.48648649, -1.47647648, -1.46646647, -1.45645646,\n",
       "       -1.44644645, -1.43643644, -1.42642643, -1.41641642, -1.40640641,\n",
       "       -1.3963964 , -1.38638639, -1.37637638, -1.36636637, -1.35635636,\n",
       "       -1.34634635, -1.33633634, -1.32632633, -1.31631632, -1.30630631,\n",
       "       -1.2962963 , -1.28628629, -1.27627628, -1.26626627, -1.25625626,\n",
       "       -1.24624625, -1.23623624, -1.22622623, -1.21621622, -1.20620621,\n",
       "       -1.1961962 , -1.18618619, -1.17617618, -1.16616617, -1.15615616,\n",
       "       -1.14614615, -1.13613614, -1.12612613, -1.11611612, -1.10610611,\n",
       "       -1.0960961 , -1.08608609, -1.07607608, -1.06606607, -1.05605606,\n",
       "       -1.04604605, -1.03603604, -1.02602603, -1.01601602, -1.00600601,\n",
       "       -0.995996  , -0.98598599, -0.97597598, -0.96596597, -0.95595596,\n",
       "       -0.94594595, -0.93593594, -0.92592593, -0.91591592, -0.90590591,\n",
       "       -0.8958959 , -0.88588589, -0.87587588, -0.86586587, -0.85585586,\n",
       "       -0.84584585, -0.83583584, -0.82582583, -0.81581582, -0.80580581,\n",
       "       -0.7957958 , -0.78578579, -0.77577578, -0.76576577, -0.75575576,\n",
       "       -0.74574575, -0.73573574, -0.72572573, -0.71571572, -0.70570571,\n",
       "       -0.6956957 , -0.68568569, -0.67567568, -0.66566567, -0.65565566,\n",
       "       -0.64564565, -0.63563564, -0.62562563, -0.61561562, -0.60560561,\n",
       "       -0.5955956 , -0.58558559, -0.57557558, -0.56556557, -0.55555556,\n",
       "       -0.54554555, -0.53553554, -0.52552553, -0.51551552, -0.50550551,\n",
       "       -0.4954955 , -0.48548549, -0.47547548, -0.46546547, -0.45545546,\n",
       "       -0.44544545, -0.43543544, -0.42542543, -0.41541542, -0.40540541,\n",
       "       -0.3953954 , -0.38538539, -0.37537538, -0.36536537, -0.35535536,\n",
       "       -0.34534535, -0.33533534, -0.32532533, -0.31531532, -0.30530531,\n",
       "       -0.2952953 , -0.28528529, -0.27527528, -0.26526527, -0.25525526,\n",
       "       -0.24524525, -0.23523524, -0.22522523, -0.21521522, -0.20520521,\n",
       "       -0.1951952 , -0.18518519, -0.17517518, -0.16516517, -0.15515516,\n",
       "       -0.14514515, -0.13513514, -0.12512513, -0.11511512, -0.10510511,\n",
       "       -0.0950951 , -0.08508509, -0.07507508, -0.06506507, -0.05505506,\n",
       "       -0.04504505, -0.03503504, -0.02502503, -0.01501502, -0.00500501,\n",
       "        0.00500501,  0.01501502,  0.02502503,  0.03503504,  0.04504505,\n",
       "        0.05505506,  0.06506507,  0.07507508,  0.08508509,  0.0950951 ,\n",
       "        0.10510511,  0.11511512,  0.12512513,  0.13513514,  0.14514515,\n",
       "        0.15515516,  0.16516517,  0.17517518,  0.18518519,  0.1951952 ,\n",
       "        0.20520521,  0.21521522,  0.22522523,  0.23523524,  0.24524525,\n",
       "        0.25525526,  0.26526527,  0.27527528,  0.28528529,  0.2952953 ,\n",
       "        0.30530531,  0.31531532,  0.32532533,  0.33533534,  0.34534535,\n",
       "        0.35535536,  0.36536537,  0.37537538,  0.38538539,  0.3953954 ,\n",
       "        0.40540541,  0.41541542,  0.42542543,  0.43543544,  0.44544545,\n",
       "        0.45545546,  0.46546547,  0.47547548,  0.48548549,  0.4954955 ,\n",
       "        0.50550551,  0.51551552,  0.52552553,  0.53553554,  0.54554555,\n",
       "        0.55555556,  0.56556557,  0.57557558,  0.58558559,  0.5955956 ,\n",
       "        0.60560561,  0.61561562,  0.62562563,  0.63563564,  0.64564565,\n",
       "        0.65565566,  0.66566567,  0.67567568,  0.68568569,  0.6956957 ,\n",
       "        0.70570571,  0.71571572,  0.72572573,  0.73573574,  0.74574575,\n",
       "        0.75575576,  0.76576577,  0.77577578,  0.78578579,  0.7957958 ,\n",
       "        0.80580581,  0.81581582,  0.82582583,  0.83583584,  0.84584585,\n",
       "        0.85585586,  0.86586587,  0.87587588,  0.88588589,  0.8958959 ,\n",
       "        0.90590591,  0.91591592,  0.92592593,  0.93593594,  0.94594595,\n",
       "        0.95595596,  0.96596597,  0.97597598,  0.98598599,  0.995996  ,\n",
       "        1.00600601,  1.01601602,  1.02602603,  1.03603604,  1.04604605,\n",
       "        1.05605606,  1.06606607,  1.07607608,  1.08608609,  1.0960961 ,\n",
       "        1.10610611,  1.11611612,  1.12612613,  1.13613614,  1.14614615,\n",
       "        1.15615616,  1.16616617,  1.17617618,  1.18618619,  1.1961962 ,\n",
       "        1.20620621,  1.21621622,  1.22622623,  1.23623624,  1.24624625,\n",
       "        1.25625626,  1.26626627,  1.27627628,  1.28628629,  1.2962963 ,\n",
       "        1.30630631,  1.31631632,  1.32632633,  1.33633634,  1.34634635,\n",
       "        1.35635636,  1.36636637,  1.37637638,  1.38638639,  1.3963964 ,\n",
       "        1.40640641,  1.41641642,  1.42642643,  1.43643644,  1.44644645,\n",
       "        1.45645646,  1.46646647,  1.47647648,  1.48648649,  1.4964965 ,\n",
       "        1.50650651,  1.51651652,  1.52652653,  1.53653654,  1.54654655,\n",
       "        1.55655656,  1.56656657,  1.57657658,  1.58658659,  1.5965966 ,\n",
       "        1.60660661,  1.61661662,  1.62662663,  1.63663664,  1.64664665,\n",
       "        1.65665666,  1.66666667,  1.67667668,  1.68668669,  1.6966967 ,\n",
       "        1.70670671,  1.71671672,  1.72672673,  1.73673674,  1.74674675,\n",
       "        1.75675676,  1.76676677,  1.77677678,  1.78678679,  1.7967968 ,\n",
       "        1.80680681,  1.81681682,  1.82682683,  1.83683684,  1.84684685,\n",
       "        1.85685686,  1.86686687,  1.87687688,  1.88688689,  1.8968969 ,\n",
       "        1.90690691,  1.91691692,  1.92692693,  1.93693694,  1.94694695,\n",
       "        1.95695696,  1.96696697,  1.97697698,  1.98698699,  1.996997  ,\n",
       "        2.00700701,  2.01701702,  2.02702703,  2.03703704,  2.04704705,\n",
       "        2.05705706,  2.06706707,  2.07707708,  2.08708709,  2.0970971 ,\n",
       "        2.10710711,  2.11711712,  2.12712713,  2.13713714,  2.14714715,\n",
       "        2.15715716,  2.16716717,  2.17717718,  2.18718719,  2.1971972 ,\n",
       "        2.20720721,  2.21721722,  2.22722723,  2.23723724,  2.24724725,\n",
       "        2.25725726,  2.26726727,  2.27727728,  2.28728729,  2.2972973 ,\n",
       "        2.30730731,  2.31731732,  2.32732733,  2.33733734,  2.34734735,\n",
       "        2.35735736,  2.36736737,  2.37737738,  2.38738739,  2.3973974 ,\n",
       "        2.40740741,  2.41741742,  2.42742743,  2.43743744,  2.44744745,\n",
       "        2.45745746,  2.46746747,  2.47747748,  2.48748749,  2.4974975 ,\n",
       "        2.50750751,  2.51751752,  2.52752753,  2.53753754,  2.54754755,\n",
       "        2.55755756,  2.56756757,  2.57757758,  2.58758759,  2.5975976 ,\n",
       "        2.60760761,  2.61761762,  2.62762763,  2.63763764,  2.64764765,\n",
       "        2.65765766,  2.66766767,  2.67767768,  2.68768769,  2.6976977 ,\n",
       "        2.70770771,  2.71771772,  2.72772773,  2.73773774,  2.74774775,\n",
       "        2.75775776,  2.76776777,  2.77777778,  2.78778779,  2.7977978 ,\n",
       "        2.80780781,  2.81781782,  2.82782783,  2.83783784,  2.84784785,\n",
       "        2.85785786,  2.86786787,  2.87787788,  2.88788789,  2.8978979 ,\n",
       "        2.90790791,  2.91791792,  2.92792793,  2.93793794,  2.94794795,\n",
       "        2.95795796,  2.96796797,  2.97797798,  2.98798799,  2.997998  ,\n",
       "        3.00800801,  3.01801802,  3.02802803,  3.03803804,  3.04804805,\n",
       "        3.05805806,  3.06806807,  3.07807808,  3.08808809,  3.0980981 ,\n",
       "        3.10810811,  3.11811812,  3.12812813,  3.13813814,  3.14814815,\n",
       "        3.15815816,  3.16816817,  3.17817818,  3.18818819,  3.1981982 ,\n",
       "        3.20820821,  3.21821822,  3.22822823,  3.23823824,  3.24824825,\n",
       "        3.25825826,  3.26826827,  3.27827828,  3.28828829,  3.2982983 ,\n",
       "        3.30830831,  3.31831832,  3.32832833,  3.33833834,  3.34834835,\n",
       "        3.35835836,  3.36836837,  3.37837838,  3.38838839,  3.3983984 ,\n",
       "        3.40840841,  3.41841842,  3.42842843,  3.43843844,  3.44844845,\n",
       "        3.45845846,  3.46846847,  3.47847848,  3.48848849,  3.4984985 ,\n",
       "        3.50850851,  3.51851852,  3.52852853,  3.53853854,  3.54854855,\n",
       "        3.55855856,  3.56856857,  3.57857858,  3.58858859,  3.5985986 ,\n",
       "        3.60860861,  3.61861862,  3.62862863,  3.63863864,  3.64864865,\n",
       "        3.65865866,  3.66866867,  3.67867868,  3.68868869,  3.6986987 ,\n",
       "        3.70870871,  3.71871872,  3.72872873,  3.73873874,  3.74874875,\n",
       "        3.75875876,  3.76876877,  3.77877878,  3.78878879,  3.7987988 ,\n",
       "        3.80880881,  3.81881882,  3.82882883,  3.83883884,  3.84884885,\n",
       "        3.85885886,  3.86886887,  3.87887888,  3.88888889,  3.8988989 ,\n",
       "        3.90890891,  3.91891892,  3.92892893,  3.93893894,  3.94894895,\n",
       "        3.95895896,  3.96896897,  3.97897898,  3.98898899,  3.998999  ,\n",
       "        4.00900901,  4.01901902,  4.02902903,  4.03903904,  4.04904905,\n",
       "        4.05905906,  4.06906907,  4.07907908,  4.08908909,  4.0990991 ,\n",
       "        4.10910911,  4.11911912,  4.12912913,  4.13913914,  4.14914915,\n",
       "        4.15915916,  4.16916917,  4.17917918,  4.18918919,  4.1991992 ,\n",
       "        4.20920921,  4.21921922,  4.22922923,  4.23923924,  4.24924925,\n",
       "        4.25925926,  4.26926927,  4.27927928,  4.28928929,  4.2992993 ,\n",
       "        4.30930931,  4.31931932,  4.32932933,  4.33933934,  4.34934935,\n",
       "        4.35935936,  4.36936937,  4.37937938,  4.38938939,  4.3993994 ,\n",
       "        4.40940941,  4.41941942,  4.42942943,  4.43943944,  4.44944945,\n",
       "        4.45945946,  4.46946947,  4.47947948,  4.48948949,  4.4994995 ,\n",
       "        4.50950951,  4.51951952,  4.52952953,  4.53953954,  4.54954955,\n",
       "        4.55955956,  4.56956957,  4.57957958,  4.58958959,  4.5995996 ,\n",
       "        4.60960961,  4.61961962,  4.62962963,  4.63963964,  4.64964965,\n",
       "        4.65965966,  4.66966967,  4.67967968,  4.68968969,  4.6996997 ,\n",
       "        4.70970971,  4.71971972,  4.72972973,  4.73973974,  4.74974975,\n",
       "        4.75975976,  4.76976977,  4.77977978,  4.78978979,  4.7997998 ,\n",
       "        4.80980981,  4.81981982,  4.82982983,  4.83983984,  4.84984985,\n",
       "        4.85985986,  4.86986987,  4.87987988,  4.88988989,  4.8998999 ,\n",
       "        4.90990991,  4.91991992,  4.92992993,  4.93993994,  4.94994995,\n",
       "        4.95995996,  4.96996997,  4.97997998,  4.98998999,  5.        ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 104.51632565\n",
      "Iteration 2, loss = 92.83440593\n",
      "Iteration 3, loss = 81.68220641\n",
      "Iteration 4, loss = 70.47766647\n",
      "Iteration 5, loss = 59.23540272\n",
      "Iteration 6, loss = 48.11113960\n",
      "Iteration 7, loss = 37.45445024\n",
      "Iteration 8, loss = 27.91190056\n",
      "Iteration 9, loss = 19.91497334\n",
      "Iteration 10, loss = 13.58114357\n",
      "Iteration 11, loss = 9.08800685\n",
      "Iteration 12, loss = 6.24994903\n",
      "Iteration 13, loss = 4.74544651\n",
      "Iteration 14, loss = 3.96309055\n",
      "Iteration 15, loss = 3.65299783\n",
      "Iteration 16, loss = 3.50781727\n",
      "Iteration 17, loss = 3.40245810\n",
      "Iteration 18, loss = 3.30500274\n",
      "Iteration 19, loss = 3.21390286\n",
      "Iteration 20, loss = 3.12433279\n",
      "Iteration 21, loss = 3.04129886\n",
      "Iteration 22, loss = 2.96346760\n",
      "Iteration 23, loss = 2.88905510\n",
      "Iteration 24, loss = 2.82118406\n",
      "Iteration 25, loss = 2.74861513\n",
      "Iteration 26, loss = 2.68380609\n",
      "Iteration 27, loss = 2.62204011\n",
      "Iteration 28, loss = 2.56035349\n",
      "Iteration 29, loss = 2.50287580\n",
      "Iteration 30, loss = 2.44695336\n",
      "Iteration 31, loss = 2.39374795\n",
      "Iteration 32, loss = 2.34091214\n",
      "Iteration 33, loss = 2.29085935\n",
      "Iteration 34, loss = 2.24138765\n",
      "Iteration 35, loss = 2.19477718\n",
      "Iteration 36, loss = 2.14808184\n",
      "Iteration 37, loss = 2.10547510\n",
      "Iteration 38, loss = 2.06088868\n",
      "Iteration 39, loss = 2.02053328\n",
      "Iteration 40, loss = 1.97894303\n",
      "Iteration 41, loss = 1.93907688\n",
      "Iteration 42, loss = 1.90072541\n",
      "Iteration 43, loss = 1.86341503\n",
      "Iteration 44, loss = 1.82651791\n",
      "Iteration 45, loss = 1.79131919\n",
      "Iteration 46, loss = 1.75616778\n",
      "Iteration 47, loss = 1.72274355\n",
      "Iteration 48, loss = 1.69014225\n",
      "Iteration 49, loss = 1.65877149\n",
      "Iteration 50, loss = 1.62606285\n",
      "Iteration 51, loss = 1.59660524\n",
      "Iteration 52, loss = 1.56751042\n",
      "Iteration 53, loss = 1.53659365\n",
      "Iteration 54, loss = 1.50905723\n",
      "Iteration 55, loss = 1.48304701\n",
      "Iteration 56, loss = 1.45585421\n",
      "Iteration 57, loss = 1.42927012\n",
      "Iteration 58, loss = 1.40370279\n",
      "Iteration 59, loss = 1.37840506\n",
      "Iteration 60, loss = 1.35523856\n",
      "Iteration 61, loss = 1.33001919\n",
      "Iteration 62, loss = 1.30723001\n",
      "Iteration 63, loss = 1.28400988\n",
      "Iteration 64, loss = 1.26291835\n",
      "Iteration 65, loss = 1.23892774\n",
      "Iteration 66, loss = 1.21964890\n",
      "Iteration 67, loss = 1.19580702\n",
      "Iteration 68, loss = 1.17537736\n",
      "Iteration 69, loss = 1.15537633\n",
      "Iteration 70, loss = 1.13428679\n",
      "Iteration 71, loss = 1.11366099\n",
      "Iteration 72, loss = 1.09318163\n",
      "Iteration 73, loss = 1.07372552\n",
      "Iteration 74, loss = 1.05427456\n",
      "Iteration 75, loss = 1.03471553\n",
      "Iteration 76, loss = 1.01598637\n",
      "Iteration 77, loss = 0.99679875\n",
      "Iteration 78, loss = 0.97812949\n",
      "Iteration 79, loss = 0.95995546\n",
      "Iteration 80, loss = 0.94156499\n",
      "Iteration 81, loss = 0.92561584\n",
      "Iteration 82, loss = 0.90542496\n",
      "Iteration 83, loss = 0.88844039\n",
      "Iteration 84, loss = 0.87096876\n",
      "Iteration 85, loss = 0.85291567\n",
      "Iteration 86, loss = 0.83509753\n",
      "Iteration 87, loss = 0.81864241\n",
      "Iteration 88, loss = 0.80148853\n",
      "Iteration 89, loss = 0.78450713\n",
      "Iteration 90, loss = 0.76817822\n",
      "Iteration 91, loss = 0.75154771\n",
      "Iteration 92, loss = 0.73515813\n",
      "Iteration 93, loss = 0.71929076\n",
      "Iteration 94, loss = 0.70365300\n",
      "Iteration 95, loss = 0.68909307\n",
      "Iteration 96, loss = 0.67239123\n",
      "Iteration 97, loss = 0.65721686\n",
      "Iteration 98, loss = 0.64211366\n",
      "Iteration 99, loss = 0.62764722\n",
      "Iteration 100, loss = 0.61315811\n",
      "Iteration 101, loss = 0.59965888\n",
      "Iteration 102, loss = 0.58506628\n",
      "Iteration 103, loss = 0.57111895\n",
      "Iteration 104, loss = 0.55687313\n",
      "Iteration 105, loss = 0.54334461\n",
      "Iteration 106, loss = 0.53030821\n",
      "Iteration 107, loss = 0.51948044\n",
      "Iteration 108, loss = 0.50437890\n",
      "Iteration 109, loss = 0.49254620\n",
      "Iteration 110, loss = 0.48032517\n",
      "Iteration 111, loss = 0.46828539\n",
      "Iteration 112, loss = 0.45687725\n",
      "Iteration 113, loss = 0.44555069\n",
      "Iteration 114, loss = 0.43531921\n",
      "Iteration 115, loss = 0.42339913\n",
      "Iteration 116, loss = 0.41331532\n",
      "Iteration 117, loss = 0.40278706\n",
      "Iteration 118, loss = 0.39280173\n",
      "Iteration 119, loss = 0.38260584\n",
      "Iteration 120, loss = 0.37468493\n",
      "Iteration 121, loss = 0.36510481\n",
      "Iteration 122, loss = 0.35550680\n",
      "Iteration 123, loss = 0.34620948\n",
      "Iteration 124, loss = 0.33731699\n",
      "Iteration 125, loss = 0.32871167\n",
      "Iteration 126, loss = 0.32054350\n",
      "Iteration 127, loss = 0.31297315\n",
      "Iteration 128, loss = 0.30499542\n",
      "Iteration 129, loss = 0.29713659\n",
      "Iteration 130, loss = 0.28984151\n",
      "Iteration 131, loss = 0.28238764\n",
      "Iteration 132, loss = 0.27588443\n",
      "Iteration 133, loss = 0.26875180\n",
      "Iteration 134, loss = 0.26246988\n",
      "Iteration 135, loss = 0.25617641\n",
      "Iteration 136, loss = 0.24907004\n",
      "Iteration 137, loss = 0.24315091\n",
      "Iteration 138, loss = 0.23695529\n",
      "Iteration 139, loss = 0.23123403\n",
      "Iteration 140, loss = 0.22603319\n",
      "Iteration 141, loss = 0.21976863\n",
      "Iteration 142, loss = 0.21461147\n",
      "Iteration 143, loss = 0.20911675\n",
      "Iteration 144, loss = 0.20380036\n",
      "Iteration 145, loss = 0.19890833\n",
      "Iteration 146, loss = 0.19434793\n",
      "Iteration 147, loss = 0.18876440\n",
      "Iteration 148, loss = 0.18469901\n",
      "Iteration 149, loss = 0.18001928\n",
      "Iteration 150, loss = 0.17541558\n",
      "Iteration 151, loss = 0.17106649\n",
      "Iteration 152, loss = 0.16690447\n",
      "Iteration 153, loss = 0.16337438\n",
      "Iteration 154, loss = 0.15894340\n",
      "Iteration 155, loss = 0.15539705\n",
      "Iteration 156, loss = 0.15107388\n",
      "Iteration 157, loss = 0.14721556\n",
      "Iteration 158, loss = 0.14399772\n",
      "Iteration 159, loss = 0.14049075\n",
      "Iteration 160, loss = 0.13689457\n",
      "Iteration 161, loss = 0.13321978\n",
      "Iteration 162, loss = 0.12978406\n",
      "Iteration 163, loss = 0.12682153\n",
      "Iteration 164, loss = 0.12386362\n",
      "Iteration 165, loss = 0.12118241\n",
      "Iteration 166, loss = 0.11786369\n",
      "Iteration 167, loss = 0.11490529\n",
      "Iteration 168, loss = 0.11221792\n",
      "Iteration 169, loss = 0.11011996\n",
      "Iteration 170, loss = 0.10649440\n",
      "Iteration 171, loss = 0.10404222\n",
      "Iteration 172, loss = 0.10196368\n",
      "Iteration 173, loss = 0.09914576\n",
      "Iteration 174, loss = 0.09663507\n",
      "Iteration 175, loss = 0.09440600\n",
      "Iteration 176, loss = 0.09213891\n",
      "Iteration 177, loss = 0.09036069\n",
      "Iteration 178, loss = 0.08758231\n",
      "Iteration 179, loss = 0.08619126\n",
      "Iteration 180, loss = 0.08422013\n",
      "Iteration 181, loss = 0.08145382\n",
      "Iteration 182, loss = 0.08051870\n",
      "Iteration 183, loss = 0.07814638\n",
      "Iteration 184, loss = 0.07629692\n",
      "Iteration 185, loss = 0.07418374\n",
      "Iteration 186, loss = 0.07242671\n",
      "Iteration 187, loss = 0.07084152\n",
      "Iteration 188, loss = 0.06928058\n",
      "Iteration 189, loss = 0.06799431\n",
      "Iteration 190, loss = 0.06623309\n",
      "Iteration 191, loss = 0.06463921\n",
      "Iteration 192, loss = 0.06317812\n",
      "Iteration 193, loss = 0.06166645\n",
      "Iteration 194, loss = 0.06024462\n",
      "Iteration 195, loss = 0.05905732\n",
      "Iteration 196, loss = 0.05755179\n",
      "Iteration 197, loss = 0.05657061\n",
      "Iteration 198, loss = 0.05503022\n",
      "Iteration 199, loss = 0.05387134\n",
      "Iteration 200, loss = 0.05295486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(500,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "red_funcion = MLPRegressor(hidden_layer_sizes=(500,), solver='adam', activation='relu', verbose=1)\n",
    "red_funcion.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988487938937554"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_funcion.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(-5,5,500)\n",
    "y_real = x_test*x_test-2*x_test+3\n",
    "x_test = x_test.reshape(-1,1)\n",
    "# x_test\n",
    "y_pred = red_funcion.predict(x_test)\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_test, y_real, color='blue')\n",
    "plt.plot(x_test, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¿Qué sucede si deseo calcular para un valor fuera del rango como por ejemplo $x=5.5$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num = 16.\n",
    "y_num = x_num*x_num-2*x_num+3\n",
    "y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.20447314])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num = np.asarray(x_num)\n",
    "x_num = x_num.reshape(-1,1)\n",
    "y_num_pred = red_funcion.predict(x_num)\n",
    "y_num_pred"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
