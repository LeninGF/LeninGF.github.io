{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "<center>\n",
    "    \n",
    "<img src='images/Neuron.svg' width=60%\\>\n",
    "</center>\n",
    "\n",
    "[Fuente Wikipedia](https://commons.wikimedia.org/w/index.php?title=File:Neuron.svg&oldid=343028396)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una red neuronal es una estructura compuesta por **nodos** o **unidades** que se encuentran interconectados. La potencia de la interconexión entre los nodos se evalúa por medio un valor de **peso**. Si la suma ponderada de todas las conexiones al **nodo** o **neurona** es mayor que un **valor umbral**, decimos que la neurona se **activa**. La función matemática aplicada a la suma ponderada se denomina **función de activación**. \n",
    "\n",
    "Se denomina **Modelo de Perceptrón** a una red neuronal con una sola salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"174pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 174.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 170,-257 170,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"106,-89 106,-164 158,-164 158,-89 106,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"132\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.041,-184.3947C64.2693,-170.9815 91.1723,-148.7454 110.144,-133.0647\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"112.5069,-135.6525 117.985,-126.5838 108.0473,-130.2569 112.5069,-135.6525\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[0]</text>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5204,-137.1729C66.2924,-133.1031 87.6838,-127.2096 104.6999,-122.5214\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.9201,-125.8158 114.6312,-119.7853 104.0608,-119.0672 105.9201,-125.8158\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[1]</text>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5204,-92.8271C66.2924,-96.8969 87.6838,-102.7904 104.6999,-107.4786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.0608,-110.9328 114.6312,-110.2147 105.9201,-104.1842 104.0608,-110.9328\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-107.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[2]</text>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.041,-45.6053C64.2693,-59.0185 91.1723,-81.2546 110.144,-96.9353\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0473,-99.7431 117.985,-103.4162 112.5069,-94.3475 108.0473,-99.7431\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-82.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[3]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7efd4b79e8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_logistic_regression_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sea $\\mathbf{X}$ el espacio de entrada que contiene $N$ muestras de datos. Cada muestra está descrita por $d$ características o **features**. Sea $\\mathcal{Y} = \\{-1, +1\\}$ el espacio de salida binario. El perceptrón queda definido por:\n",
    "\n",
    "\n",
    "    \n",
    "$h(\\mathbf{x}) = sign \\left( \\sum_{i=1}^{d} \\left( w_ix_i \\right) + b \\right)$\n",
    "\n",
    "Donde **sign** es la función signo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sea $\\mathbf{w} = \\{w_{0},w_{1}, w_{2}, \\dots, w_{d} \\}^T$ el vector de pesos; en donde $w_{0}=b$ y sea $\\mathbf{x} = \\{x_{0},x_{1}, x_{2}, \\dots, x_{d} \\}^T $ con $w_{0}=1$, entonces la expresión para el Perceptron se puede reescribir:\n",
    "\n",
    "$h(\\mathbf{x}) = sign \\left(  \\mathbf{w}^T \\mathbf{x} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo de aprendizaje del perceptrón\n",
    "Para realizar el entrenamiento es preciso que las muestras de datos y etiquetas (o valores) sean randomizados. Luega en cada iteración se corregirá los valores del vector $\\mathbf{w}$, mediante la siguiente expresión:\n",
    "\n",
    "$\\mathbf{w}(t+1)=\\mathbf{w}(t)+\\alpha y(t)\\mathbf{x}(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## El Perceptron  y la compuerta AND\n",
    "La compuerta **and** consta de 4 ejemplos. Cada uno con 2 características $d=2$. \n",
    "\n",
    "\n",
    "| muestra | x1 | x2 | y  |\n",
    "|---------|----|----|----|\n",
    "| 1       | -1 | -1 | -1 |\n",
    "| 2       | -1 |  1 | -1 |\n",
    "| 3       |  1 | -1 | -1 |\n",
    "| 4       |  1 | 1  |  1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "Y = np.array([-1, -1, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 4, Avg. loss: 0.750000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 8, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 12, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 16, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 20, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Rendimiento del entrenamiento: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "percept_and = Perceptron(verbose=1, shuffle=True)\n",
    "percept_and.fit(X, Y)\n",
    "print('Rendimiento del entrenamiento: {}'.format(percept_and.score(X,Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = percept_and.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "1. Verifique que la Compuerta **XOR** No tiene solución con un Perceptron\n",
    "2. Verifique que la Computerta **OR** Tiene solución con un Perceptrón\n",
    "3. Escriba un programa en Python que ejecute el algoritmo de aprendizaje del Perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales Multicapa con Alimentación hacia adelante (Feed Forward)\n",
    "Al añadir capas ocultas a una estructra de redes neuronales se amplía el espacio de hipótesis. Una red sencilla con una capa oculta con 3 perceptrones es la indicada en la siguiente figura. Observe la estructura de izquiera a derecha formada por:\n",
    "\n",
    "* Capa de entrada\n",
    "* Capa oculta\n",
    "* Capa de Salida\n",
    "\n",
    "Note que la capa de salida puede tener más nodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"252pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 252.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 248,-257 248,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"80,-35 80,-218 164,-218 164,-35 80,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"184,-89 184,-164 236,-164 236,-89 184,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- h0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>h0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[0]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.9237,-180.7762C59.1082,-157.4817 88.244,-112.7848 106.311,-85.0684\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.4488,-86.6639 111.9776,-76.3753 103.5847,-82.8414 109.4488,-86.6639\"/>\n",
       "</g>\n",
       "<!-- h1 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>h1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[1]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-190.6657C63.8004,-186.8567 80.7424,-181.6586 94.9198,-177.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-180.6026 104.6501,-174.3232 94.0634,-173.9105 96.1167,-180.6026\"/>\n",
       "</g>\n",
       "<!-- h2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>h2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[2]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-183.6978C61.5794,-170.6144 84.2611,-149.7369 100.8935,-134.4276\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5216,-136.7655 108.5089,-127.4179 98.7809,-131.6152 103.5216,-136.7655\"/>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-129.6978C61.5794,-116.6144 84.2611,-95.7369 100.8935,-80.4276\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5216,-82.7655 108.5089,-73.4179 98.7809,-77.6152 103.5216,-82.7655\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-147.3343C63.8004,-151.1433 80.7424,-156.3414 94.9198,-160.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-164.0895 104.6501,-163.6768 96.1167,-157.3974 94.0634,-164.0895\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-136.6657C63.8004,-132.8567 80.7424,-127.6586 94.9198,-123.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-126.6026 104.6501,-120.3232 94.0634,-119.9105 96.1167,-126.6026\"/>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-82.6657C63.8004,-78.8567 80.7424,-73.6586 94.9198,-69.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-72.6026 104.6501,-66.3232 94.0634,-65.9105 96.1167,-72.6026\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-100.3022C61.5794,-113.3856 84.2611,-134.2631 100.8935,-149.5724\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.7809,-152.3848 108.5089,-156.5821 103.5216,-147.2345 98.7809,-152.3848\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h2 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-93.3343C63.8004,-97.1433 80.7424,-102.3414 94.9198,-106.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-110.0895 104.6501,-109.6768 96.1167,-103.3974 94.0634,-110.0895\"/>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-39.3343C63.8004,-43.1433 80.7424,-48.3414 94.9198,-52.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-56.0895 104.6501,-55.6768 96.1167,-49.3974 94.0634,-56.0895\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.9237,-49.2238C59.1082,-72.5183 88.244,-117.2152 106.311,-144.9316\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5847,-147.1586 111.9776,-153.6247 109.4488,-143.3361 103.5847,-147.1586\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h2 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-46.3022C61.5794,-59.3856 84.2611,-80.2631 100.8935,-95.5724\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.7809,-98.3848 108.5089,-102.5821 103.5216,-93.2345 98.7809,-98.3848\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"210\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- h0&#45;&gt;y -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>h0&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.7326,-70.6541C150.9973,-78.7938 170.2058,-90.5808 185.4857,-99.9571\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.0498,-103.1824 194.4036,-105.4295 187.7109,-97.2161 184.0498,-103.1824\"/>\n",
       "</g>\n",
       "<!-- h1&#45;&gt;y -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>h1&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.7326,-159.3459C150.9973,-151.2062 170.2058,-139.4192 185.4857,-130.0429\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7109,-132.7839 194.4036,-124.5705 184.0498,-126.8176 187.7109,-132.7839\"/>\n",
       "</g>\n",
       "<!-- h2&#45;&gt;y -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>h2&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.2337,-115C152.1508,-115 167.9616,-115 181.5183,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.7897,-118.5001 191.7897,-115 181.7897,-111.5001 181.7897,-118.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7efd4b79eeb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_single_hidden_layer_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La complejidad del problema puede requerir incrementar el número de capas ocultas. Para entrenar este tipo de redes se necesita el algoritmo de **back propagation** o retropropagación del error, ya que al tener varias neuronas en una capa oculta se dispone de un vector de hipótesis cuyos valores correctos no se conocen previamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"378pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 378.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 374,-257 374,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"80,-35 80,-218 175,-218 175,-35 80,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer 1</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"195,-35 195,-218 290,-218 290,-35 195,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer 2</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"310,-89 310,-164 362,-164 362,-89 310,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- h1[0] -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>h1[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[0]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.308,-181.0368C60.4387,-157.6212 91.7762,-112.1314 110.9005,-84.3702\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.8551,-86.2509 116.6459,-76.0302 108.0905,-82.2797 113.8551,-86.2509\"/>\n",
       "</g>\n",
       "<!-- h1[1] -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>h1[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[1]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-190.9215C65.1319,-186.9617 84.3149,-181.3924 99.9321,-176.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-180.2051 109.5858,-174.0557 99.0065,-173.4827 100.9582,-180.2051\"/>\n",
       "</g>\n",
       "<!-- h1[2] -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>h1[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[2]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-184.0482C62.9704,-170.7677 87.7855,-149.1546 105.5924,-133.6453\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.9791,-136.208 113.2212,-127.0009 103.3816,-130.9294 107.9791,-136.208\"/>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-130.0482C62.9704,-116.7677 87.7855,-95.1546 105.5924,-79.6453\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.9791,-82.208 113.2212,-73.0009 103.3816,-76.9294 107.9791,-82.208\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-147.0785C65.1319,-151.0383 84.3149,-156.6076 99.9321,-161.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-164.5173 109.5858,-163.9443 100.9582,-157.7949 99.0065,-164.5173\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-136.9215C65.1319,-132.9617 84.3149,-127.3924 99.9321,-122.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-126.2051 109.5858,-120.0557 99.0065,-119.4827 100.9582,-126.2051\"/>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-82.9215C65.1319,-78.9617 84.3149,-73.3924 99.9321,-68.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-72.2051 109.5858,-66.0557 99.0065,-65.4827 100.9582,-72.2051\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-99.9518C62.9704,-113.2323 87.7855,-134.8454 105.5924,-150.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3816,-153.0706 113.2212,-156.9991 107.9791,-147.792 103.3816,-153.0706\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-93.0785C65.1319,-97.0383 84.3149,-102.6076 99.9321,-107.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-110.5173 109.5858,-109.9443 100.9582,-103.7949 99.0065,-110.5173\"/>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-39.0785C65.1319,-43.0383 84.3149,-48.6076 99.9321,-53.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-56.5173 109.5858,-55.9443 100.9582,-49.7949 99.0065,-56.5173\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.308,-48.9632C60.4387,-72.3788 91.7762,-117.8686 110.9005,-145.6298\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0905,-147.7203 116.6459,-153.9698 113.8551,-143.7491 108.0905,-147.7203\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-45.9518C62.9704,-59.2323 87.7855,-80.8454 105.5924,-96.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3816,-99.0706 113.2212,-102.9991 107.9791,-93.792 103.3816,-99.0706\"/>\n",
       "</g>\n",
       "<!-- h2[0] -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>h2[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[0]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-61C163.6433,-61 192.3671,-61 213.7431,-61\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-64.5001 223.8632,-61 213.8631,-57.5001 213.8632,-64.5001\"/>\n",
       "</g>\n",
       "<!-- h2[1] -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>h2[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[1]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.192,-73.389C160.0161,-92.0064 197.669,-127.3674 221.211,-149.4764\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.9222,-152.1284 228.6077,-156.4228 223.7142,-147.0258 218.9222,-152.1284\"/>\n",
       "</g>\n",
       "<!-- h2[2] -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>h2[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[2]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-68.7369C162.5201,-77.679 194.0899,-92.5031 216.3526,-102.9569\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0145,-106.1951 225.5539,-107.2775 217.9898,-99.8589 215.0145,-106.1951\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.192,-156.611C160.0161,-137.9936 197.669,-102.6326 221.211,-80.5236\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"223.7142,-82.9742 228.6077,-73.5772 218.9222,-77.8716 223.7142,-82.9742\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-169C163.6433,-169 192.3671,-169 213.7431,-169\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-172.5001 223.8632,-169 213.8631,-165.5001 213.8632,-172.5001\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-161.2631C162.5201,-152.321 194.0899,-137.4969 216.3526,-127.0431\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.9898,-130.1411 225.5539,-122.7225 215.0145,-123.8049 217.9898,-130.1411\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-107.2631C162.5201,-98.321 194.0899,-83.4969 216.3526,-73.0431\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.9898,-76.1411 225.5539,-68.7225 215.0145,-69.8049 217.9898,-76.1411\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-122.7369C162.5201,-131.679 194.0899,-146.5031 216.3526,-156.9569\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0145,-160.1951 225.5539,-161.2775 217.9898,-153.8589 215.0145,-160.1951\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-115C163.6433,-115 192.3671,-115 213.7431,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-118.5001 223.8632,-115 213.8631,-111.5001 213.8632,-118.5001\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"336\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- h2[0]&#45;&gt;y -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>h2[0]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M257.9458,-70.1604C272.6188,-78.5895 294.6007,-91.2174 311.5017,-100.9265\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"309.8752,-104.0285 320.2897,-105.9749 313.3621,-97.9588 309.8752,-104.0285\"/>\n",
       "</g>\n",
       "<!-- h2[1]&#45;&gt;y -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>h2[1]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M257.9458,-159.8396C272.6188,-151.4105 294.6007,-138.7826 311.5017,-129.0735\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.3621,-132.0412 320.2897,-124.0251 309.8752,-125.9715 313.3621,-132.0412\"/>\n",
       "</g>\n",
       "<!-- h2[2]&#45;&gt;y -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>h2[2]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M260.1241,-115C273.6484,-115 292.3808,-115 307.8486,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.9315,-118.5001 317.9315,-115 307.9315,-111.5001 307.9315,-118.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7efd4b758438>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_two_hidden_layer_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "Utilice una red neuronal multicapa para clasificar los datos del dataset moons, con:\n",
    "* Algoritmo de descenso de gradiente estocástico,\n",
    "* 50 neuronas en la capa oculta,\n",
    "* Función de activación relu, luego con sigmoid\n",
    "* Pruebe con algoritmo lbfgs y sgd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Realicemos un plot de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], c=y, cmap=cm_bright)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42) #, stratify=y\n",
    "red = MLPClassifier(hidden_layer_sizes=(50,), \n",
    "                    solver='lbfgs', \n",
    "#                     learning_rate_init=0.0001, \n",
    "#                     activation='relu', \n",
    "                    random_state=0, \n",
    "                    verbose=True, \n",
    "                    max_iter=1000)\n",
    "history = red.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31702684, -0.2525239 ],\n",
       "       [ 1.15536561, -0.50593577],\n",
       "       [ 1.31311917, -0.69665985],\n",
       "       [ 0.8729088 ,  0.08643291],\n",
       "       [ 1.72532644,  0.53367598],\n",
       "       [-0.4993884 ,  0.13192906],\n",
       "       [ 0.35940317,  0.84867003],\n",
       "       [-0.16955317,  0.60660877],\n",
       "       [ 1.50917461, -0.06701048],\n",
       "       [ 0.36877983, -0.34894509],\n",
       "       [-0.7280717 ,  0.3259131 ],\n",
       "       [ 0.77145295, -0.69709227],\n",
       "       [ 1.00549331,  0.38686701],\n",
       "       [-0.74872343, -0.06972957],\n",
       "       [ 1.89948318,  0.79928869],\n",
       "       [-0.87006365,  0.70686285],\n",
       "       [ 1.12856036,  0.33191968],\n",
       "       [ 0.97370054, -0.08631168],\n",
       "       [ 0.89715307,  0.94175457],\n",
       "       [-0.51699811,  0.74457804],\n",
       "       [-0.59385445,  0.46769065],\n",
       "       [-0.46333991,  0.86330772],\n",
       "       [ 0.55039452,  1.16554689],\n",
       "       [-0.60690411,  0.50000529],\n",
       "       [ 0.42598043, -0.3006242 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La precisión sobre el dataset de entrenamiento es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = red.score(X_train, y_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La precisión sobre el dataset de prueba es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = red.score(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_2d_separator(red, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train) \n",
    "plt.xlabel(\"Feature 0\") \n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio\n",
    "Resuelva el problema del perceptron con 2 neuronas en la capa oculta. Considere utilizar una función de activación apropiada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "Y = np.array([[-1], [1], [1],[-1] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pruebe el código utiliznado:\n",
    "1. SGD\n",
    "2. lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "red_xor = MLPClassifier(hidden_layer_sizes=(2,2),\n",
    "                        activation='tanh',\n",
    "                        solver='lbfgs',\n",
    "                        max_iter=1500, verbose=1)\n",
    "#lbfgs / lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenando la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(2, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_xor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_xor.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = red_xor.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_grafico = [-1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], c=y_grafico, cmap=cm_bright)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_2d_separator(red_xor, X, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y_grafico) \n",
    "plt.xlabel(\"Feature 0\") \n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicios adicionales\n",
    "Resuelva con una arquitectura de red neuronal feed forward multicapa el dataset iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Red Neuronal como Regresión\n",
    "Considere una función $y = x^2-2x+3$. Para el intervalo de $[-5, 5]$ Obtenga 1000 puntos. Puede hacer que la red neuronal reproduzca esta función en el Intervalo propuesto?\n",
    "\n",
    "Que pasa si incrementa el dataset a 2000 muestras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5, num=2000)\n",
    "# x = np.arange(10)\n",
    "y = x*x-2*x+3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.       , -4.9949975, -4.989995 , ...,  4.989995 ,  4.9949975,\n",
       "        5.       ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 104.54274586\n",
      "Iteration 2, loss = 93.70256841\n",
      "Iteration 3, loss = 83.31303183\n",
      "Iteration 4, loss = 73.02388197\n",
      "Iteration 5, loss = 62.78668769\n",
      "Iteration 6, loss = 52.38647833\n",
      "Iteration 7, loss = 42.16415699\n",
      "Iteration 8, loss = 32.67310074\n",
      "Iteration 9, loss = 24.41457486\n",
      "Iteration 10, loss = 17.28583361\n",
      "Iteration 11, loss = 11.84024295\n",
      "Iteration 12, loss = 7.96522695\n",
      "Iteration 13, loss = 5.65010431\n",
      "Iteration 14, loss = 4.35257779\n",
      "Iteration 15, loss = 3.78914838\n",
      "Iteration 16, loss = 3.54399713\n",
      "Iteration 17, loss = 3.43101724\n",
      "Iteration 18, loss = 3.33078869\n",
      "Iteration 19, loss = 3.24122221\n",
      "Iteration 20, loss = 3.15508905\n",
      "Iteration 21, loss = 3.07238756\n",
      "Iteration 22, loss = 2.99488687\n",
      "Iteration 23, loss = 2.92023646\n",
      "Iteration 24, loss = 2.85067419\n",
      "Iteration 25, loss = 2.78062203\n",
      "Iteration 26, loss = 2.71592701\n",
      "Iteration 27, loss = 2.65240131\n",
      "Iteration 28, loss = 2.59224316\n",
      "Iteration 29, loss = 2.53262906\n",
      "Iteration 30, loss = 2.47799061\n",
      "Iteration 31, loss = 2.42171980\n",
      "Iteration 32, loss = 2.36893930\n",
      "Iteration 33, loss = 2.31621151\n",
      "Iteration 34, loss = 2.26686164\n",
      "Iteration 35, loss = 2.21701225\n",
      "Iteration 36, loss = 2.17025492\n",
      "Iteration 37, loss = 2.12373427\n",
      "Iteration 38, loss = 2.07859874\n",
      "Iteration 39, loss = 2.03494753\n",
      "Iteration 40, loss = 1.99186902\n",
      "Iteration 41, loss = 1.94960788\n",
      "Iteration 42, loss = 1.90960089\n",
      "Iteration 43, loss = 1.86983864\n",
      "Iteration 44, loss = 1.83034670\n",
      "Iteration 45, loss = 1.79260293\n",
      "Iteration 46, loss = 1.75551880\n",
      "Iteration 47, loss = 1.71899510\n",
      "Iteration 48, loss = 1.68464164\n",
      "Iteration 49, loss = 1.64999208\n",
      "Iteration 50, loss = 1.61517620\n",
      "Iteration 51, loss = 1.58256298\n",
      "Iteration 52, loss = 1.55136969\n",
      "Iteration 53, loss = 1.52026777\n",
      "Iteration 54, loss = 1.48874224\n",
      "Iteration 55, loss = 1.45882898\n",
      "Iteration 56, loss = 1.42995182\n",
      "Iteration 57, loss = 1.40145083\n",
      "Iteration 58, loss = 1.37446954\n",
      "Iteration 59, loss = 1.34680104\n",
      "Iteration 60, loss = 1.32089744\n",
      "Iteration 61, loss = 1.29504458\n",
      "Iteration 62, loss = 1.26930053\n",
      "Iteration 63, loss = 1.24595251\n",
      "Iteration 64, loss = 1.22035205\n",
      "Iteration 65, loss = 1.19667927\n",
      "Iteration 66, loss = 1.17307017\n",
      "Iteration 67, loss = 1.14987033\n",
      "Iteration 68, loss = 1.12796113\n",
      "Iteration 69, loss = 1.10540228\n",
      "Iteration 70, loss = 1.08370507\n",
      "Iteration 71, loss = 1.06233928\n",
      "Iteration 72, loss = 1.04210165\n",
      "Iteration 73, loss = 1.02024516\n",
      "Iteration 74, loss = 0.99981336\n",
      "Iteration 75, loss = 0.97953259\n",
      "Iteration 76, loss = 0.96019902\n",
      "Iteration 77, loss = 0.93950348\n",
      "Iteration 78, loss = 0.91996535\n",
      "Iteration 79, loss = 0.90157464\n",
      "Iteration 80, loss = 0.88137390\n",
      "Iteration 81, loss = 0.86255243\n",
      "Iteration 82, loss = 0.84437419\n",
      "Iteration 83, loss = 0.82539668\n",
      "Iteration 84, loss = 0.80755612\n",
      "Iteration 85, loss = 0.78941369\n",
      "Iteration 86, loss = 0.77186993\n",
      "Iteration 87, loss = 0.75419060\n",
      "Iteration 88, loss = 0.73726796\n",
      "Iteration 89, loss = 0.72034886\n",
      "Iteration 90, loss = 0.70300122\n",
      "Iteration 91, loss = 0.68729450\n",
      "Iteration 92, loss = 0.67059685\n",
      "Iteration 93, loss = 0.65383697\n",
      "Iteration 94, loss = 0.63767063\n",
      "Iteration 95, loss = 0.62166496\n",
      "Iteration 96, loss = 0.60636021\n",
      "Iteration 97, loss = 0.59112644\n",
      "Iteration 98, loss = 0.57687688\n",
      "Iteration 99, loss = 0.56103143\n",
      "Iteration 100, loss = 0.54665567\n",
      "Iteration 101, loss = 0.53211990\n",
      "Iteration 102, loss = 0.51841471\n",
      "Iteration 103, loss = 0.50482769\n",
      "Iteration 104, loss = 0.49084855\n",
      "Iteration 105, loss = 0.47775408\n",
      "Iteration 106, loss = 0.46497611\n",
      "Iteration 107, loss = 0.45205594\n",
      "Iteration 108, loss = 0.43968209\n",
      "Iteration 109, loss = 0.42758849\n",
      "Iteration 110, loss = 0.41680837\n",
      "Iteration 111, loss = 0.40469209\n",
      "Iteration 112, loss = 0.39336360\n",
      "Iteration 113, loss = 0.38191917\n",
      "Iteration 114, loss = 0.37142731\n",
      "Iteration 115, loss = 0.36099589\n",
      "Iteration 116, loss = 0.35082540\n",
      "Iteration 117, loss = 0.34118168\n",
      "Iteration 118, loss = 0.33187310\n",
      "Iteration 119, loss = 0.32244874\n",
      "Iteration 120, loss = 0.31340898\n",
      "Iteration 121, loss = 0.30453773\n",
      "Iteration 122, loss = 0.29617929\n",
      "Iteration 123, loss = 0.28778381\n",
      "Iteration 124, loss = 0.27986314\n",
      "Iteration 125, loss = 0.27208278\n",
      "Iteration 126, loss = 0.26462541\n",
      "Iteration 127, loss = 0.25910397\n",
      "Iteration 128, loss = 0.25231234\n",
      "Iteration 129, loss = 0.24330477\n",
      "Iteration 130, loss = 0.23673786\n",
      "Iteration 131, loss = 0.23064194\n",
      "Iteration 132, loss = 0.22381774\n",
      "Iteration 133, loss = 0.21766159\n",
      "Iteration 134, loss = 0.21178861\n",
      "Iteration 135, loss = 0.20667277\n",
      "Iteration 136, loss = 0.20014598\n",
      "Iteration 137, loss = 0.19519027\n",
      "Iteration 138, loss = 0.18955946\n",
      "Iteration 139, loss = 0.18449809\n",
      "Iteration 140, loss = 0.17937331\n",
      "Iteration 141, loss = 0.17467651\n",
      "Iteration 142, loss = 0.16969354\n",
      "Iteration 143, loss = 0.16580487\n",
      "Iteration 144, loss = 0.16104067\n",
      "Iteration 145, loss = 0.15649059\n",
      "Iteration 146, loss = 0.15224629\n",
      "Iteration 147, loss = 0.14824049\n",
      "Iteration 148, loss = 0.14438588\n",
      "Iteration 149, loss = 0.14045773\n",
      "Iteration 150, loss = 0.13680276\n",
      "Iteration 151, loss = 0.13308519\n",
      "Iteration 152, loss = 0.13029918\n",
      "Iteration 153, loss = 0.12616788\n",
      "Iteration 154, loss = 0.12326751\n",
      "Iteration 155, loss = 0.11943398\n",
      "Iteration 156, loss = 0.11663096\n",
      "Iteration 157, loss = 0.11389504\n",
      "Iteration 158, loss = 0.11065942\n",
      "Iteration 159, loss = 0.10764596\n",
      "Iteration 160, loss = 0.10523909\n",
      "Iteration 161, loss = 0.10256153\n",
      "Iteration 162, loss = 0.09971177\n",
      "Iteration 163, loss = 0.09704684\n",
      "Iteration 164, loss = 0.09477342\n",
      "Iteration 165, loss = 0.09224754\n",
      "Iteration 166, loss = 0.08989922\n",
      "Iteration 167, loss = 0.08747285\n",
      "Iteration 168, loss = 0.08537470\n",
      "Iteration 169, loss = 0.08361705\n",
      "Iteration 170, loss = 0.08156793\n",
      "Iteration 171, loss = 0.07908367\n",
      "Iteration 172, loss = 0.07748799\n",
      "Iteration 173, loss = 0.07524190\n",
      "Iteration 174, loss = 0.07407402\n",
      "Iteration 175, loss = 0.07171263\n",
      "Iteration 176, loss = 0.07033584\n",
      "Iteration 177, loss = 0.06833562\n",
      "Iteration 178, loss = 0.06694904\n",
      "Iteration 179, loss = 0.06516413\n",
      "Iteration 180, loss = 0.06364775\n",
      "Iteration 181, loss = 0.06245319\n",
      "Iteration 182, loss = 0.06106659\n",
      "Iteration 183, loss = 0.05942671\n",
      "Iteration 184, loss = 0.05819519\n",
      "Iteration 185, loss = 0.05671902\n",
      "Iteration 186, loss = 0.05548366\n",
      "Iteration 187, loss = 0.05421996\n",
      "Iteration 188, loss = 0.05317606\n",
      "Iteration 189, loss = 0.05192455\n",
      "Iteration 190, loss = 0.05074059\n",
      "Iteration 191, loss = 0.04993614\n",
      "Iteration 192, loss = 0.04866733\n",
      "Iteration 193, loss = 0.04745871\n",
      "Iteration 194, loss = 0.04647147\n",
      "Iteration 195, loss = 0.04553039\n",
      "Iteration 196, loss = 0.04492018\n",
      "Iteration 197, loss = 0.04355938\n",
      "Iteration 198, loss = 0.04270807\n",
      "Iteration 199, loss = 0.04171559\n",
      "Iteration 200, loss = 0.04086161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(500,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "red_funcion = MLPRegressor(hidden_layer_sizes=(500,), solver='adam', activation='relu', verbose=1)\n",
    "red_funcion.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991146427710008"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_funcion.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(-5,5,500)\n",
    "y_real = x_test*x_test-2*x_test+3\n",
    "x_test = x_test.reshape(-1,1)\n",
    "# x_test\n",
    "y_pred = red_funcion.predict(x_test)\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_test, y_real, color='blue')\n",
    "plt.plot(x_test, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¿Qué sucede si deseo calcular para un valor fuera del rango como por ejemplo $x=5.5$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num = 16.\n",
    "y_num = x_num*x_num-2*x_num+3\n",
    "y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.91845536])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num = np.asarray(x_num)\n",
    "x_num = x_num.reshape(-1,1)\n",
    "y_num_pred = red_funcion.predict(x_num)\n",
    "y_num_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolviendo el problema de clasificación del iris dataset\n",
    "Considere el problema de clasificar las flores iris según la longitud y ancho del sépalo y el pétolo. Resuelva este problema utilizando Redes Neuronales Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "print(iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primeros 5 datos del dataset son $\\mathbf{\\mathcal{X}}:$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset['data'][0:5,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas para las **muestras** o **samples** anteriores son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset['target'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso los datos del iris dataset a una variable $\\mathbf{\\mathcal{X}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_dataset['data']\n",
    "Y = iris_dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificando las clases como **ONE HOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_one_hot = np_utils.to_categorical(Y)\n",
    "Y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalando los valores de $\\mathbf{\\mathcal{X}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.84333333 3.05733333 3.758      1.19933333]\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "min 0.1\n",
      "max 7.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "funcion_escalado = scaler.fit(X)\n",
    "X_escalado = X\n",
    "# X_escalado = funcion_escalado.transform(X)\n",
    "print(scaler.mean_)\n",
    "print(X_escalado[0:5,:])\n",
    "print('min {}'.format(X_escalado.min()))\n",
    "print('max {}'.format(X_escalado.max()))\n",
    "# StandardScaler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiendo el dataset en train y test. Los datos se deben aleatorizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2, 2.8, 4.8, 1.8],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [5.4, 3. , 4.5, 1.5]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_escalado, Y_one_hot, test_size=0.2, random_state=2)\n",
    "X_train[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_iris = MLPClassifier(hidden_layer_sizes=(3,),\n",
    "                        activation='tanh',\n",
    "                        solver='sgd',\n",
    "                        momentum=0.95,\n",
    "                        max_iter=1500, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.57848298\n",
      "Iteration 2, loss = 2.57647467\n",
      "Iteration 3, loss = 2.57354228\n",
      "Iteration 4, loss = 2.56973783\n",
      "Iteration 5, loss = 2.56511221\n",
      "Iteration 6, loss = 2.55971511\n",
      "Iteration 7, loss = 2.55359498\n",
      "Iteration 8, loss = 2.54679899\n",
      "Iteration 9, loss = 2.53937299\n",
      "Iteration 10, loss = 2.53136154\n",
      "Iteration 11, loss = 2.52280789\n",
      "Iteration 12, loss = 2.51375394\n",
      "Iteration 13, loss = 2.50424034\n",
      "Iteration 14, loss = 2.49430638\n",
      "Iteration 15, loss = 2.48399011\n",
      "Iteration 16, loss = 2.47332831\n",
      "Iteration 17, loss = 2.46235647\n",
      "Iteration 18, loss = 2.45110889\n",
      "Iteration 19, loss = 2.43961861\n",
      "Iteration 20, loss = 2.42791749\n",
      "Iteration 21, loss = 2.41603619\n",
      "Iteration 22, loss = 2.40400422\n",
      "Iteration 23, loss = 2.39184990\n",
      "Iteration 24, loss = 2.37960042\n",
      "Iteration 25, loss = 2.36728185\n",
      "Iteration 26, loss = 2.35491914\n",
      "Iteration 27, loss = 2.34253612\n",
      "Iteration 28, loss = 2.33015555\n",
      "Iteration 29, loss = 2.31779908\n",
      "Iteration 30, loss = 2.30548731\n",
      "Iteration 31, loss = 2.29323978\n",
      "Iteration 32, loss = 2.28107495\n",
      "Iteration 33, loss = 2.26901027\n",
      "Iteration 34, loss = 2.25706215\n",
      "Iteration 35, loss = 2.24524597\n",
      "Iteration 36, loss = 2.23357611\n",
      "Iteration 37, loss = 2.22206597\n",
      "Iteration 38, loss = 2.21072794\n",
      "Iteration 39, loss = 2.19957346\n",
      "Iteration 40, loss = 2.18861300\n",
      "Iteration 41, loss = 2.17785612\n",
      "Iteration 42, loss = 2.16731143\n",
      "Iteration 43, loss = 2.15698667\n",
      "Iteration 44, loss = 2.14688869\n",
      "Iteration 45, loss = 2.13702346\n",
      "Iteration 46, loss = 2.12739617\n",
      "Iteration 47, loss = 2.11801114\n",
      "Iteration 48, loss = 2.10887195\n",
      "Iteration 49, loss = 2.09998141\n",
      "Iteration 50, loss = 2.09134161\n",
      "Iteration 51, loss = 2.08295394\n",
      "Iteration 52, loss = 2.07481912\n",
      "Iteration 53, loss = 2.06693724\n",
      "Iteration 54, loss = 2.05930780\n",
      "Iteration 55, loss = 2.05192971\n",
      "Iteration 56, loss = 2.04480138\n",
      "Iteration 57, loss = 2.03792068\n",
      "Iteration 58, loss = 2.03128505\n",
      "Iteration 59, loss = 2.02489147\n",
      "Iteration 60, loss = 2.01873654\n",
      "Iteration 61, loss = 2.01281649\n",
      "Iteration 62, loss = 2.00712722\n",
      "Iteration 63, loss = 2.00166432\n",
      "Iteration 64, loss = 1.99642314\n",
      "Iteration 65, loss = 1.99139877\n",
      "Iteration 66, loss = 1.98658610\n",
      "Iteration 67, loss = 1.98197985\n",
      "Iteration 68, loss = 1.97757457\n",
      "Iteration 69, loss = 1.97336472\n",
      "Iteration 70, loss = 1.96934463\n",
      "Iteration 71, loss = 1.96550857\n",
      "Iteration 72, loss = 1.96185077\n",
      "Iteration 73, loss = 1.95836541\n",
      "Iteration 74, loss = 1.95504668\n",
      "Iteration 75, loss = 1.95188874\n",
      "Iteration 76, loss = 1.94888583\n",
      "Iteration 77, loss = 1.94603218\n",
      "Iteration 78, loss = 1.94332210\n",
      "Iteration 79, loss = 1.94074998\n",
      "Iteration 80, loss = 1.93831026\n",
      "Iteration 81, loss = 1.93599748\n",
      "Iteration 82, loss = 1.93380630\n",
      "Iteration 83, loss = 1.93173145\n",
      "Iteration 84, loss = 1.92976781\n",
      "Iteration 85, loss = 1.92791036\n",
      "Iteration 86, loss = 1.92615421\n",
      "Iteration 87, loss = 1.92449460\n",
      "Iteration 88, loss = 1.92292691\n",
      "Iteration 89, loss = 1.92144663\n",
      "Iteration 90, loss = 1.92004942\n",
      "Iteration 91, loss = 1.91873105\n",
      "Iteration 92, loss = 1.91748746\n",
      "Iteration 93, loss = 1.91631469\n",
      "Iteration 94, loss = 1.91520895\n",
      "Iteration 95, loss = 1.91416656\n",
      "Iteration 96, loss = 1.91318399\n",
      "Iteration 97, loss = 1.91225784\n",
      "Iteration 98, loss = 1.91138485\n",
      "Iteration 99, loss = 1.91056186\n",
      "Iteration 100, loss = 1.90978585\n",
      "Iteration 101, loss = 1.90905394\n",
      "Iteration 102, loss = 1.90836332\n",
      "Iteration 103, loss = 1.90771135\n",
      "Iteration 104, loss = 1.90709545\n",
      "Iteration 105, loss = 1.90651318\n",
      "Iteration 106, loss = 1.90596218\n",
      "Iteration 107, loss = 1.90544021\n",
      "Iteration 108, loss = 1.90494511\n",
      "Iteration 109, loss = 1.90447479\n",
      "Iteration 110, loss = 1.90402728\n",
      "Iteration 111, loss = 1.90360067\n",
      "Iteration 112, loss = 1.90319313\n",
      "Iteration 113, loss = 1.90280290\n",
      "Iteration 114, loss = 1.90242828\n",
      "Iteration 115, loss = 1.90206765\n",
      "Iteration 116, loss = 1.90171941\n",
      "Iteration 117, loss = 1.90138206\n",
      "Iteration 118, loss = 1.90105410\n",
      "Iteration 119, loss = 1.90073411\n",
      "Iteration 120, loss = 1.90042069\n",
      "Iteration 121, loss = 1.90011246\n",
      "Iteration 122, loss = 1.89980809\n",
      "Iteration 123, loss = 1.89950625\n",
      "Iteration 124, loss = 1.89920565\n",
      "Iteration 125, loss = 1.89890497\n",
      "Iteration 126, loss = 1.89860294\n",
      "Iteration 127, loss = 1.89829826\n",
      "Iteration 128, loss = 1.89798962\n",
      "Iteration 129, loss = 1.89767570\n",
      "Iteration 130, loss = 1.89735517\n",
      "Iteration 131, loss = 1.89702664\n",
      "Iteration 132, loss = 1.89668871\n",
      "Iteration 133, loss = 1.89633992\n",
      "Iteration 134, loss = 1.89597876\n",
      "Iteration 135, loss = 1.89560364\n",
      "Iteration 136, loss = 1.89521292\n",
      "Iteration 137, loss = 1.89480484\n",
      "Iteration 138, loss = 1.89437758\n",
      "Iteration 139, loss = 1.89392918\n",
      "Iteration 140, loss = 1.89345758\n",
      "Iteration 141, loss = 1.89296055\n",
      "Iteration 142, loss = 1.89243576\n",
      "Iteration 143, loss = 1.89188065\n",
      "Iteration 144, loss = 1.89129254\n",
      "Iteration 145, loss = 1.89066850\n",
      "Iteration 146, loss = 1.89000541\n",
      "Iteration 147, loss = 1.88929992\n",
      "Iteration 148, loss = 1.88854841\n",
      "Iteration 149, loss = 1.88774700\n",
      "Iteration 150, loss = 1.88689154\n",
      "Iteration 151, loss = 1.88597759\n",
      "Iteration 152, loss = 1.88500040\n",
      "Iteration 153, loss = 1.88395492\n",
      "Iteration 154, loss = 1.88283579\n",
      "Iteration 155, loss = 1.88163739\n",
      "Iteration 156, loss = 1.88035380\n",
      "Iteration 157, loss = 1.87897891\n",
      "Iteration 158, loss = 1.87750640\n",
      "Iteration 159, loss = 1.87592985\n",
      "Iteration 160, loss = 1.87424285\n",
      "Iteration 161, loss = 1.87243904\n",
      "Iteration 162, loss = 1.87051231\n",
      "Iteration 163, loss = 1.86845689\n",
      "Iteration 164, loss = 1.86626755\n",
      "Iteration 165, loss = 1.86393970\n",
      "Iteration 166, loss = 1.86146955\n",
      "Iteration 167, loss = 1.85885417\n",
      "Iteration 168, loss = 1.85609158\n",
      "Iteration 169, loss = 1.85318061\n",
      "Iteration 170, loss = 1.85012084\n",
      "Iteration 171, loss = 1.84691233\n",
      "Iteration 172, loss = 1.84355531\n",
      "Iteration 173, loss = 1.84004985\n",
      "Iteration 174, loss = 1.83639558\n",
      "Iteration 175, loss = 1.83259150\n",
      "Iteration 176, loss = 1.82863605\n",
      "Iteration 177, loss = 1.82452744\n",
      "Iteration 178, loss = 1.82026437\n",
      "Iteration 179, loss = 1.81584705\n",
      "Iteration 180, loss = 1.81127859\n",
      "Iteration 181, loss = 1.80656646\n",
      "Iteration 182, loss = 1.80172397\n",
      "Iteration 183, loss = 1.79677139\n",
      "Iteration 184, loss = 1.79173656\n",
      "Iteration 185, loss = 1.78665463\n",
      "Iteration 186, loss = 1.78156686\n",
      "Iteration 187, loss = 1.77651849\n",
      "Iteration 188, loss = 1.77155576\n",
      "Iteration 189, loss = 1.76672248\n",
      "Iteration 190, loss = 1.76205668\n",
      "Iteration 191, loss = 1.75758763\n",
      "Iteration 192, loss = 1.75333372\n",
      "Iteration 193, loss = 1.74930139\n",
      "Iteration 194, loss = 1.74548514\n",
      "Iteration 195, loss = 1.74186843\n",
      "Iteration 196, loss = 1.73842543\n",
      "Iteration 197, loss = 1.73512311\n",
      "Iteration 198, loss = 1.73192366\n",
      "Iteration 199, loss = 1.72878689\n",
      "Iteration 200, loss = 1.72567250\n",
      "Iteration 201, loss = 1.72254206\n",
      "Iteration 202, loss = 1.71936075\n",
      "Iteration 203, loss = 1.71609860\n",
      "Iteration 204, loss = 1.71273149\n",
      "Iteration 205, loss = 1.70924167\n",
      "Iteration 206, loss = 1.70561800\n",
      "Iteration 207, loss = 1.70185579\n",
      "Iteration 208, loss = 1.69795645\n",
      "Iteration 209, loss = 1.69392684\n",
      "Iteration 210, loss = 1.68977853\n",
      "Iteration 211, loss = 1.68552685\n",
      "Iteration 212, loss = 1.68118997\n",
      "Iteration 213, loss = 1.67678789\n",
      "Iteration 214, loss = 1.67234155\n",
      "Iteration 215, loss = 1.66787192\n",
      "Iteration 216, loss = 1.66339924\n",
      "Iteration 217, loss = 1.65894237\n",
      "Iteration 218, loss = 1.65451828\n",
      "Iteration 219, loss = 1.65014163\n",
      "Iteration 220, loss = 1.64582453\n",
      "Iteration 221, loss = 1.64157641\n",
      "Iteration 222, loss = 1.63740402\n",
      "Iteration 223, loss = 1.63331147\n",
      "Iteration 224, loss = 1.62930045\n",
      "Iteration 225, loss = 1.62537046\n",
      "Iteration 226, loss = 1.62151909\n",
      "Iteration 227, loss = 1.61774235\n",
      "Iteration 228, loss = 1.61403502\n",
      "Iteration 229, loss = 1.61039103\n",
      "Iteration 230, loss = 1.60680378\n",
      "Iteration 231, loss = 1.60326645\n",
      "Iteration 232, loss = 1.59977234\n",
      "Iteration 233, loss = 1.59631510\n",
      "Iteration 234, loss = 1.59288898\n",
      "Iteration 235, loss = 1.58948892\n",
      "Iteration 236, loss = 1.58611077\n",
      "Iteration 237, loss = 1.58275128\n",
      "Iteration 238, loss = 1.57940818\n",
      "Iteration 239, loss = 1.57608013\n",
      "Iteration 240, loss = 1.57276666\n",
      "Iteration 241, loss = 1.56946810\n",
      "Iteration 242, loss = 1.56618547\n",
      "Iteration 243, loss = 1.56292035\n",
      "Iteration 244, loss = 1.55967471\n",
      "Iteration 245, loss = 1.55645083\n",
      "Iteration 246, loss = 1.55325112\n",
      "Iteration 247, loss = 1.55007799\n",
      "Iteration 248, loss = 1.54693379\n",
      "Iteration 249, loss = 1.54382065\n",
      "Iteration 250, loss = 1.54074043\n",
      "Iteration 251, loss = 1.53769471\n",
      "Iteration 252, loss = 1.53468467\n",
      "Iteration 253, loss = 1.53171114\n",
      "Iteration 254, loss = 1.52877456\n",
      "Iteration 255, loss = 1.52587505\n",
      "Iteration 256, loss = 1.52301238\n",
      "Iteration 257, loss = 1.52018601\n",
      "Iteration 258, loss = 1.51739519\n",
      "Iteration 259, loss = 1.51463896\n",
      "Iteration 260, loss = 1.51191621\n",
      "Iteration 261, loss = 1.50922571\n",
      "Iteration 262, loss = 1.50656620\n",
      "Iteration 263, loss = 1.50393640\n",
      "Iteration 264, loss = 1.50133504\n",
      "Iteration 265, loss = 1.49876094\n",
      "Iteration 266, loss = 1.49621295\n",
      "Iteration 267, loss = 1.49369004\n",
      "Iteration 268, loss = 1.49119131\n",
      "Iteration 269, loss = 1.48871594\n",
      "Iteration 270, loss = 1.48626325\n",
      "Iteration 271, loss = 1.48383268\n",
      "Iteration 272, loss = 1.48142376\n",
      "Iteration 273, loss = 1.47903612\n",
      "Iteration 274, loss = 1.47666950\n",
      "Iteration 275, loss = 1.47432370\n",
      "Iteration 276, loss = 1.47199857\n",
      "Iteration 277, loss = 1.46969402\n",
      "Iteration 278, loss = 1.46740999\n",
      "Iteration 279, loss = 1.46514643\n",
      "Iteration 280, loss = 1.46290330\n",
      "Iteration 281, loss = 1.46068057\n",
      "Iteration 282, loss = 1.45847818\n",
      "Iteration 283, loss = 1.45629606\n",
      "Iteration 284, loss = 1.45413410\n",
      "Iteration 285, loss = 1.45199218\n",
      "Iteration 286, loss = 1.44987014\n",
      "Iteration 287, loss = 1.44776780\n",
      "Iteration 288, loss = 1.44568492\n",
      "Iteration 289, loss = 1.44362128\n",
      "Iteration 290, loss = 1.44157658\n",
      "Iteration 291, loss = 1.43955054\n",
      "Iteration 292, loss = 1.43754283\n",
      "Iteration 293, loss = 1.43555314\n",
      "Iteration 294, loss = 1.43358112\n",
      "Iteration 295, loss = 1.43162643\n",
      "Iteration 296, loss = 1.42968872\n",
      "Iteration 297, loss = 1.42776766\n",
      "Iteration 298, loss = 1.42586290\n",
      "Iteration 299, loss = 1.42397412\n",
      "Iteration 300, loss = 1.42210099\n",
      "Iteration 301, loss = 1.42024323\n",
      "Iteration 302, loss = 1.41840053\n",
      "Iteration 303, loss = 1.41657263\n",
      "Iteration 304, loss = 1.41475926\n",
      "Iteration 305, loss = 1.41296017\n",
      "Iteration 306, loss = 1.41117515\n",
      "Iteration 307, loss = 1.40940397\n",
      "Iteration 308, loss = 1.40764644\n",
      "Iteration 309, loss = 1.40590236\n",
      "Iteration 310, loss = 1.40417156\n",
      "Iteration 311, loss = 1.40245386\n",
      "Iteration 312, loss = 1.40074911\n",
      "Iteration 313, loss = 1.39905714\n",
      "Iteration 314, loss = 1.39737782\n",
      "Iteration 315, loss = 1.39571100\n",
      "Iteration 316, loss = 1.39405653\n",
      "Iteration 317, loss = 1.39241428\n",
      "Iteration 318, loss = 1.39078410\n",
      "Iteration 319, loss = 1.38916587\n",
      "Iteration 320, loss = 1.38755945\n",
      "Iteration 321, loss = 1.38596470\n",
      "Iteration 322, loss = 1.38438148\n",
      "Iteration 323, loss = 1.38280966\n",
      "Iteration 324, loss = 1.38124911\n",
      "Iteration 325, loss = 1.37969969\n",
      "Iteration 326, loss = 1.37816127\n",
      "Iteration 327, loss = 1.37663370\n",
      "Iteration 328, loss = 1.37511687\n",
      "Iteration 329, loss = 1.37361062\n",
      "Iteration 330, loss = 1.37211484\n",
      "Iteration 331, loss = 1.37062939\n",
      "Iteration 332, loss = 1.36915415\n",
      "Iteration 333, loss = 1.36768898\n",
      "Iteration 334, loss = 1.36623377\n",
      "Iteration 335, loss = 1.36478839\n",
      "Iteration 336, loss = 1.36335273\n",
      "Iteration 337, loss = 1.36192666\n",
      "Iteration 338, loss = 1.36051009\n",
      "Iteration 339, loss = 1.35910289\n",
      "Iteration 340, loss = 1.35770495\n",
      "Iteration 341, loss = 1.35631618\n",
      "Iteration 342, loss = 1.35493647\n",
      "Iteration 343, loss = 1.35356573\n",
      "Iteration 344, loss = 1.35220385\n",
      "Iteration 345, loss = 1.35085074\n",
      "Iteration 346, loss = 1.34950632\n",
      "Iteration 347, loss = 1.34817048\n",
      "Iteration 348, loss = 1.34684315\n",
      "Iteration 349, loss = 1.34552423\n",
      "Iteration 350, loss = 1.34421365\n",
      "Iteration 351, loss = 1.34291132\n",
      "Iteration 352, loss = 1.34161716\n",
      "Iteration 353, loss = 1.34033110\n",
      "Iteration 354, loss = 1.33905305\n",
      "Iteration 355, loss = 1.33778293\n",
      "Iteration 356, loss = 1.33652068\n",
      "Iteration 357, loss = 1.33526622\n",
      "Iteration 358, loss = 1.33401948\n",
      "Iteration 359, loss = 1.33278038\n",
      "Iteration 360, loss = 1.33154886\n",
      "Iteration 361, loss = 1.33032484\n",
      "Iteration 362, loss = 1.32910825\n",
      "Iteration 363, loss = 1.32789903\n",
      "Iteration 364, loss = 1.32669710\n",
      "Iteration 365, loss = 1.32550241\n",
      "Iteration 366, loss = 1.32431489\n",
      "Iteration 367, loss = 1.32313446\n",
      "Iteration 368, loss = 1.32196108\n",
      "Iteration 369, loss = 1.32079467\n",
      "Iteration 370, loss = 1.31963517\n",
      "Iteration 371, loss = 1.31848252\n",
      "Iteration 372, loss = 1.31733665\n",
      "Iteration 373, loss = 1.31619752\n",
      "Iteration 374, loss = 1.31506506\n",
      "Iteration 375, loss = 1.31393922\n",
      "Iteration 376, loss = 1.31281993\n",
      "Iteration 377, loss = 1.31170713\n",
      "Iteration 378, loss = 1.31060078\n",
      "Iteration 379, loss = 1.30950082\n",
      "Iteration 380, loss = 1.30840720\n",
      "Iteration 381, loss = 1.30731985\n",
      "Iteration 382, loss = 1.30623873\n",
      "Iteration 383, loss = 1.30516379\n",
      "Iteration 384, loss = 1.30409497\n",
      "Iteration 385, loss = 1.30303223\n",
      "Iteration 386, loss = 1.30197551\n",
      "Iteration 387, loss = 1.30092477\n",
      "Iteration 388, loss = 1.29987996\n",
      "Iteration 389, loss = 1.29884102\n",
      "Iteration 390, loss = 1.29780792\n",
      "Iteration 391, loss = 1.29678060\n",
      "Iteration 392, loss = 1.29575903\n",
      "Iteration 393, loss = 1.29474314\n",
      "Iteration 394, loss = 1.29373291\n",
      "Iteration 395, loss = 1.29272828\n",
      "Iteration 396, loss = 1.29172921\n",
      "Iteration 397, loss = 1.29073565\n",
      "Iteration 398, loss = 1.28974757\n",
      "Iteration 399, loss = 1.28876492\n",
      "Iteration 400, loss = 1.28778767\n",
      "Iteration 401, loss = 1.28681576\n",
      "Iteration 402, loss = 1.28584915\n",
      "Iteration 403, loss = 1.28488781\n",
      "Iteration 404, loss = 1.28393170\n",
      "Iteration 405, loss = 1.28298077\n",
      "Iteration 406, loss = 1.28203499\n",
      "Iteration 407, loss = 1.28109432\n",
      "Iteration 408, loss = 1.28015871\n",
      "Iteration 409, loss = 1.27922814\n",
      "Iteration 410, loss = 1.27830256\n",
      "Iteration 411, loss = 1.27738193\n",
      "Iteration 412, loss = 1.27646622\n",
      "Iteration 413, loss = 1.27555539\n",
      "Iteration 414, loss = 1.27464941\n",
      "Iteration 415, loss = 1.27374824\n",
      "Iteration 416, loss = 1.27285183\n",
      "Iteration 417, loss = 1.27196017\n",
      "Iteration 418, loss = 1.27107321\n",
      "Iteration 419, loss = 1.27019092\n",
      "Iteration 420, loss = 1.26931326\n",
      "Iteration 421, loss = 1.26844020\n",
      "Iteration 422, loss = 1.26757171\n",
      "Iteration 423, loss = 1.26670775\n",
      "Iteration 424, loss = 1.26584830\n",
      "Iteration 425, loss = 1.26499331\n",
      "Iteration 426, loss = 1.26414275\n",
      "Iteration 427, loss = 1.26329660\n",
      "Iteration 428, loss = 1.26245482\n",
      "Iteration 429, loss = 1.26161739\n",
      "Iteration 430, loss = 1.26078426\n",
      "Iteration 431, loss = 1.25995541\n",
      "Iteration 432, loss = 1.25913081\n",
      "Iteration 433, loss = 1.25831042\n",
      "Iteration 434, loss = 1.25749423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 435, loss = 1.25668219\n",
      "Iteration 436, loss = 1.25587428\n",
      "Iteration 437, loss = 1.25507047\n",
      "Iteration 438, loss = 1.25427074\n",
      "Iteration 439, loss = 1.25347504\n",
      "Iteration 440, loss = 1.25268336\n",
      "Iteration 441, loss = 1.25189567\n",
      "Iteration 442, loss = 1.25111193\n",
      "Iteration 443, loss = 1.25033212\n",
      "Iteration 444, loss = 1.24955622\n",
      "Iteration 445, loss = 1.24878420\n",
      "Iteration 446, loss = 1.24801602\n",
      "Iteration 447, loss = 1.24725167\n",
      "Iteration 448, loss = 1.24649111\n",
      "Iteration 449, loss = 1.24573432\n",
      "Iteration 450, loss = 1.24498128\n",
      "Iteration 451, loss = 1.24423196\n",
      "Iteration 452, loss = 1.24348632\n",
      "Iteration 453, loss = 1.24274436\n",
      "Iteration 454, loss = 1.24200604\n",
      "Iteration 455, loss = 1.24127134\n",
      "Iteration 456, loss = 1.24054023\n",
      "Iteration 457, loss = 1.23981269\n",
      "Iteration 458, loss = 1.23908870\n",
      "Iteration 459, loss = 1.23836822\n",
      "Iteration 460, loss = 1.23765125\n",
      "Iteration 461, loss = 1.23693774\n",
      "Iteration 462, loss = 1.23622769\n",
      "Iteration 463, loss = 1.23552106\n",
      "Iteration 464, loss = 1.23481784\n",
      "Iteration 465, loss = 1.23411800\n",
      "Iteration 466, loss = 1.23342152\n",
      "Iteration 467, loss = 1.23272838\n",
      "Iteration 468, loss = 1.23203854\n",
      "Iteration 469, loss = 1.23135200\n",
      "Iteration 470, loss = 1.23066873\n",
      "Iteration 471, loss = 1.22998871\n",
      "Iteration 472, loss = 1.22931192\n",
      "Iteration 473, loss = 1.22863833\n",
      "Iteration 474, loss = 1.22796793\n",
      "Iteration 475, loss = 1.22730069\n",
      "Iteration 476, loss = 1.22663659\n",
      "Iteration 477, loss = 1.22597562\n",
      "Iteration 478, loss = 1.22531774\n",
      "Iteration 479, loss = 1.22466295\n",
      "Iteration 480, loss = 1.22401122\n",
      "Iteration 481, loss = 1.22336253\n",
      "Iteration 482, loss = 1.22271686\n",
      "Iteration 483, loss = 1.22207420\n",
      "Iteration 484, loss = 1.22143452\n",
      "Iteration 485, loss = 1.22079780\n",
      "Iteration 486, loss = 1.22016402\n",
      "Iteration 487, loss = 1.21953317\n",
      "Iteration 488, loss = 1.21890523\n",
      "Iteration 489, loss = 1.21828017\n",
      "Iteration 490, loss = 1.21765799\n",
      "Iteration 491, loss = 1.21703865\n",
      "Iteration 492, loss = 1.21642215\n",
      "Iteration 493, loss = 1.21580846\n",
      "Iteration 494, loss = 1.21519757\n",
      "Iteration 495, loss = 1.21458945\n",
      "Iteration 496, loss = 1.21398410\n",
      "Iteration 497, loss = 1.21338149\n",
      "Iteration 498, loss = 1.21278160\n",
      "Iteration 499, loss = 1.21218443\n",
      "Iteration 500, loss = 1.21158995\n",
      "Iteration 501, loss = 1.21099814\n",
      "Iteration 502, loss = 1.21040899\n",
      "Iteration 503, loss = 1.20982248\n",
      "Iteration 504, loss = 1.20923859\n",
      "Iteration 505, loss = 1.20865732\n",
      "Iteration 506, loss = 1.20807863\n",
      "Iteration 507, loss = 1.20750252\n",
      "Iteration 508, loss = 1.20692897\n",
      "Iteration 509, loss = 1.20635796\n",
      "Iteration 510, loss = 1.20578949\n",
      "Iteration 511, loss = 1.20522352\n",
      "Iteration 512, loss = 1.20466005\n",
      "Iteration 513, loss = 1.20409906\n",
      "Iteration 514, loss = 1.20354054\n",
      "Iteration 515, loss = 1.20298447\n",
      "Iteration 516, loss = 1.20243083\n",
      "Iteration 517, loss = 1.20187961\n",
      "Iteration 518, loss = 1.20133080\n",
      "Iteration 519, loss = 1.20078438\n",
      "Iteration 520, loss = 1.20024034\n",
      "Iteration 521, loss = 1.19969866\n",
      "Iteration 522, loss = 1.19915932\n",
      "Iteration 523, loss = 1.19862232\n",
      "Iteration 524, loss = 1.19808764\n",
      "Iteration 525, loss = 1.19755526\n",
      "Iteration 526, loss = 1.19702518\n",
      "Iteration 527, loss = 1.19649737\n",
      "Iteration 528, loss = 1.19597182\n",
      "Iteration 529, loss = 1.19544852\n",
      "Iteration 530, loss = 1.19492746\n",
      "Iteration 531, loss = 1.19440862\n",
      "Iteration 532, loss = 1.19389199\n",
      "Iteration 533, loss = 1.19337756\n",
      "Iteration 534, loss = 1.19286531\n",
      "Iteration 535, loss = 1.19235523\n",
      "Iteration 536, loss = 1.19184731\n",
      "Iteration 537, loss = 1.19134153\n",
      "Iteration 538, loss = 1.19083788\n",
      "Iteration 539, loss = 1.19033635\n",
      "Iteration 540, loss = 1.18983692\n",
      "Iteration 541, loss = 1.18933959\n",
      "Iteration 542, loss = 1.18884434\n",
      "Iteration 543, loss = 1.18835116\n",
      "Iteration 544, loss = 1.18786003\n",
      "Iteration 545, loss = 1.18737095\n",
      "Iteration 546, loss = 1.18688391\n",
      "Iteration 547, loss = 1.18639888\n",
      "Iteration 548, loss = 1.18591586\n",
      "Iteration 549, loss = 1.18543484\n",
      "Iteration 550, loss = 1.18495580\n",
      "Iteration 551, loss = 1.18447874\n",
      "Iteration 552, loss = 1.18400364\n",
      "Iteration 553, loss = 1.18353049\n",
      "Iteration 554, loss = 1.18305928\n",
      "Iteration 555, loss = 1.18259000\n",
      "Iteration 556, loss = 1.18212264\n",
      "Iteration 557, loss = 1.18165718\n",
      "Iteration 558, loss = 1.18119361\n",
      "Iteration 559, loss = 1.18073194\n",
      "Iteration 560, loss = 1.18027213\n",
      "Iteration 561, loss = 1.17981419\n",
      "Iteration 562, loss = 1.17935809\n",
      "Iteration 563, loss = 1.17890384\n",
      "Iteration 564, loss = 1.17845142\n",
      "Iteration 565, loss = 1.17800083\n",
      "Iteration 566, loss = 1.17755204\n",
      "Iteration 567, loss = 1.17710505\n",
      "Iteration 568, loss = 1.17665985\n",
      "Iteration 569, loss = 1.17621642\n",
      "Iteration 570, loss = 1.17577477\n",
      "Iteration 571, loss = 1.17533488\n",
      "Iteration 572, loss = 1.17489673\n",
      "Iteration 573, loss = 1.17446033\n",
      "Iteration 574, loss = 1.17402566\n",
      "Iteration 575, loss = 1.17359270\n",
      "Iteration 576, loss = 1.17316145\n",
      "Iteration 577, loss = 1.17273191\n",
      "Iteration 578, loss = 1.17230406\n",
      "Iteration 579, loss = 1.17187788\n",
      "Iteration 580, loss = 1.17145338\n",
      "Iteration 581, loss = 1.17103055\n",
      "Iteration 582, loss = 1.17060936\n",
      "Iteration 583, loss = 1.17018983\n",
      "Iteration 584, loss = 1.16977192\n",
      "Iteration 585, loss = 1.16935564\n",
      "Iteration 586, loss = 1.16894098\n",
      "Iteration 587, loss = 1.16852793\n",
      "Iteration 588, loss = 1.16811648\n",
      "Iteration 589, loss = 1.16770662\n",
      "Iteration 590, loss = 1.16729834\n",
      "Iteration 591, loss = 1.16689163\n",
      "Iteration 592, loss = 1.16648649\n",
      "Iteration 593, loss = 1.16608291\n",
      "Iteration 594, loss = 1.16568087\n",
      "Iteration 595, loss = 1.16528037\n",
      "Iteration 596, loss = 1.16488140\n",
      "Iteration 597, loss = 1.16448395\n",
      "Iteration 598, loss = 1.16408802\n",
      "Iteration 599, loss = 1.16369360\n",
      "Iteration 600, loss = 1.16330067\n",
      "Iteration 601, loss = 1.16290923\n",
      "Iteration 602, loss = 1.16251927\n",
      "Iteration 603, loss = 1.16213079\n",
      "Iteration 604, loss = 1.16174377\n",
      "Iteration 605, loss = 1.16135821\n",
      "Iteration 606, loss = 1.16097410\n",
      "Iteration 607, loss = 1.16059143\n",
      "Iteration 608, loss = 1.16021020\n",
      "Iteration 609, loss = 1.15983039\n",
      "Iteration 610, loss = 1.15945201\n",
      "Iteration 611, loss = 1.15907503\n",
      "Iteration 612, loss = 1.15869946\n",
      "Iteration 613, loss = 1.15832529\n",
      "Iteration 614, loss = 1.15795250\n",
      "Iteration 615, loss = 1.15758110\n",
      "Iteration 616, loss = 1.15721107\n",
      "Iteration 617, loss = 1.15684241\n",
      "Iteration 618, loss = 1.15647510\n",
      "Iteration 619, loss = 1.15610916\n",
      "Iteration 620, loss = 1.15574455\n",
      "Iteration 621, loss = 1.15538129\n",
      "Iteration 622, loss = 1.15501936\n",
      "Iteration 623, loss = 1.15465875\n",
      "Iteration 624, loss = 1.15429946\n",
      "Iteration 625, loss = 1.15394148\n",
      "Iteration 626, loss = 1.15358481\n",
      "Iteration 627, loss = 1.15322943\n",
      "Iteration 628, loss = 1.15287534\n",
      "Iteration 629, loss = 1.15252254\n",
      "Iteration 630, loss = 1.15217101\n",
      "Iteration 631, loss = 1.15182076\n",
      "Iteration 632, loss = 1.15147177\n",
      "Iteration 633, loss = 1.15112404\n",
      "Iteration 634, loss = 1.15077755\n",
      "Iteration 635, loss = 1.15043232\n",
      "Iteration 636, loss = 1.15008832\n",
      "Iteration 637, loss = 1.14974555\n",
      "Iteration 638, loss = 1.14940401\n",
      "Iteration 639, loss = 1.14906368\n",
      "Iteration 640, loss = 1.14872457\n",
      "Iteration 641, loss = 1.14838667\n",
      "Iteration 642, loss = 1.14804997\n",
      "Iteration 643, loss = 1.14771446\n",
      "Iteration 644, loss = 1.14738014\n",
      "Iteration 645, loss = 1.14704701\n",
      "Iteration 646, loss = 1.14671505\n",
      "Iteration 647, loss = 1.14638426\n",
      "Iteration 648, loss = 1.14605463\n",
      "Iteration 649, loss = 1.14572617\n",
      "Iteration 650, loss = 1.14539885\n",
      "Iteration 651, loss = 1.14507269\n",
      "Iteration 652, loss = 1.14474766\n",
      "Iteration 653, loss = 1.14442377\n",
      "Iteration 654, loss = 1.14410102\n",
      "Iteration 655, loss = 1.14377938\n",
      "Iteration 656, loss = 1.14345887\n",
      "Iteration 657, loss = 1.14313946\n",
      "Iteration 658, loss = 1.14282117\n",
      "Iteration 659, loss = 1.14250397\n",
      "Iteration 660, loss = 1.14218788\n",
      "Iteration 661, loss = 1.14187287\n",
      "Iteration 662, loss = 1.14155895\n",
      "Iteration 663, loss = 1.14124611\n",
      "Iteration 664, loss = 1.14093435\n",
      "Iteration 665, loss = 1.14062366\n",
      "Iteration 666, loss = 1.14031403\n",
      "Iteration 667, loss = 1.14000546\n",
      "Iteration 668, loss = 1.13969794\n",
      "Iteration 669, loss = 1.13939147\n",
      "Iteration 670, loss = 1.13908605\n",
      "Iteration 671, loss = 1.13878166\n",
      "Iteration 672, loss = 1.13847831\n",
      "Iteration 673, loss = 1.13817599\n",
      "Iteration 674, loss = 1.13787469\n",
      "Iteration 675, loss = 1.13757441\n",
      "Iteration 676, loss = 1.13727514\n",
      "Iteration 677, loss = 1.13697688\n",
      "Iteration 678, loss = 1.13667962\n",
      "Iteration 679, loss = 1.13638337\n",
      "Iteration 680, loss = 1.13608811\n",
      "Iteration 681, loss = 1.13579383\n",
      "Iteration 682, loss = 1.13550055\n",
      "Iteration 683, loss = 1.13520824\n",
      "Iteration 684, loss = 1.13491690\n",
      "Iteration 685, loss = 1.13462654\n",
      "Iteration 686, loss = 1.13433714\n",
      "Iteration 687, loss = 1.13404871\n",
      "Iteration 688, loss = 1.13376123\n",
      "Iteration 689, loss = 1.13347470\n",
      "Iteration 690, loss = 1.13318912\n",
      "Iteration 691, loss = 1.13290448\n",
      "Iteration 692, loss = 1.13262078\n",
      "Iteration 693, loss = 1.13233802\n",
      "Iteration 694, loss = 1.13205619\n",
      "Iteration 695, loss = 1.13177528\n",
      "Iteration 696, loss = 1.13149529\n",
      "Iteration 697, loss = 1.13121621\n",
      "Iteration 698, loss = 1.13093805\n",
      "Iteration 699, loss = 1.13066080\n",
      "Iteration 700, loss = 1.13038445\n",
      "Iteration 701, loss = 1.13010900\n",
      "Iteration 702, loss = 1.12983445\n",
      "Iteration 703, loss = 1.12956079\n",
      "Iteration 704, loss = 1.12928801\n",
      "Iteration 705, loss = 1.12901612\n",
      "Iteration 706, loss = 1.12874510\n",
      "Iteration 707, loss = 1.12847496\n",
      "Iteration 708, loss = 1.12820569\n",
      "Iteration 709, loss = 1.12793729\n",
      "Iteration 710, loss = 1.12766975\n",
      "Iteration 711, loss = 1.12740306\n",
      "Iteration 712, loss = 1.12713723\n",
      "Iteration 713, loss = 1.12687225\n",
      "Iteration 714, loss = 1.12660812\n",
      "Iteration 715, loss = 1.12634483\n",
      "Iteration 716, loss = 1.12608238\n",
      "Iteration 717, loss = 1.12582077\n",
      "Iteration 718, loss = 1.12555998\n",
      "Iteration 719, loss = 1.12530002\n",
      "Iteration 720, loss = 1.12504089\n",
      "Iteration 721, loss = 1.12478258\n",
      "Iteration 722, loss = 1.12452508\n",
      "Iteration 723, loss = 1.12426839\n",
      "Iteration 724, loss = 1.12401251\n",
      "Iteration 725, loss = 1.12375744\n",
      "Iteration 726, loss = 1.12350317\n",
      "Iteration 727, loss = 1.12324970\n",
      "Iteration 728, loss = 1.12299702\n",
      "Iteration 729, loss = 1.12274513\n",
      "Iteration 730, loss = 1.12249402\n",
      "Iteration 731, loss = 1.12224370\n",
      "Iteration 732, loss = 1.12199417\n",
      "Iteration 733, loss = 1.12174540\n",
      "Iteration 734, loss = 1.12149741\n",
      "Iteration 735, loss = 1.12125019\n",
      "Iteration 736, loss = 1.12100373\n",
      "Iteration 737, loss = 1.12075804\n",
      "Iteration 738, loss = 1.12051311\n",
      "Iteration 739, loss = 1.12026893\n",
      "Iteration 740, loss = 1.12002550\n",
      "Iteration 741, loss = 1.11978282\n",
      "Iteration 742, loss = 1.11954089\n",
      "Iteration 743, loss = 1.11929970\n",
      "Iteration 744, loss = 1.11905925\n",
      "Iteration 745, loss = 1.11881954\n",
      "Iteration 746, loss = 1.11858056\n",
      "Iteration 747, loss = 1.11834230\n",
      "Iteration 748, loss = 1.11810477\n",
      "Iteration 749, loss = 1.11786797\n",
      "Iteration 750, loss = 1.11763189\n",
      "Iteration 751, loss = 1.11739652\n",
      "Iteration 752, loss = 1.11716186\n",
      "Iteration 753, loss = 1.11692792\n",
      "Iteration 754, loss = 1.11669468\n",
      "Iteration 755, loss = 1.11646215\n",
      "Iteration 756, loss = 1.11623031\n",
      "Iteration 757, loss = 1.11599918\n",
      "Iteration 758, loss = 1.11576874\n",
      "Iteration 759, loss = 1.11553899\n",
      "Iteration 760, loss = 1.11530993\n",
      "Iteration 761, loss = 1.11508156\n",
      "Iteration 762, loss = 1.11485387\n",
      "Iteration 763, loss = 1.11462686\n",
      "Iteration 764, loss = 1.11440052\n",
      "Iteration 765, loss = 1.11417486\n",
      "Iteration 766, loss = 1.11394987\n",
      "Iteration 767, loss = 1.11372555\n",
      "Iteration 768, loss = 1.11350190\n",
      "Iteration 769, loss = 1.11327890\n",
      "Iteration 770, loss = 1.11305657\n",
      "Iteration 771, loss = 1.11283490\n",
      "Iteration 772, loss = 1.11261387\n",
      "Iteration 773, loss = 1.11239350\n",
      "Iteration 774, loss = 1.11217378\n",
      "Iteration 775, loss = 1.11195470\n",
      "Iteration 776, loss = 1.11173627\n",
      "Iteration 777, loss = 1.11151848\n",
      "Iteration 778, loss = 1.11130132\n",
      "Iteration 779, loss = 1.11108480\n",
      "Iteration 780, loss = 1.11086891\n",
      "Iteration 781, loss = 1.11065365\n",
      "Iteration 782, loss = 1.11043902\n",
      "Iteration 783, loss = 1.11022501\n",
      "Iteration 784, loss = 1.11001162\n",
      "Iteration 785, loss = 1.10979885\n",
      "Iteration 786, loss = 1.10958670\n",
      "Iteration 787, loss = 1.10937516\n",
      "Iteration 788, loss = 1.10916424\n",
      "Iteration 789, loss = 1.10895392\n",
      "Iteration 790, loss = 1.10874421\n",
      "Iteration 791, loss = 1.10853510\n",
      "Iteration 792, loss = 1.10832659\n",
      "Iteration 793, loss = 1.10811868\n",
      "Iteration 794, loss = 1.10791137\n",
      "Iteration 795, loss = 1.10770465\n",
      "Iteration 796, loss = 1.10749852\n",
      "Iteration 797, loss = 1.10729298\n",
      "Iteration 798, loss = 1.10708802\n",
      "Iteration 799, loss = 1.10688365\n",
      "Iteration 800, loss = 1.10667986\n",
      "Iteration 801, loss = 1.10647665\n",
      "Iteration 802, loss = 1.10627402\n",
      "Iteration 803, loss = 1.10607196\n",
      "Iteration 804, loss = 1.10587047\n",
      "Iteration 805, loss = 1.10566955\n",
      "Iteration 806, loss = 1.10546920\n",
      "Iteration 807, loss = 1.10526942\n",
      "Iteration 808, loss = 1.10507019\n",
      "Iteration 809, loss = 1.10487153\n",
      "Iteration 810, loss = 1.10467342\n",
      "Iteration 811, loss = 1.10447587\n",
      "Iteration 812, loss = 1.10427888\n",
      "Iteration 813, loss = 1.10408243\n",
      "Iteration 814, loss = 1.10388654\n",
      "Iteration 815, loss = 1.10369119\n",
      "Iteration 816, loss = 1.10349638\n",
      "Iteration 817, loss = 1.10330212\n",
      "Iteration 818, loss = 1.10310839\n",
      "Iteration 819, loss = 1.10291521\n",
      "Iteration 820, loss = 1.10272256\n",
      "Iteration 821, loss = 1.10253044\n",
      "Iteration 822, loss = 1.10233886\n",
      "Iteration 823, loss = 1.10214780\n",
      "Iteration 824, loss = 1.10195728\n",
      "Iteration 825, loss = 1.10176727\n",
      "Iteration 826, loss = 1.10157779\n",
      "Iteration 827, loss = 1.10138883\n",
      "Iteration 828, loss = 1.10120039\n",
      "Iteration 829, loss = 1.10101247\n",
      "Iteration 830, loss = 1.10082506\n",
      "Iteration 831, loss = 1.10063816\n",
      "Iteration 832, loss = 1.10045178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 833, loss = 1.10026590\n",
      "Iteration 834, loss = 1.10008053\n",
      "Iteration 835, loss = 1.09989566\n",
      "Iteration 836, loss = 1.09971130\n",
      "Iteration 837, loss = 1.09952744\n",
      "Iteration 838, loss = 1.09934407\n",
      "Iteration 839, loss = 1.09916120\n",
      "Iteration 840, loss = 1.09897883\n",
      "Iteration 841, loss = 1.09879695\n",
      "Iteration 842, loss = 1.09861556\n",
      "Iteration 843, loss = 1.09843466\n",
      "Iteration 844, loss = 1.09825424\n",
      "Iteration 845, loss = 1.09807431\n",
      "Iteration 846, loss = 1.09789487\n",
      "Iteration 847, loss = 1.09771590\n",
      "Iteration 848, loss = 1.09753742\n",
      "Iteration 849, loss = 1.09735941\n",
      "Iteration 850, loss = 1.09718188\n",
      "Iteration 851, loss = 1.09700482\n",
      "Iteration 852, loss = 1.09682823\n",
      "Iteration 853, loss = 1.09665212\n",
      "Iteration 854, loss = 1.09647647\n",
      "Iteration 855, loss = 1.09630129\n",
      "Iteration 856, loss = 1.09612657\n",
      "Iteration 857, loss = 1.09595231\n",
      "Iteration 858, loss = 1.09577852\n",
      "Iteration 859, loss = 1.09560519\n",
      "Iteration 860, loss = 1.09543231\n",
      "Iteration 861, loss = 1.09525989\n",
      "Iteration 862, loss = 1.09508792\n",
      "Iteration 863, loss = 1.09491641\n",
      "Iteration 864, loss = 1.09474535\n",
      "Iteration 865, loss = 1.09457473\n",
      "Iteration 866, loss = 1.09440457\n",
      "Iteration 867, loss = 1.09423484\n",
      "Iteration 868, loss = 1.09406557\n",
      "Iteration 869, loss = 1.09389673\n",
      "Iteration 870, loss = 1.09372833\n",
      "Iteration 871, loss = 1.09356038\n",
      "Iteration 872, loss = 1.09339286\n",
      "Iteration 873, loss = 1.09322577\n",
      "Iteration 874, loss = 1.09305912\n",
      "Iteration 875, loss = 1.09289290\n",
      "Iteration 876, loss = 1.09272712\n",
      "Iteration 877, loss = 1.09256176\n",
      "Iteration 878, loss = 1.09239682\n",
      "Iteration 879, loss = 1.09223232\n",
      "Iteration 880, loss = 1.09206823\n",
      "Iteration 881, loss = 1.09190457\n",
      "Iteration 882, loss = 1.09174134\n",
      "Iteration 883, loss = 1.09157852\n",
      "Iteration 884, loss = 1.09141611\n",
      "Iteration 885, loss = 1.09125413\n",
      "Iteration 886, loss = 1.09109256\n",
      "Iteration 887, loss = 1.09093140\n",
      "Iteration 888, loss = 1.09077065\n",
      "Iteration 889, loss = 1.09061031\n",
      "Iteration 890, loss = 1.09045039\n",
      "Iteration 891, loss = 1.09029087\n",
      "Iteration 892, loss = 1.09013175\n",
      "Iteration 893, loss = 1.08997304\n",
      "Iteration 894, loss = 1.08981473\n",
      "Iteration 895, loss = 1.08965682\n",
      "Iteration 896, loss = 1.08949931\n",
      "Iteration 897, loss = 1.08934220\n",
      "Iteration 898, loss = 1.08918548\n",
      "Iteration 899, loss = 1.08902916\n",
      "Iteration 900, loss = 1.08887324\n",
      "Iteration 901, loss = 1.08871770\n",
      "Iteration 902, loss = 1.08856256\n",
      "Iteration 903, loss = 1.08840781\n",
      "Iteration 904, loss = 1.08825344\n",
      "Iteration 905, loss = 1.08809946\n",
      "Iteration 906, loss = 1.08794587\n",
      "Iteration 907, loss = 1.08779266\n",
      "Iteration 908, loss = 1.08763983\n",
      "Iteration 909, loss = 1.08748738\n",
      "Iteration 910, loss = 1.08733532\n",
      "Iteration 911, loss = 1.08718363\n",
      "Iteration 912, loss = 1.08703231\n",
      "Iteration 913, loss = 1.08688137\n",
      "Iteration 914, loss = 1.08673081\n",
      "Iteration 915, loss = 1.08658062\n",
      "Iteration 916, loss = 1.08643080\n",
      "Iteration 917, loss = 1.08628135\n",
      "Iteration 918, loss = 1.08613227\n",
      "Iteration 919, loss = 1.08598356\n",
      "Iteration 920, loss = 1.08583521\n",
      "Iteration 921, loss = 1.08568722\n",
      "Iteration 922, loss = 1.08553961\n",
      "Iteration 923, loss = 1.08539235\n",
      "Iteration 924, loss = 1.08524545\n",
      "Iteration 925, loss = 1.08509891\n",
      "Iteration 926, loss = 1.08495273\n",
      "Iteration 927, loss = 1.08480691\n",
      "Iteration 928, loss = 1.08466145\n",
      "Iteration 929, loss = 1.08451633\n",
      "Iteration 930, loss = 1.08437157\n",
      "Iteration 931, loss = 1.08422717\n",
      "Iteration 932, loss = 1.08408311\n",
      "Iteration 933, loss = 1.08393940\n",
      "Iteration 934, loss = 1.08379605\n",
      "Iteration 935, loss = 1.08365303\n",
      "Iteration 936, loss = 1.08351037\n",
      "Iteration 937, loss = 1.08336805\n",
      "Iteration 938, loss = 1.08322607\n",
      "Iteration 939, loss = 1.08308443\n",
      "Iteration 940, loss = 1.08294313\n",
      "Iteration 941, loss = 1.08280218\n",
      "Iteration 942, loss = 1.08266156\n",
      "Iteration 943, loss = 1.08252128\n",
      "Iteration 944, loss = 1.08238134\n",
      "Iteration 945, loss = 1.08224173\n",
      "Iteration 946, loss = 1.08210245\n",
      "Iteration 947, loss = 1.08196351\n",
      "Iteration 948, loss = 1.08182490\n",
      "Iteration 949, loss = 1.08168662\n",
      "Iteration 950, loss = 1.08154867\n",
      "Iteration 951, loss = 1.08141104\n",
      "Iteration 952, loss = 1.08127374\n",
      "Iteration 953, loss = 1.08113677\n",
      "Iteration 954, loss = 1.08100013\n",
      "Iteration 955, loss = 1.08086380\n",
      "Iteration 956, loss = 1.08072780\n",
      "Iteration 957, loss = 1.08059212\n",
      "Iteration 958, loss = 1.08045676\n",
      "Iteration 959, loss = 1.08032172\n",
      "Iteration 960, loss = 1.08018700\n",
      "Iteration 961, loss = 1.08005259\n",
      "Iteration 962, loss = 1.07991850\n",
      "Iteration 963, loss = 1.07978473\n",
      "Iteration 964, loss = 1.07965126\n",
      "Iteration 965, loss = 1.07951811\n",
      "Iteration 966, loss = 1.07938528\n",
      "Iteration 967, loss = 1.07925275\n",
      "Iteration 968, loss = 1.07912053\n",
      "Iteration 969, loss = 1.07898862\n",
      "Iteration 970, loss = 1.07885702\n",
      "Iteration 971, loss = 1.07872572\n",
      "Iteration 972, loss = 1.07859473\n",
      "Iteration 973, loss = 1.07846404\n",
      "Iteration 974, loss = 1.07833366\n",
      "Iteration 975, loss = 1.07820357\n",
      "Iteration 976, loss = 1.07807379\n",
      "Iteration 977, loss = 1.07794431\n",
      "Iteration 978, loss = 1.07781513\n",
      "Iteration 979, loss = 1.07768624\n",
      "Iteration 980, loss = 1.07755765\n",
      "Iteration 981, loss = 1.07742936\n",
      "Iteration 982, loss = 1.07730137\n",
      "Iteration 983, loss = 1.07717366\n",
      "Iteration 984, loss = 1.07704625\n",
      "Iteration 985, loss = 1.07691914\n",
      "Iteration 986, loss = 1.07679231\n",
      "Iteration 987, loss = 1.07666577\n",
      "Iteration 988, loss = 1.07653952\n",
      "Iteration 989, loss = 1.07641356\n",
      "Iteration 990, loss = 1.07628789\n",
      "Iteration 991, loss = 1.07616250\n",
      "Iteration 992, loss = 1.07603740\n",
      "Iteration 993, loss = 1.07591259\n",
      "Iteration 994, loss = 1.07578805\n",
      "Iteration 995, loss = 1.07566380\n",
      "Iteration 996, loss = 1.07553983\n",
      "Iteration 997, loss = 1.07541614\n",
      "Iteration 998, loss = 1.07529273\n",
      "Iteration 999, loss = 1.07516960\n",
      "Iteration 1000, loss = 1.07504675\n",
      "Iteration 1001, loss = 1.07492417\n",
      "Iteration 1002, loss = 1.07480187\n",
      "Iteration 1003, loss = 1.07467985\n",
      "Iteration 1004, loss = 1.07455810\n",
      "Iteration 1005, loss = 1.07443662\n",
      "Iteration 1006, loss = 1.07431541\n",
      "Iteration 1007, loss = 1.07419448\n",
      "Iteration 1008, loss = 1.07407381\n",
      "Iteration 1009, loss = 1.07395342\n",
      "Iteration 1010, loss = 1.07383330\n",
      "Iteration 1011, loss = 1.07371344\n",
      "Iteration 1012, loss = 1.07359385\n",
      "Iteration 1013, loss = 1.07347452\n",
      "Iteration 1014, loss = 1.07335546\n",
      "Iteration 1015, loss = 1.07323667\n",
      "Iteration 1016, loss = 1.07311814\n",
      "Iteration 1017, loss = 1.07299987\n",
      "Iteration 1018, loss = 1.07288186\n",
      "Iteration 1019, loss = 1.07276412\n",
      "Iteration 1020, loss = 1.07264663\n",
      "Iteration 1021, loss = 1.07252941\n",
      "Iteration 1022, loss = 1.07241244\n",
      "Iteration 1023, loss = 1.07229573\n",
      "Iteration 1024, loss = 1.07217928\n",
      "Iteration 1025, loss = 1.07206308\n",
      "Iteration 1026, loss = 1.07194714\n",
      "Iteration 1027, loss = 1.07183145\n",
      "Iteration 1028, loss = 1.07171602\n",
      "Iteration 1029, loss = 1.07160083\n",
      "Iteration 1030, loss = 1.07148590\n",
      "Iteration 1031, loss = 1.07137123\n",
      "Iteration 1032, loss = 1.07125680\n",
      "Iteration 1033, loss = 1.07114262\n",
      "Iteration 1034, loss = 1.07102869\n",
      "Iteration 1035, loss = 1.07091501\n",
      "Iteration 1036, loss = 1.07080157\n",
      "Iteration 1037, loss = 1.07068838\n",
      "Iteration 1038, loss = 1.07057544\n",
      "Iteration 1039, loss = 1.07046274\n",
      "Iteration 1040, loss = 1.07035029\n",
      "Iteration 1041, loss = 1.07023808\n",
      "Iteration 1042, loss = 1.07012611\n",
      "Iteration 1043, loss = 1.07001438\n",
      "Iteration 1044, loss = 1.06990289\n",
      "Iteration 1045, loss = 1.06979165\n",
      "Iteration 1046, loss = 1.06968064\n",
      "Iteration 1047, loss = 1.06956987\n",
      "Iteration 1048, loss = 1.06945934\n",
      "Iteration 1049, loss = 1.06934905\n",
      "Iteration 1050, loss = 1.06923899\n",
      "Iteration 1051, loss = 1.06912917\n",
      "Iteration 1052, loss = 1.06901959\n",
      "Iteration 1053, loss = 1.06891024\n",
      "Iteration 1054, loss = 1.06880112\n",
      "Iteration 1055, loss = 1.06869223\n",
      "Iteration 1056, loss = 1.06858358\n",
      "Iteration 1057, loss = 1.06847515\n",
      "Iteration 1058, loss = 1.06836696\n",
      "Iteration 1059, loss = 1.06825900\n",
      "Iteration 1060, loss = 1.06815127\n",
      "Iteration 1061, loss = 1.06804376\n",
      "Iteration 1062, loss = 1.06793649\n",
      "Iteration 1063, loss = 1.06782944\n",
      "Iteration 1064, loss = 1.06772261\n",
      "Iteration 1065, loss = 1.06761601\n",
      "Iteration 1066, loss = 1.06750964\n",
      "Iteration 1067, loss = 1.06740349\n",
      "Iteration 1068, loss = 1.06729757\n",
      "Iteration 1069, loss = 1.06719186\n",
      "Iteration 1070, loss = 1.06708638\n",
      "Iteration 1071, loss = 1.06698112\n",
      "Iteration 1072, loss = 1.06687608\n",
      "Iteration 1073, loss = 1.06677127\n",
      "Iteration 1074, loss = 1.06666667\n",
      "Iteration 1075, loss = 1.06656229\n",
      "Iteration 1076, loss = 1.06645812\n",
      "Iteration 1077, loss = 1.06635418\n",
      "Iteration 1078, loss = 1.06625045\n",
      "Iteration 1079, loss = 1.06614694\n",
      "Iteration 1080, loss = 1.06604364\n",
      "Iteration 1081, loss = 1.06594056\n",
      "Iteration 1082, loss = 1.06583769\n",
      "Iteration 1083, loss = 1.06573503\n",
      "Iteration 1084, loss = 1.06563259\n",
      "Iteration 1085, loss = 1.06553036\n",
      "Iteration 1086, loss = 1.06542834\n",
      "Iteration 1087, loss = 1.06532654\n",
      "Iteration 1088, loss = 1.06522494\n",
      "Iteration 1089, loss = 1.06512355\n",
      "Iteration 1090, loss = 1.06502237\n",
      "Iteration 1091, loss = 1.06492140\n",
      "Iteration 1092, loss = 1.06482064\n",
      "Iteration 1093, loss = 1.06472008\n",
      "Iteration 1094, loss = 1.06461973\n",
      "Iteration 1095, loss = 1.06451959\n",
      "Iteration 1096, loss = 1.06441965\n",
      "Iteration 1097, loss = 1.06431992\n",
      "Iteration 1098, loss = 1.06422039\n",
      "Iteration 1099, loss = 1.06412106\n",
      "Iteration 1100, loss = 1.06402194\n",
      "Iteration 1101, loss = 1.06392302\n",
      "Iteration 1102, loss = 1.06382429\n",
      "Iteration 1103, loss = 1.06372578\n",
      "Iteration 1104, loss = 1.06362746\n",
      "Iteration 1105, loss = 1.06352934\n",
      "Iteration 1106, loss = 1.06343142\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1500, momentum=0.95,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_iris.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluando el desempeño de entrenamiento de la Red Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_iris.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluando el desempeño de la Red Iris en el dataset de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_iris.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibujando la función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cost_function = red_iris.loss_curve_\n",
    "plt.figure()\n",
    "plt.plot(cost_function)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
